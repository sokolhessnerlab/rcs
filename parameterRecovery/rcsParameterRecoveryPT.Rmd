---
title: "rcsParameterRecovery"
author: "Hayley Brooks"
date: "2/16/2022"
output: html_document
---

This file executes and analyzes the results of the parameter recovery activity for the RCS studu to dissociate parameters from a simple prospect theory model (rho and mu) and to detect temporal context effects at three timescales

```{r setup, include=FALSE}
# config
library('config')
config = config::get()

# load packages 
library('parallel');
library('tictoc');
library('rio');
library("ggplot2")


# load our functions
source('./choiceProbabilityProspectTheory.R')
source('./negLLProspectTheory.R')
source('./constrainLambdaNegLL.R')
source('./constrainLambdaProbability.R')
source('./binaryChoices.R')
source('./rcsPtParamRecov.R')

eps = .Machine$double.eps;


```

Get our choice set function:
```{r load-choice-set}
choiceSetPath = file.path(config$path$code_files$choiceSetFx); # choice set path
source(choiceSetPath); # load choiceset
```


Specify some PT parameters we'd like to recover:
```{r set-parameter-values}

ptvalsRho = c(.5, .65, .9, 1.1, 1.3, 1.5); # risk attitudes
ptvalsMu = c(60,90,120,150,180,200); # choice consistency
PTvals = expand.grid(ptvalsRho, ptvalsMu);
#colnames(PTvals) <- c('rho','mu')
nSub = nrow(PTvals);
# the overall pattern for choice sets like this (i.e. VNI og and VNI narrow), mus are very high
```


Set up meta-parameters for parameter recovery exercise
```{r set-meta-parameters}
iter = 500; # iterations per person
ncores = 4; # cores we will use for parallel processing 
cIter = 10; #iterations per core


```


Check that our code works by plotting choices, probabilities, etc
```{r plot-example}
examplePTvals = c(.9, 120); # example rho and mu

cs = rcsChoiceSet(); # generate a choice set

exampleChoiceProb = conLprob(examplePTvals, cs);
exampleBinaryChoices = binaryChoiceFromProb(exampleChoiceProb);

# Scatter plots for probabilities, binary choices and both
plot(exampleChoiceProb);
plot(exampleBinaryChoices);
plot(exampleChoiceProb, exampleBinaryChoices); 

# Plot histogram of choice probabilities to see how variable choices are predicted to be.
# code from PSH CLASE
hist(exampleChoiceProb,xlab = 'Probability of Selecting Risky Option', ylab = 'Count of this probability', main = 'Distribution of choice probabilities given parameters'); 

exampleChoiceDF = data.frame(cs, exampleChoiceProb, exampleBinaryChoices);


# Plot p(choose risky option) given parameters as a function of choice values (code based on PSH CLASE)
exampleProbabilisticPlot = ggplot(data = exampleChoiceDF, aes(x = alternative, y = riskyGain)) + 
  geom_point(aes(color = exampleChoiceProb)) + 
  xlim(c(0,32)) + ylim(c(0,62)) + 
  scale_colour_gradient(low='red',high='green');
print(exampleProbabilisticPlot);


# Plot simulated binary choices given parameters as a function of choice values (also based on PSH CLASE code)
exampleBinaryPlot = ggplot(data = exampleChoiceDF, aes(x = alternative, y = riskyGain)) + 
  geom_point(aes(color = factor(exampleBinaryChoices))) + scale_color_manual(values = c('#ff0000','#00ff44'));
print(exampleBinaryPlot);

```

# Let's do the parameter recovery!

```{r parameter-recovery}

PTparRecResults = array(data = NA, dim = list(nSub,5,iter), dimnames = list(c(NULL), c("rho", "mu", "rho se", "mu se", "ll"),c(NULL))); # stores for each person and iteration, the best optimization results

# Initialize the progress bar
progress_bar = txtProgressBar(min = 0, max = nSub, style = 3)


tic();
for(n in 1:nSub){ # for each person
 for(i in 1:iter){ # iteration per person

# for testing on one person and a couple iterations:
#for(n in 1){ # for each person
 # for(i in 1:2){ # iteration per person
    
    cs = rcsChoiceSet(); # generate a new choice set
    predictP = conLprob(PTvals[n,], cs); #generate probabilities (constrains lambda to 1)
    choices = binaryChoiceFromProb(predictP); # convert proabilities to binary choices
    
    
    # now we use PT function to estimate paramter values based on generated choices
    indivEstimates = array(data=NA, dim = list(ncores,4,cIter)); # this will temporarily hold optimization results (pars and ll) from cores x cIter
    subjectn = cbind(cs, choices); # combine choice set with person's choices for optimization to have necessary data
    outputlist = mclapply(1:ncores, mc.cores = ncores, function(i) rcsPTparRec(cIter,subjectn)); #do the optimization
    
    for(c in 1:ncores){ #in each core
      for(r in 1:cIter){ # for each iteration
        if (typeof(outputlist[[c]][[r]]) == 'list'){ #if the output is a list -- this means optim worked
          indivEstimates[c,1:2,r] <- outputlist[[c]][[r]]$par; # pull out the parameter values for each iteration in each core
          indivEstimates[c,3,r] <- outputlist[[c]][[r]]$value; # pull out the log likelihood value
        } else {
          indivEstimates[c,1:2,r]<- NA ; #if optim did not work, just store as NA
          indivEstimates[c,3,r]<- NA}
      }
    };
    
    
    if (any(is.finite(indivEstimates))){ # if there was at least one optimization iteration that worked then follow the next steps
      indBest <- which(min(indivEstimates[,3,], na.rm = TRUE)==indivEstimates,arr.ind = T); # get the indices of the single best optimization across the cores & iterations
      bestoutput<- outputlist[[indBest[1,1]]][[indBest[1,3]]]; # use index to pull the best optim results from the outputlist
      #print(bestoutput)
      PTparRecResults[n,1:2,i]= bestoutput$par; # store the parameter values 
      PTparRecResults[n,5,i] = bestoutput$value; # store the nll value
      
      if(!any(bestoutput$hessian==0)){ # if there are not any zeroes in the hessian, then
       PTparRecResults[n,3:4,i] = sqrt(diag(solve(bestoutput$hessian)));# solve hessian and store the parameter SEs
      }
      
    }else { # if there were NO optimization iterations that worked, then follow the next step
      PTparRecResults[n,1:5,i] <- NA
    }
    
  } # end the loop: for i in 1:iter
    setTxtProgressBar(progress_bar, n)

}#end the loop: for n in 1:nSub

close(progress_bar)

toc();

save(PTparRecResults, file = "parameterRecoveryOutput.Rdata");

# ~10hr45min to complete

```

```{r check-results}
CIzscore = 1.96; # multiplier for calculating 95% confidence intervals (will be multiplied by standard errors)


#rho:
goodcountRho = 0
badcountRho =0
for(s in 1:nSub){
  for(i in 1:iter){
    if(!is.nan(PTparRecResults[s,3,i])){
      lowCI = PTparRecResults[s,1,i] - (CIzscore*PTparRecResults[s,3,i]); # low CI
      upCI = PTparRecResults[s,1,i] + (CIzscore*PTparRecResults[s,3,i]); # high CI
      if(PTvals[s,1] >= lowCI && PTvals[s,1] <= upCI){
        goodcountRho = goodcountRho + 1
      } else{
        print(c(s,i)); # print the subs and the iteration that was not successful
        badcountRho = badcountRho+1
      }
    }else{
      print(c(s,i,'nan'))
    }
  }
}

sprintf("Recovery for rho was %f", (goodcountRho/(nSub*iter)*100))
# 94.2

#mu:
goodcountMu = 0
badcountMu = 0
for(s in 1:nSub){
  for(i in 1:iter){
    if(!is.nan(PTparRecResults[s,4,i])){
      lowCI = PTparRecResults[s,2,i] - (CIzscore*PTparRecResults[s,4,i]); # low CI
      upCI = PTparRecResults[s,2,i] + (CIzscore*PTparRecResults[s,4,i]); # high CI
      if(PTvals[s,2] >= lowCI && PTvals[s,2] <= upCI){
        goodcountMu = goodcountMu + 1
      } else{
        print(c(s,i)); # print the subs and the iteration that was not successful
        badcountMu = badcountMu+1
      }
    }else{
      print(c(s,i,'nan'))
    }
  }
}

sprintf("Recovery for mu was %f", (goodcountMu/(nSub*iter)*100))
# 96.8


sprintf("Overall recovery was %.2f%%", ((goodcountMu + goodcountRho)/(nSub*iter*2))*100)





rhoPlotpdfFileName= file.path(config$path$directory, config$path$shlab_figures, "rhoResultsPlot.pdf")
pdf(rhoPlotpdfFileName)
for (s in 1:nSub){
  estimates = PTparRecResults[s,1,];
  error = PTparRecResults[s,3,];
  lowerCI = estimates - CIzscore*error;
  upperCI = estimates + CIzscore*error;
  
  plot(estimates, main = sprintf("recovery for rho = %g\n mu=%g", PTvals[s,1], PTvals[s,2]), ylim =c(-3,3))
  arrows(1:iter, upperCI, 1:iter, lowerCI,code=3, angle=90, length=0.05);
}
dev.off();


muPlotpdfFileName= file.path(config$path$directory, config$path$shlab_figures, "muResultsPlot.pdf")
pdf(muPlotpdfFileName)
for (s in 1:nSub){
  estimates = PTparRecResults[s,2,];
  error = PTparRecResults[s,4,];
  lowerCI = estimates - CIzscore*error;
  upperCI = estimates + CIzscore*error;
  
  plot(estimates, main = sprintf("recovery for mu = %g\n rho=%g", PTvals[s,2], PTvals[s,1]), ylim =c(-50,200))
  arrows(1:iter, upperCI, 1:iter, lowerCI,code=3, angle=90, length=0.05);
}
dev.off();

# Plots binary choices generated by probability and binary choice functions
# choices are shown for gain/safe combinations and a line for rho is plotted
choicesWithRhoPlotFileName= file.path(config$path$directory, config$path$shlab_figures, "choicesWithRhoPlot.pdf")
pdf(choicesWithRhoPlotFileName)
for(s in 1:nSub){
  for(i in 1:iter){
    
    cs = rcsChoiceSet(); # generate a new choice set
    predictP = conLprob(PTvals[s,], cs); #generate probabilities
    choices = binaryChoiceFromProb(predictP); # convert proabilities to binary choices
    
    
    
    yvals = seq(from=0,to=55,by=5);#  gain values
    rho = PTvals[s,1]; 
    xvalsSeekingL = (0.5*(yvals^rho))^(1/rho); 
    
    plot(cs$alternative, cs$riskyGain, col=choices/.5+2, main=sprintf("choices for rho = %g, mu = %g\n iteration %g", PTvals[s,1], PTvals[s,2], i)); # blue is accept, red is reject
    lines(xvalsSeekingL,yvals, col='black',lty = "longdash"); #
    
    segments(0,20,10,0, lwd=1); # slope = -2, intercept = 20
    segments(10,40,20,20, lwd=1); # slope = -2, intercept = 60
    segments(20,60,30,40, lwd=1); # slope = -2, intercept = 100
  }
}
dev.off();



```


