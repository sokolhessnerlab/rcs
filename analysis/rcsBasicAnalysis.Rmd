---
title: "RCS Basic Analysis"
author: "Hayley Brooks"
date: "2022-10-12"
output: html_document
---

# To do:
# wrap up complex span stuff (composite score)
# how does complex span and ERQ in our dataset compare to others?
# check rfx for context effects, start with past outcome
# Compare natural vs strategy difficulty at round 1 with t.test
# For RT â€“ do group mean of subject-level median; could also see what happens when removing trials with very fast RTs
# should we account for outcome on randomly selected trial from round 1? could put in outcome variable mean centered -30 to 30



```{r setup, include=FALSE}
rm(list=ls())

library('config')
config = config::get()

library('lmerTest')

setup_source = file.path(config$path$code_files$dataSetUp) # run our set up script (which loads all the data)
source(setup_source) #, local = knitr::knit_global())
```

#### How many participants are in each condition/order?
```{r conditions, echo=FALSE}

cat("participants in natural-natural condition:",sum(rcsSubLevelWide_clean$condCode==1), "\nparticipants in natural-strategy condition:",sum(rcsSubLevelWide_clean$condCode==2), "\nparticipants in strategy-natural condition:",sum(rcsSubLevelWide_clean$condCode==3),"\nparticipants in strategy-strategy condition:", sum(rcsSubLevelWide_clean$condCode==4))


condcode1 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==1]
condcode2 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==2]
condcode3 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==3]
condcode4 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==4]
```

#### Demographic
```{r demographic-info}



```


#### Average change in risk-taking across conditions
```{r, risk-taking-across-rounds, echo=FALSE}
# some basic pgamble stuff
summary(rcsSubLevelWide_clean$round1_pgamble)
# range: 0.007692-0.885496; median: 0.538168 mean: 0.533754

summary(rcsSubLevelWide_clean$round2_pgamble)
# range: 0.0229-0.9160  median: 0.5249  mean: 0.5343  

t.test(rcsSubLevelWide_clean$round1_pgamble, rcsSubLevelWide_clean$round2_pgamble, paired = T); # no significant difference in pgamble across rounds

# differences in pgam from round 1 to round 2:
pgamDiff = rcsSubLevelWide_clean$round1_pgamble - rcsSubLevelWide_clean$round2_pgamble

cat("\nChange in risk-taking from round1 to round 2 \n(round 1-round2)\n",mean(pgamDiff))

# pgamble diff between round 1 and 2 across conditions
# control, control
pgamDiffnatNat=mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode1)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode1)])

cat("\n\nDifference in risk-taking across rounds \nnatural(round1) - natural (round2)\ndiff p(gamble)",pgamDiffnatNat)

# control, strategy
pgamDiffnatStrat = mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode2)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode2)])
cat("\n\nDifference in risk-taking across rounds \nnatural(round1) - strategy (round2)\ndiff p(gamble)",pgamDiffnatStrat)

# strategy, control
pgamDiffstratNat = mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode3)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode3)])
cat("\n\nDifference in risk-taking across rounds \nstrategy(round1) - natural (round2)\ndiff p(gamble)",pgamDiffstratNat)

# strategy, strategy
pgamDiffstratStrat = mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode4)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode4)])
cat("\n\nDifference in risk-taking across rounds \nstrategy(round1) - strategy (round2)\ndiff p(gamble)",pgamDiffstratStrat)


# best way to show change in pgamble across rounds and strategy for raw data?

pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamByRound_condition.pdf'))
par(pty="s", mfrow=c(2,2))

plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==1], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==1], asp=1,col = "blue", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=1.5, main=sprintf("Natural-Natural\npgam diff = %.2f",pgamDiffnatNat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)


plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==2], asp=1,col = "green", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=1.5, main=sprintf("Natural-Strategy\npgam diff = %.2f",pgamDiffnatStrat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)


plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==3], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==3],col = "red", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", asp =1, axes=F, cex=1.5, main=sprintf("Strategy-Natural\npgam diff = %.2f",pgamDiffstratNat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)

plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==4], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==4], asp=1,col = "purple", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=1.5, main=sprintf("Strategy-Strategy\npgam diff = %.2f",pgamDiffstratStrat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)
dev.off();
```

#### Plot change in risk-taking across rounds and conditions
##### More risk taking in strategy condition (regardless of order)
```{r plot-basics, echo=FALSE}

#pdf("/Users/hayley/Desktop/shenhavLabTalk/risk-taking_rounds.pdf")
# plot(RDMqualityCheck$pgambleRound1[-c(12,15)]-RDMqualityCheck$pgambleRound2[-c(12,15)], ylab ="pGamble(round 1 - round 2)", xlab="participant", main="change in risk-taking across rounds", axes=F, pch=16, col="maroon", cex=1.5, ylim=c(-.4,.4), xlim=c(1,24))
# abline(h=0, col="grey", lty="dashed")
# axis(1, at = 1:nSub, labels = 1:nSub, lwd=3)
# axis(2, at = seq(-.4, .4, .1), lwd=3)
#dev.off()


# create a variable for condition code
# 1 = control, control
# 2 = control, strategy
# 3 = strategy, control
# 4 = strategy, strategy



par(pty="s")
plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==1], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==1], asp=1,col = rgb(red=0, green=0, blue=1, alpha = 0.4), pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=2)

abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)

points(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==2], col = rgb(red=0, green=1, blue=0, alpha = 0.4),asp=1, pch=16,cex=2)

points(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==3], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==3], asp=1, col = rgb(red=1, green=0, blue=0, alpha = 0.4), pch=16, cex=2)


points(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==4], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==4], asp= 1,col = rgb(red=.5, green=0, blue=.5, alpha = 0.4), pch=16, cex=2)
axis(1, lwd=6)
axis(2, lwd=6)
legend("bottomright", legend=c("nat-nat","nat-strat", "strat-nat" ,"strat-strat"), pch=16, bty="n", col=c("blue", "green", "red", "purple"), cex=1)





plot(c(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==2]- rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==3]- rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==3]), pch=16, ylab="Risk-taking\n (round 1 - round 2)", xlab="participant", ylim=c(-.5,.5),cex= 2,col=c(rep("green",length(condcode2)), rep("red", length(condcode3))), axes=F)
axis(1, at =1:sum(rcsSubLevelWide_clean$condCode %in% c(2,3)), labels = as.numeric(c(rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==3])), lwd=6, cex.axis=1)
axis(2, lwd=6, cex=1.5)
abline(h=0, col="darkgrey", lty="dashed", lwd=4)

legend("bottomright", legend=c("nat-strat", "strat-nat"), pch=16, bty="n", col=c("green","red"), cex=1)




```


#### Post round difficulty ratings
```{r instDifficulty-ratings}
# summary stats for diffciculty ratings in each condition and order
# participant generally felt that strategy was more difficult, on average.
summary(rcsSubLevelLong_clean$instDifficult[rcsSubLevelLong_clean$strategy==0])
summary(rcsSubLevelLong_clean$instDifficult[rcsSubLevelLong_clean$strategy==1])

# for participants who did natural condition both rounds, difficulty ratings is on average, higher in second round
natNatRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==1]
natNatRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==1]

summary(natNatRound1difficulty)
summary(natNatRound2difficulty)


# for participants who did natural then strategy, difficulty rating is on average, higher for second round (strategy harder)
natStratRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==2]
natStratRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==2]

summary(natStratRound1difficulty)
summary(natStratRound2difficulty)

# for participants who did strategy then natural, difficulty rating is on average, higher for first round (strategy harder) but this difference is much smaller than ones above
stratNatRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==3]
stratNatRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==3]

summary(stratNatRound1difficulty)
summary(stratNatRound2difficulty)

# for participants who did strategy then strategy, difficulty rating is on average, higher for first round and difference here is also smaller than nat-nat and nat-strat differences
stratStratRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==4]
stratStratRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==4]

summary(stratStratRound1difficulty)
summary(stratStratRound2difficulty)

# these are somewhat odd so it might make more sense to look at strat vs nat in round 2 for people who experienced natural first and for people who experience strategy first
plot(c(1,2), c(mean(natNatRound1difficulty), mean(natNatRound2difficulty)), pch = 16, col="red", ylim=c(20,50))
points(c(1,2), c(mean(natStratRound1difficulty), mean(natStratRound2difficulty)), pch = 16, col="blue")

plot(c(1,2), c(mean(stratNatRound1difficulty), mean(stratNatRound2difficulty)), pch = 16, col="red", ylim=c(20,50))
points(c(1,2), c(mean(stratStratRound1difficulty), mean(stratStratRound2difficulty)), pch = 16, col="blue")

# this suggests that we need to be careful about how we use the difficulty ratings because they are super variable and aren't as straightforward as we expected
# its also possible that mean is not the best measure. 
# it might worth looking at change in ratings instead of actual ratings

pdf(file.path(config$path$directory, config$path$shlab_figures,'InstDifficultyRatingPlots.pdf'))
par(pty="s", mfrow= c(2,2))
plot(natNatRound1difficulty, natNatRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue")
abline(a=0, b=1, col="grey")

plot(natStratRound1difficulty, natStratRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green")
abline(a=0, b=1, col="grey")

plot(stratNatRound1difficulty, stratNatRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red")
abline(a=0, b=1, col="grey")

plot(stratStratRound1difficulty, stratStratRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple")
abline(a=0, b=1, col="grey")

mtext("Instruction Difficulty Ratings", side = 3, line = - 2, outer = TRUE)
dev.off()


# change in ratings:
natNatDifficultyDiff = natNatRound1difficulty- natNatRound2difficulty
natStratDifficultyDiff = natStratRound1difficulty- natStratRound2difficulty
stratNatDifficultyDiff = stratNatRound1difficulty- stratNatRound2difficulty
stratStratDifficultyDiff = stratStratRound1difficulty- stratStratRound2difficulty

par(mfrow=c(2,2))
hist(natNatDifficultyDiff, xlim=c(-100, 100), main="change in difficulty ratings\n nat-nat", xlab="round 1 - round 2 difficulty")
hist(natStratDifficultyDiff,xlim=c(-100, 100), main="change in difficulty ratings\n nat-strat",xlab="round 1 - round 2 difficulty")
hist(stratNatDifficultyDiff,xlim=c(-100, 100), main="change in difficulty ratings\n strat-nat",xlab="round 1 - round 2 difficulty")
hist(stratStratDifficultyDiff,xlim=c(-100, 100),main="change in difficulty ratings\n strat-strat",xlab="round 1 - round 2 difficulty")

```


#### Post round how often ratings
```{r instFrequency-ratings}
# summary stats for how often ratings in each condition and order

# participants rated, on average, that they were able to follow instructions about 75% of the time for both conditions
summary(rcsSubLevelLong_clean$instHowOften[rcsSubLevelLong_clean$strategy==0])
summary(rcsSubLevelLong_clean$instHowOften[rcsSubLevelLong_clean$strategy==1])


# for participants who did natural condition both rounds, participants felt they followed task instructions roughly the same amount of time across rounds, 72-73% of the time
natNatRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==1]
natNatRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==1]

summary(natNatRound1howOften)
summary(natNatRound2howOften)
t.test(natNatRound1howOften,natNatRound2howOften, paired= T); #not significant p =.8


# for participants who did natural then strategy, participants report implementing strategy condition less often than acting natural
natStratRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==2]
natStratRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==2]

summary(natStratRound1howOften)
summary(natStratRound2howOften)
t.test(natStratRound1howOften,natStratRound2howOften, paired= T); #significant difference p =.04

# for participants who did strategy then natural, participants report implementing act natural instructions slightly more often than strategy (smaller difference than above)
stratNatRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==3]
stratNatRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==3]

summary(stratNatRound1howOften)
summary(stratNatRound2howOften)
t.test(stratNatRound1howOften,stratNatRound2howOften, paired= T); #not significant difference

# for participants who did strategy then strategy, participants rated following instructions more, on average, in the first round, relative to second round. but the difference is mall 76% vs 78%
stratStratRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==4]
stratStratRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==4]

summary(stratStratRound1howOften)
summary(stratStratRound2howOften)

t.test(stratStratRound1howOften,stratStratRound2howOften, paired= T); #not significant difference

# although people feel like natural and strategy are different in difficulty, it looks like they are able to do implement them roughly the same amount of time (here we are seeing averages for all 70-80%)

pdf(file.path(config$path$directory, config$path$shlab_figures,'InstFrequencyRatingPlots.pdf'))
par(pty="s", mfrow= c(2,2))
plot(natNatRound1howOften, natNatRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue")
abline(a=0, b=1, col="grey")

plot(natStratRound1howOften, natStratRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green")
abline(a=0, b=1, col="grey")

plot(stratNatRound1howOften, stratNatRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red")
abline(a=0, b=1, col="grey")

plot(stratStratRound1howOften, stratStratRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple")
abline(a=0, b=1, col="grey")

mtext("Instruction Frequency Ratings", side = 3, line = - 2, outer = TRUE)
dev.off()

```

#### average RT across conditions

```{r RT-conditions}

# On average, participants are slower to respond in the strategy condition (difference is very small)
summary(rcsSubLevelLong_clean$RT[rcsSubLevelLong_clean$strategy==0])
summary(rcsSubLevelLong_clean$RT[rcsSubLevelLong_clean$strategy==1])


# for participants who did natural then natural, they are, on average, faster in the second round
natNatRound1rt = rcsSubLevelWide_clean$round1_RT[rcsSubLevelWide_clean$condCode==1]
natNatRound2rt = rcsSubLevelWide_clean$round2_RT[rcsSubLevelWide_clean$condCode==1]

summary(natNatRound1rt)
summary(natNatRound2rt)
t.test(natNatRound1rt,natNatRound2rt, paired=T); # significant difference

# for participants who did natural then strategy, they are slightly faster in the second round (strategy)
natStratRound1rt = rcsSubLevelWide_clean$round1_RT[rcsSubLevelWide_clean$condCode==2]
natStratRound2rt = rcsSubLevelWide_clean$round2_RT[rcsSubLevelWide_clean$condCode==2]

summary(natStratRound1rt)
summary(natStratRound2rt)
t.test(natStratRound1rt,natStratRound2rt, paired=T); # significant difference


# for participants who did strategy then natural, they are slightly faster in second round (natural)
stratNatRound1rt = rcsSubLevelWide_clean$round1_RT[rcsSubLevelWide_clean$condCode==3]
stratNatRound2rt = rcsSubLevelWide_clean$round2_RT[rcsSubLevelWide_clean$condCode==3]

summary(stratNatRound1rt)
summary(stratNatRound2rt)

t.test(stratNatRound1rt,stratNatRound2rt, paired=T); # significant difference

# for participants who did strategy then strategy, they are faster in the second round
stratStratRound1rt = rcsSubLevelWide_clean$round1_RT[rcsSubLevelWide_clean$condCode==4]
stratStratRound2rt = rcsSubLevelWide_clean$round2_RT[rcsSubLevelWide_clean$condCode==4]

summary(stratStratRound1rt)
summary(stratStratRound2rt)
t.test(stratStratRound1rt,stratStratRound2rt, paired=T); # not significant

# people are faster in second rounds across the conditions.


pdf(file.path(config$path$directory, config$path$shlab_figures,'rtAcrossRndsStratPlots.pdf'))
par(pty="s", mfrow= c(2,2))
plot(natNatRound1rt, natNatRound2rt, ylim=c(0,3), xlim=c(0,3), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue")
abline(a=0, b=1, col="grey")

plot(natStratRound1rt, natStratRound2rt, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green")
abline(a=0, b=1, col="grey")

plot(stratStratRound1rt, stratStratRound2rt, ylim=c(0,3), xlim=c(0,3), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red")
abline(a=0, b=1, col="grey")

plot(stratStratRound1rt, stratStratRound2rt, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple")
abline(a=0, b=1, col="grey")

mtext("Average Reaction Time", side = 3, line = - 2, outer = TRUE)
dev.off()


```



```{r motivation-and-round-independence}
# How motivated were people?
rcsSubLevelWide_clean$motivationNumeric = as.numeric(rcsSubLevelWide_clean$motivation)
summary(rcsSubLevelWide_clean$motivationNumeric); # mean = 5.17; median = 5; min = 2; max = 7 (scale was 1-7)

# are there any differences in motivation across conditions (not that we'd expect this to happen on purpose but should check)
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==1]); # mean = ~5
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==2]); # mean = 5.26
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==3]); # mean = 5.34
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==4]); # mean = 5.1

hist(rcsSubLevelWide_clean$motivationNumeric, breaks=7, main= "Motivation ratings n=124\n mean = 5.17", xlab="motivation (1-7)", xlim=c(1,7))


# did the rounds feel independent to people? and did this depend on condition?

rcsSubLevelWide_clean$rdmRoundsIndepNumeric = as.numeric(rcsSubLevelWide_clean$rdmRoundsIndep)
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric); # mean= 4.99; median = 5; range = 1-7 (on a scale from 1-7)

summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==1]); # mean = 4.48
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==2]); # mean = 5.355
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==3]); # mean = 4.871
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==4]); # mean = 5.258

hist(rcsSubLevelWide_clean$rdmRoundsIndepNumeric, breaks=7, main= "RDM round independence\nn=124; mean = 4.99", xlab="independence ratings (1-7)", xlim=c(1,7))

```


```{r complex-span-tasks}
 summary(rcsSubLevelWide_clean$ospan); # range = 0-25; mean =14.53; median = 13
 summary(rcsSubLevelWide_clean$symspan); # range = 0-14; mean = 7.657; median = 9
 summary(rcsSubLevelWide_clean$ERQreapp); # range = 14-42; mean = 29.69; median =30
 summary(rcsSubLevelWide_clean$ERQsupp); # range = 4 - 27; mean = 14.89; median = 15
 
 
```


### Generalized linear mixed effects models
#### Trial-level
##### There are a couple of possibilities here. Account for round and strategy in trial-level models or leave out to help detect interactions in subsequent (context models)
```{r trial-level-glmer}

# # model with gain, safe and EV level (magnitude)
# model1_trialLev =glmer(choice ~ 1 +  gainScaled + safeScaled + evLevScaled + (1|subID), data=rdmDFclean , family = "binomial")
# summary(model1_trialLev)
# # risk-taking increases as gain amounts increases and decreases as safe values increase and magnitude increases
# 
# 
# # model with just round
# model2_trialLevRound= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode + (1|subID), data=rdmDFclean , family = "binomial")
# summary(model2_trialLevRound)
# # gain, safe, EV as above
# # no effect of round 

# model with round and strategy (and interaction)
model3_trialLevRoundStrat= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + (1|subID), data=rdmDFclean , family = "binomial")
summary(model3_trialLevRoundStrat)
# gain, safe, EV as above
# no main effect of round 
# main effect of strategy (more risk-taking in strategy condition)
# positive interaction between round and strategy 
  # this interaction means that the effect of each condition is stronger in round 2 (i.e. more risk-taking for strategy, esp in round 2 and less risk-taking in natural, esp round 2)


# Including round but not strategy in trial-model makes the subsequent analyses weird because there is a (potential) interaction between round and strategy. We either want to include both or none. Below, we will two analyses using predicted values (i.e. residuals) from model with just gain, safe, and EV and model with both round and strategy
```

```{r plot-strategy-round-effect}

# using estimates from model3_trialLevRoundStrat:
model3summary = summary(model3_trialLevRoundStrat)

conditionBeta = model3summary$coefficients[6]
roundBeta = model3summary$coefficients[5]
condRoundIntxnBeta =model3summary$coefficients[7]

rounds = c(-1,-1,1,1); # round 1, round 1, round 2, round 2
conditions = c(-1,1,-1,1) # natural, strategy, natural, strategy

pgamRoundxCondition = 1/(1+exp(-1*( (conditionBeta*conditions) + (roundBeta*rounds) + (condRoundIntxnBeta*conditions*rounds) )));

# natural, round 1 pgam = 0.4909277
# natural, round 2  pgam = 0.4593623
# strategy, round 1 pgam = 0.5125908
# strategy, round 2 pgam = 0.5371388

pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamRoundxCondition.pdf'))
#par(pty="s")

plot(c(pgamRoundxCondition[1], pgamRoundxCondition[3]),  ylim = c(.4,.6), pch=16, axes = F, lwd = 5, col="goldenrod1", ylab="P(gamble)", xlab="Round", cex = 2)
points(c(pgamRoundxCondition[2], pgamRoundxCondition[4]), pch=16, cex=2, col="tomato1")
axis(1, at=c(1,2), label=c("1", "2"), lwd=6, cex=1.5)
axis(2, lwd =6, cex=1.5)
abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)

legend("bottomright", legend=c("Act Natural", "Strategy"),pch =16, bty="n", col=c("goldenrod1","tomato1"), cex=1)
dev.off()
```




```{r save-predicted-values, echo=FALSE}
#rdmDFclean$predModel1= predict(model1_trialLev,type="link"); 


rdmDFclean$predModel3= predict(model3_trialLevRoundStrat,type="link"); 

# if you plot both of these predicted values, it it looks like there is a SLIGHT bias of unexplained gambling.

```


### Recent event models
#### glmer models are showing up as singular - we will use glm, effects are nearly identical between glmer and glm versions
```{r basic-recent-events-model}

# what happens when we account for strategy and round using predicted values from both of our trial level models
# using predicted values from model 1 above (gain, safe, ev)
# model_roundStrat_pred1= glm(choice ~ 0 + roundRecode*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_roundStrat_pred1)
# strategy is still significant and positive, positive interaction between round and strategy (no main effect of round)

# using predicted avlues from model 3 above (gain, safe, ev, round and strategy)
model_roundStrat_pred3= glm(choice ~ 0 + roundRecode*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_roundStrat_pred3)
# no effects of round, strategy or interaction


# PAST OUTCOME
# model_poc_pred1 = glm(choice ~ 0 + pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_poc_pred1)
# trending, negative beta is trending at <.05

model_poc_pred3 = glm(choice ~ 0 + pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_poc_pred3)
# negative trending effect of poc; p = 0.0703 .

# PAST OUTCOME INTXN WITH STRATEGY
# model_pocStrat_pred1 = glm(choice ~ 0 + pastOC1sc*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_pocStrat_pred1)
#no interaction, but outcome is still negative and significant 

model_pocStrat_pred3 = glm(choice ~ 0 + pastOC1sc*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_pocStrat_pred3)
# no interaction with strategy or main effect of strategy. poc is trending and negative


# SHIFT
# model_signedShiftStrat_pred1 = glm(choice ~ 0 + signedShiftsc*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_signedShiftStrat_pred1)

# positive effect of signed shift on risk-taking (more risk-taking as shift increases, less risk-taking a shift decreases)
# positive effect of strategy (more risk-taking in strategy condition)
# positive, trending interaction 
    # how does the weight change across conditions and shift sizes: from older model:
    # strategy + large positive shift: .33*.59 + 1*.05 + .33*1*.45 = .3932
    # strategy + large negative shift: -.33*.59 + 1*.05 + -.33*1*.45 = -.2932
    # natural + large positive shift: .33*.59 + -1*.05 + .33*-1*.45 = -.0038
    # natural + large negative shift: -.33*.59 + -1*.05 + -.33*-1*.45 = -.0962
    # effect of shift (in both directions) is stronger in strategy condition

#the effect of positive shift is super dependent on strategy (there could be an overall effect of positive shift) but the interaction is important. Negative shift has a stronger overall effect and no interaction with strategy 


model_signedShiftStrat_pred3 = glm(choice ~ 0 + signedShiftsc*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_signedShiftStrat_pred3)

# positive effct of signed shift (more risk-taking as shift increases)
# positive, trending interaction between shift and strategy, similar as above


#POSITIVE AND NEGATIVE SHIFT
# model_posNegShift_pred1 = glm(choice ~ 0 + posShiftsc  + negShiftsc, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_posNegShift_pred1) 
# only trending positive effect of negative shift

model_posNegShift_pred3 = glm(choice ~ 0 + posShiftsc  + negShiftsc, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_posNegShift_pred3)  
# positive shift is trending
# negative shift is significant (negative effect, so less risk-takign with larger negative shifts)



# POSITIVE AND NEGATIVE SHIFT WITH STRATEGY

# model_posNegShiftStrat_pred1 = glm(choice ~ 0 + posShiftsc*strategyRecode + negShiftsc*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_posNegShiftStrat_pred1) # AIC: 24519 (very similar to signedShift model)
# more risk-taking in strategy condition
# trening effect of negative shift: less risk-taking as negative shift increases (no interaction between negative shift and strategy)
# no main effect of positive shift but there is an interaction between positive shift and strategy (old model results used below but pattern is similar)
    # act natural, large positive shift = -1*.04 + .33*.43 + -1*.33*.88 = -0.1885
    # strategy, large positive shift = 1*.04 + .33*.43 + 1*.33*.88 = 0.4723
    # weight of positive shift on risk-taking is negative in natural condition
    # weight of positive shift on risk-taking is positive in strategy condition

model_posNegShiftStrat_pred3 = glm(choice ~ 0 + posShiftsc*strategyRecode + negShiftsc*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_posNegShiftStrat_pred3)
#  these models with positive and negative shift (vs signed shift) are allowing asymmetries between the positive and negative shift effect 
# similar results above but with no main effect of strategy and significant effect of negative shift
# trending effect of positive shift
# interaction between positive shift and strategy (stronger effect of positive shift in strategy condition)


#shift effect is comparing current vs previous shift but when we tell people to ignore recent things, they aren't thinking about current values (and how it changes from previous trial) as contextual effects. Perhaps is because its not accesible and so people can't defend against it in a way they could with past outcome.

# EARNINGS X EXPECTATIONS (I.E. TRIAL NORMALIZED)
# 
# model_earnsExp_pred1 = glm(choice ~ 0 + earnNormalizedOverall + trialSC, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_earnsExp_pred1)
# betas are in direction as expected and significant

model_earnsExp_pred3 = glm(choice ~ 0 + earnNormalizedOverall + trialSC, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_earnsExp_pred3)
# both significant in expected direction (positive effect of earnings; negative effect of expectations)
# AIC = 30496

# EARNINGS AND EXPECTATIONS (TIME) INTERACTING
# model_earnsExpIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*trialSC, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_earnsExpIntxn_pred1)
# effect of earnigns enx expectations as we'd expect, interactoin between trial and earnings is positive
# beta estimates are so similar between expectations and earnings

model_earnsExpIntxn_pred3 = glm(choice ~ 0 + earnNormalizedOverall*trialSC, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_earnsExpIntxn_pred3)
# betas for earnings and expectations nearly the same and direction is as expected. Trending interaction between them
# AIC = 30494 
(.8786*.5) - (.8538*.5) + (.5*.5*.2963); # earnings = expectations effect on gambling: 0.086475 
(.8786*1) - (.8538*.5) + (1*.5*.2963); # earnings > expectations effect on gambling: 0.59985
(.8786*.5) - (.8538*1) + (.5*1*.2963); # earnings < expectations effect on gambling: -0.26635
# when earnings are roughly equal to expectaions the net effect on gambling is small. When earnings are more than expected, the effect on gambling is positive and when earnings are less than expected the effect on gambling is negative.

#EARNINGS, EXPECTATIONS AND STRATEGY
# model_earnsExpIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*trialSC*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_earnsExpIntxn_pred1)
# main effect of expectation and earnings
# interaction beweten aernings and expectation is positive
# interactoin beweeen earnings, expectation and strategy (positive)


model_earnsExpIntxn_pred3 = glm(choice ~ 0 + earnNormalizedOverall*trialSC*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_earnsExpIntxn_pred3)
# main effects and interaction hold up (now interaction is significant) but no interaction with strategy
# AIC = 30493 - accoutning for strategy improves AIC though

#check earnings and expectations overall - breaking up earnings could be hurting us here.
#could still interact with strategy

# EARNINGS AND OUTCOME INTERACTION

# model_earnsOcExpIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*pastOC1sc*trialSC*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_earnsOcExpIntxn_pred1)
# negative effect of past outcome
# positive interaction between earnings and outcome and negative interaction bewteen expectations and outcome


# model above but remove interaction that includes trial
# model_earnsOcIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*pastOC1sc*strategyRecode + trialSC, data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_earnsOcIntxn_pred1)
# negative effect of past outcome
# signifcaint positive effect of earnings
# positive interaction between earnings and outcome
# positive efect expectation now

# does outcome interact with earnings/expectations?
model_earnsOcIntxn_pred3 = glm(choice ~ 0 + earnNormalizedOverall*trialSC*pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_earnsOcIntxn_pred3)
# when adding past outcome, both main effects of earnings and expectation goes away and so does the interaction
# AIC: 30219

model_earnsOC_expOC_Intxn_pred3 = glm(choice ~ 0 + earnNormalizedOverall*pastOC1sc+ trialSC*pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_earnsOC_expOC_Intxn_pred3)
# AIC: 30216
# negative effect of past outcome, interaction between earnings x poc and expectation x poc are significant (these interations have opposite betas)


model_earnsOC_expOC_Intxn_strategy_pred3 = glm(choice ~ 0 + earnNormalizedOverall*pastOC1sc*strategyRecode+ trialSC*pastOC1sc*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_earnsOC_expOC_Intxn_strategy_pred3)
# AIC:  30219
# no effect of strategy


# PUT ALL TIMESCALES IN MODEL

# model_3timescales_pred1 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall + posShiftsc + negShiftsc + trialSC,  data=rdmDFclean, family="binomial", offset=predModel1)
# summary(model_3timescales_pred1)
# negative past outcome effect
# no positive shift effect
# trending negaitve shift effeect
# interaction between past outcome and earnings 
# main positive effect of earnings
# main negative efect of expectations

model_3timescales_pred3 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall + posShiftsc + negShiftsc + trialSC*pastOC1sc,  data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_3timescales_pred3)
# AIC = 30212
# negative effect of past outcome, negative effect of negative shift, interaction between past outcome and earnings and past outcome and expectation


# model_3timescalesStrategy_pred1 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialSC*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
# # similar main effects as above include negative past outcome, negative shift effect, pocxearnings
# # strategy only effects positive shift
# summary(model_3timescalesStrategy_pred1)

model_3timescalesStrategy_pred3 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialSC*pastOC1sc*strategyRecode,  data=rdmDFclean, family="binomial", offset=predModel3)

summary(model_3timescalesStrategy_pred3)
# AIC = 30213
# main effect of past outcome
# main effect of strategy (although negative here)
# main effect of negative shift
# positive interaction between past outcome and earnings
# positive effect between strategy and positive shift
# negative interaction between past outcome and expectations

# Unclear if analysis below is super relevant or something we want to follow up on - these thoughts were mid data collection and we werent seeing an expected effect of earnings/expectations
# are we weakening the cumulative earnings effect by cutting it off between rounds? Do people track earnings over rounds?
model_3timescalesStrategy_earnOverall_pred3 = glm(choice ~ 0 + pastOC1sc*earningsAcrossRounds*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialSC*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)

summary(model_3timescalesStrategy_earnOverall_pred3)
# 24304 - a little higher than above
# negative past outcome and strategy effect.
# trending positive effect of earnings
# negative effect of negative shift (beta is positive but the effect is less risk-taking)
# negative trending effect of trial/expectations
# positive interaction between poc and earnings across rounds
# positive interaction bewteen positive shift and strategy

# and including trial over all
model_3timescalesStrategy_earnTrialOverall_pred3 = glm(choice ~ 0 + pastOC1sc*earningsAcrossRounds*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialAcrossRounds*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel3)

summary(model_3timescalesStrategy_earnTrialOverall_pred3)
# 24307
# similar as model above but now we see main effects of earnings and trial in the expected directions

# the best fitting model is one that accounts for earnings across both rounds but not expectations/trial across both rounds but when accounting for earnings and trial across rounds, we see the effects we'd expect to see.

# between subjects, it doesn't look like earnings and expectations don't interact with strategy at this point. 
# the strategy effect does seem to enhance one timescale but doesn't change the other two 
# if people ask: people who repeat conditions - we don't see an effect of strategy on earnings vs trial doing a between group analysis. things are getting complicated with people who change and these variables are cumulative but with a potential reset in the middle. 



```


```{r}
# it looks like people who repeat conditions may be more likely to track earnings over the rounds whereas people who switch strategies might reset between rounds

# subset data for those who were in condition code 1 and 4
repeatconditions = c(condcode1, condcode4)
rdmDFrepeatCond = rdmDFclean[as.numeric(rdmDFclean$subID) %in% repeatconditions,]

model1_repeatcond_trialLevRoundStrat= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + (1|subID), data=rdmDFrepeatCond , family = "binomial")
summary(model1_repeatcond_trialLevRoundStrat)

# get predicted values
rdmDFrepeatCond$pred= predict(model1_repeatcond_trialLevRoundStrat,type="link"); 


model_repeatcond_3timescalesStrategy = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialSC*strategyRecode, data=rdmDFrepeatCond, family="binomial", offset=pred)
summary(model_repeatcond_3timescalesStrategy)
#  11727


model_repeatcond_3timescalesStrategy_earnExpAcrossRounds = glm(choice ~ 0 + pastOC1sc*earningsAcrossRounds*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialAcrossRounds*strategyRecode, data=rdmDFrepeatCond, family="binomial", offset=pred)
summary(model_repeatcond_3timescalesStrategy_earnExpAcrossRounds)
# 11723




# subset data for those who were in condition code 2 and 3
switchconditions = c(condcode2, condcode3)
rdmDFswitchCond = rdmDFclean[as.numeric(rdmDFclean$subID) %in% switchconditions,]

model1_switchcond_trialLevRoundStrat= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + (1|subID), data=rdmDFswitchCond , family = "binomial")
summary(model1_switchcond_trialLevRoundStrat)

# get predicted values
rdmDFswitchCond$pred= predict(model1_switchcond_trialLevRoundStrat,type="link"); 


model_switchcond_3timescalesStrategy = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialSC*strategyRecode, data=rdmDFswitchCond, family="binomial", offset=pred)
summary(model_switchcond_3timescalesStrategy)
# 12541


model_switchcond_3timescalesStrategy_earnExpAcrossRounds = glm(choice ~ 0 + pastOC1sc*earningsAcrossRounds*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialAcrossRounds*strategyRecode, data=rdmDFswitchCond, family="binomial", offset=pred)
summary(model_switchcond_3timescalesStrategy_earnExpAcrossRounds)
# 12552




```




```{r, plot-big-model-results}
# haven't updated this
# first lets plot the effect of past outcome and strategy
# from big model, accounting for earnings and expectations across rounds using residuals model 3
pocBeta =  -0.34512
strategyBeta = -0.08747
pocXstrategyBeta= 0.06633 

poc = rep(seq(0,1, by=.1), times= 2)
strategy = rep(c(-1,1), each = length(poc)/2)
  
pgamPOCxStrategy= 1/(1+exp(-1*( (pocBeta*poc) + (strategyBeta*strategy) + (pocXstrategyBeta*poc*strategy) )));


pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamPOCxStrategy.pdf'))
par(pty="s")
plot(pgamPOCxStrategy[1:11], type="l", ylim=c(.35,.6), ylab="P(gamble)", xlab="Past Outcome ($)", lwd=5, col = "goldenrod1", axes = F)
lines(pgamPOCxStrategy[12:22], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
lines(pgamPOCxStrategy[1:11], lwd=5, col="goldenrod1")
axis(1, at = c(1,6,11), labels = c(0,30,61), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

legend("topright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()

# for presentation purposes, just plot act natural line
pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamPOCxStrategy_actNatLineOnly.pdf'))
par(pty="s")
plot(pgamPOCxStrategy[1:11], type="l", ylim=c(.35,.6), ylab="P(gamble)", xlab="Past Outcome ($)", lwd=5, col = "goldenrod1", axes = F)
#lines(pgamPOCxStrategy[12:22], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
lines(pgamPOCxStrategy[1:11], lwd=5, col="goldenrod1")
axis(1, at = c(1,6,11), labels = c(0,30,61), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

legend("topright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()


# plot shift effect
posShiftBeta = 0.43950 
negShiftBeta = 0.66468
posShiftStratIntxn = 0.77048
negShiftStratIntxn = -0.07737

posShiftAmts = rep(seq(0, .33, length.out = 3), times =2)
negShiftAmts = rep(seq(-.33, 0, length.out = 3), times = 2)
strategy = rep(c(-1,1), each = length(posShiftAmts)/2)

pgamPosshiftxStrategy= 1/(1+exp(-1*( (posShiftBeta*posShiftAmts) + (strategyBeta*strategy) + (posShiftStratIntxn*posShiftAmts*strategy) )));

pgamNegShiftxStrategy = 1/(1+exp(-1*( (negShiftBeta*negShiftAmts) + (strategyBeta*strategy) + (negShiftStratIntxn*negShiftAmts*strategy) )));

pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamPosShiftxStrategy.pdf'))
par(pty="s")
plot(pgamPosshiftxStrategy[1:3], type="l", ylim=c(.4,.6), ylab="P(gamble)", xlab="Positive Shift ($)", lwd=5, col = "goldenrod1", axes = F)
lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
lines(pgamPosshiftxStrategy[1:3], lwd=5, col="goldenrod1")
lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
axis(1, at = c(1:3), labels = c(0,10,20), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

legend("bottomright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()



pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamPosShiftxStrategy_actNatLineOnly.pdf'))
par(pty="s")
plot(pgamPosshiftxStrategy[1:3], type="l", ylim=c(.4,.6), ylab="P(gamble)", xlab="Positive Shift ($)", lwd=5, col = "goldenrod1", axes = F)
#lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
lines(pgamPosshiftxStrategy[1:3], lwd=5, col="goldenrod1")
#lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
axis(1, at = c(1:3), labels = c(0,10,20), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

#legend("bottomright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()



pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamNegShiftxStrategy.pdf'))
par(pty="s")
plot(pgamNegShiftxStrategy[1:3], type="l", ylim=c(.35,.6), ylab="P(gamble)", xlab="Negative Shift ($)", lwd=5, col = "goldenrod1", axes = F)
lines(pgamNegShiftxStrategy[4:6], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
lines(pgamNegShiftxStrategy[1:3], lwd=5, col="goldenrod1")
lines(pgamNegShiftxStrategy[4:6], lwd=5, col="tomato1")
axis(1, at = c(1:3), labels = c(-20,-10,0), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

legend("bottomright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()


```



```{r}
model_3timescales_pred3 = glm(choice ~ 0 + pastOC1sc + posShiftsc + negShiftsc+ earnNormalizedOverall*trialSC,  data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_3timescales_pred3)


model_3timescalesStrat_pred3 = glm(choice ~ 0 + pastOC1sc*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode+ earnNormalizedOverall*strategyRecode + trialSC*strategyRecode,  data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_3timescalesStrat_pred3)


pocBeta =  -0.16106


poc = seq(0,1, by=.1)

  
pgamPOC= 1/(1+exp(-1*( (pocBeta*poc))));


pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamPOC.pdf'))
par(pty="s")
plot(pgamPOC, type="l", ylim=c(.35,.6), ylab="P(gamble)", xlab="Past Outcome ($)", lwd=5, axes = F)
#lines(pgamPOCxStrategy[12:22], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
#lines(pgamPOCxStrategy[1:11], lwd=5, col="goldenrod1")
axis(1, at = c(1,6,11), labels = c(0,30,61), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

#legend("topright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()



# plot shift effect
posShiftBeta = 0.40937 
negShiftBeta =  0.63384


posShiftAmts = seq(0, .33, length.out = 3)
negShiftAmts = seq(-.33, 0, length.out = 3)


pgamPosshift= 1/(1+exp(-1*( (posShiftBeta*posShiftAmts))))

pgamNegShift = 1/(1+exp(-1*( (negShiftBeta*negShiftAmts))))

pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamPosShift.pdf'))
par(pty="s")
plot(pgamPosshift, type="l", ylim=c(.4,.6), ylab="P(gamble)", xlab="Positive Shift ($)", lwd=5, col = "blue", axes = F)
#lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
#lines(pgamPosshiftxStrategy[1:3], lwd=5, col="goldenrod1")
#lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
axis(1, at = c(1:3), labels = c(0,10,20), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

#legend("bottomright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()

pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamNegShift.pdf'))
par(pty="s")
plot(pgamNegShift, type="l", ylim=c(.4,.6), ylab="P(gamble)", xlab="Negative Shift ($)", lwd=5, col = "red", axes = F)
#lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
abline(a=.5, b=0, lwd=3, lty="dashed", col = "darkgrey")
#lines(pgamPosshiftxStrategy[1:3], lwd=5, col="goldenrod1")
#lines(pgamPosshiftxStrategy[4:6], lwd=5, col="tomato1")
axis(1, at = c(1:3), labels = c(-20,-10,0), lwd=5, cex = 1.5)
axis(2, lwd = 5, cex = 1.5)

#legend("bottomright", legend=c("Act Natural", "Strategy"), lty=c("solid", "solid"),lwd = 3, bty="n", col=c("goldenrod1","tomato1"), cex=1.15)
dev.off()





```



```{r, subset-round1-data}

rdmRound1df = rdmDFclean[rdmDFclean$roundRDM==1,]

natRound1 = rcsSubLevelWide_clean[rcsSubLevelWide_clean$round1_strategy==0,]
stratRound1 = rcsSubLevelWide_clean[rcsSubLevelWide_clean$round1_strategy==1,]


# more risk-taking in strategy condition
mean(natRound1$round1_pgamble)
mean(stratRound1$round1_pgamble)

# slightly slower in strategy 
mean(natRound1$round1_RT)
mean(stratRound1$round1_RT)

# more difficult in strategy
mean(natRound1$round1_instDifficult)
mean(stratRound1$round1_instDifficult)

# instruction frequency higher in strategy
mean(natRound1$round1_instHowOften)
mean(stratRound1$round1_instHowOften)
t.test(natRound1$round1_instHowOften, stratRound1$round1_instHowOften, paired = FALSE) # not a meaningful difference



model_round1_triLevelStrat = glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + strategyRecode + (1|subID), data=rdmRound1df , family = "binomial")
summary(model_round1_triLevelStrat)
# gain, safe and ev as expected
# no effect of strategy

rdmRound1df$predRnd1TriLev= predict(model_round1_triLevelStrat,type="link"); 

model_round1_3timescales = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode + posShiftsc*strategyRecode + negShiftsc*strategyRecode + trialSC*strategyRecode, data=rdmRound1df, family="binomial", offset=predRnd1TriLev)
summary(model_round1_3timescales)
# similar results above even when just looking at round 1 data
  # negative past outcome, negative shift effect, interaction between strategy and positive shift
  # trending positive effect of earnings




```


```{r explore-individual-differences}

# is there a relationship between strategy instruction difficulty and ospan/symspan scores
# start by just looking at round 1
cor.test(rcsSubLevelWide_clean$ospan, rcsSubLevelWide_clean$symspan); # positive correlation

plot(rcsSubLevelWide_clean$ospan+runif(nrow(rcsSubLevelWide_clean),min = -.25, max = .25), rcsSubLevelWide_clean$symspan); # positive correlation


cor.test(stratRound1$round1_instDifficult, stratRound1$ospan, method="spearman"); 
cor.test(stratRound1$round1_instDifficult, stratRound1$symspan, method="spearman"); 
cor.test(stratRound1$round1_instDifficult, stratRound1$ERQsupp, method="spearman"); 
cor.test(stratRound1$round1_instDifficult, stratRound1$ERQreapp, method="spearman"); 
# no correlation between instruction difficulty for participants who did strategy first and complex span or ERQ scores


cor.test(stratRound1$round1_instHowOften, stratRound1$ospan, method="spearman"); 
cor.test(stratRound1$round1_instHowOften, stratRound1$symspan, method="spearman"); 
cor.test(stratRound1$round1_instHowOften, stratRound1$ERQsupp, method="spearman"); # positive correlation
cor.test(stratRound1$round1_instHowOften, stratRound1$ERQreapp, method="spearman"); 

# no correlation between instruction frequency for participants who did strategy first with ospan, symspan, and ERQ reappraisal but there is a weak, positive relationship between instruction frequency and ERQ supression. Could this mean that people who have a tendency to supress emotional experiences are better at implementing the strategy instructions more often?


# Are instruction difficulty related to how often participants rated following the instructions
cor.test(stratRound1$round1_instDifficult, stratRound1$round1_instHowOften, method="spearman"); # difficulty rating negatively correlated with frequency (more difficult, lower frequency ratings)




cor.test(natRound1$round1_instDifficult, natRound1$ospan, method="spearman"); 
cor.test(natRound1$round1_instDifficult, natRound1$symspan, method="spearman"); 
cor.test(natRound1$round1_instDifficult, natRound1$ERQsupp, method="spearman"); 
cor.test(natRound1$round1_instDifficult, natRound1$ERQreapp, method="spearman"); 
# no correlation between instruction difficulty for participants who did natural first and complex span or ERQ scores


cor.test(natRound1$round1_instHowOften, natRound1$ospan, method="spearman"); # positive correlation
cor.test(natRound1$round1_instHowOften, natRound1$symspan, method="spearman"); 
cor.test(natRound1$round1_instHowOften, natRound1$ERQsupp, method="spearman"); 
cor.test(natRound1$round1_instHowOften, natRound1$ERQreapp, method="spearman"); 

# no correlation between instruction frequency for participants who did natural first with symspan, and ERQ scores but there is a positive relationship between instruction frequency and ospan. 


# Are instruction difficulty related to how often participants rated following the instructions
cor.test(natRound1$round1_instDifficult, natRound1$round1_instHowOften, method="spearman"); # difficulty rating negatively correlated with frequency (more difficult, lower frequency ratings)


# does strategy interact with ospan and symspan
# not sure if it makes sense to do this but:
model_3timescalesStrategy_complexSpan_pred3 = glm(choice ~ 0 + pastOC1sc*strategyRecode*symSpanScore + posShiftsc*strategyRecode*symSpanScore  + earnNormalizedOverall*strategyRecode*symSpanScore +  trialSC*strategyRecode*symSpanScore, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_3timescalesStrategy_complexSpan_pred3); # AIC: 20943; 3570 observations deleted (no data for those participants)
# positive interaction bewteen poc and strategy (strategy makes poc effect less negative and maybe even goes away but haven't plotted that yet)
# trending positive interaction between strategy and positive shift (making positive shift stronger)
# negative interaction between poc, strategy and symspan: 
# large past outcome, strategy condition, high symspan: -.08*(1) -.07*(1) +  0.003*(14) -0.035*(1)*(1)*(14) = -0.598
# large past outcome, strategy condition, low symspan: -.08*(1) -.07*(1) +  0.003*(0) -0.035*(1)*(1)*(0) = -.15

# large past outcome, natural condition, high symspan: -.08*(1) -.07*(1) +  0.003*(14) -0.035*(1)*(1)*(14) = -0.598
# large past outcome, natural condition, low symspan: -.08*(1) -.07*(1) +  0.003*(0) -0.035*(1)*(1)*(0) = -.15


# plot intxn between symspan, poc and strategy effect
pocBeta = -.08
stratBeta = -.07
symspanBeta = 0.003
pocStratSymspanBeta = -0.035

pocAmt = rep(seq(0, 1, length.out = 2), times =4)
symspanAmt = rep(c(0,14, 0,14), each= 2)
strategy = rep(c(-1,1), each = length(pocAmt)/2)

pgamPOCstrategySymspan= 1/(1+exp(-1*( (pocBeta*pocAmt) + (stratBeta*strategy) + (symspanBeta*symspanAmt) + (pocStratSymspanBeta*pocAmt*symspanAmt * strategy) )));


# 0 outcome, low symspan, natural: 0.5174929
# 0 outcome, high symspan, natural: 0.5279708
# big outcome, low symspan, natural: 0.4975000
# big outcome, high symspan, natural: 0.6276153


# 0 outcome, low symspan, strategy: 0.4825071
# 0 outcome, high symspan, strategy: 0.4930005
# big outcome, low symspan, strategy: 0.4625702 
# big outcome, high symspan, strategy: 0.3548014
# hard to really get what is going on here but it seems like higher sympspan is associated with stronger impact of past outcome in strategy condition


model_3timescalesStrategy_oSpan_pred3 = glm(choice ~ 0 + pastOC1sc*strategyRecode*ospanScore + posShiftsc*strategyRecode*ospanScore  + earnNormalizedOverall*strategyRecode*ospanScore +  trialSC*strategyRecode*ospanScore, data=rdmDFclean, family="binomial", offset=predModel3)
summary(model_3timescalesStrategy_oSpan_pred3); # AIC: 22244; 2014 observations deleted (no data for those participants)
# there's more data in the ospan model so the AIC will be higher but ospan doesn't interact with anything


# let's take a step back and just look at whether difficulty and frequency ratings of instrcutions are related to symspan and ERQ using glm

rcsSubLevelLong_clean$strategyRecode = rcsSubLevelLong_clean$strategy;
rcsSubLevelLong_clean$strategyRecode[rcsSubLevelLong_clean$strategyRecode==0] = -1; # change 0s to -1

instDiff_model1 = lmer(instDifficult ~ 1+ ospan + symspan + ERQreapp +  ERQsupp + strategyRecode + (1|subID), data=rcsSubLevelLong_clean)
summary(instDiff_model1)
# difficulty ratings significantly higher in strategy condition
# no relationship between instruction difficulty and working memory/ERQ

# in a model interacting strategy with complex span and ERQ - no interaction between strategy with the other things; and now main effect of  strategy goes away - asking too much of model?


instHowOften_model1 = lmer(instHowOften ~ 1+ ospan + symspan + ERQreapp +  ERQsupp + strategyRecode + (1|subID), data=rcsSubLevelLong_clean)
summary(instHowOften_model1)
# positive relationship between instructions frequency and ospan - higher ospan, higher frequency rating
# no effect of strategy on frequency

instHowOften_model2 = lmer(instHowOften ~ 1+ ospan*strategyRecode + symspan*strategyRecode + ERQreapp*strategyRecode +  ERQsupp*strategyRecode+  (1|subID), data=rcsSubLevelLong_clean)
summary(instHowOften_model2)
# no interactions with strategy or main effect of strategy.

```

```{r motivation}
rdmDFclean$overallMotivation = as.numeric(rdmDFclean$overallMotivation)



```

