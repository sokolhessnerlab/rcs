---
title: "RCS Basic Analysis"
author: "Hayley Brooks"
date: "2022-10-12"
output: html_document
---

# To do:
# how does complex span and ERQ in our dataset compare to others?
# check rfx for context effects, start with past outcome
# should we account for outcome on randomly selected trial from round 1? could put in outcome variable mean centered -30 to 30



```{r setup, include=FALSE}
rm(list=ls())

library('config')
config = config::get()

library('lmerTest')
library(dplyr)

setup_source = file.path(config$path$code_files$dataSetUp) # run our set up script (which loads all the data)
source(setup_source) #, local = knitr::knit_global())
```

#### How many participants are in each condition/order?
```{r conditions, echo=FALSE}

cat("participants in natural-natural condition:",sum(rcsSubLevelWide_clean$condCode==1), "\nparticipants in natural-strategy condition:",sum(rcsSubLevelWide_clean$condCode==2), "\nparticipants in strategy-natural condition:",sum(rcsSubLevelWide_clean$condCode==3),"\nparticipants in strategy-strategy condition:", sum(rcsSubLevelWide_clean$condCode==4))


condcode1 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==1]
condcode2 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==2]
condcode3 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==3]
condcode4 = rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==4]
```

#### Demographic
```{r demographic-info}

# Race code: 1 = white, 2 = Black or African American, 3 = American Indian and Alaskan Native, 4 = Asian, 5 = Native Hawaiian and Other Pacific Islander, 6 = Two or more races, 7= other, 8 = Decline to answer
cat("RACE: \nWhite:", sum(rcsSubLevelWide_clean$raceCode==1), 
        "\nBlack or African American:",sum(rcsSubLevelWide_clean$raceCode==2), 
        "\nAmerican Indian and Alaskan Native:",sum(rcsSubLevelWide_clean$raceCode==3),
        "\nAsian:", sum(rcsSubLevelWide_clean$raceCode==4),
        "\nNative Hawaiian and Other Pacific Islander:", sum(rcsSubLevelWide_clean$raceCode==5),
        "\nTwo or more races:", sum(rcsSubLevelWide_clean$raceCode==6),
        "\nOther:", sum(rcsSubLevelWide_clean$raceCode==7),
        "\nDecline to answer:", sum(rcsSubLevelWide_clean$raceCode==8))


# Ethnicity code: 1 = Hispanic or Latino; 2 = Not Hispanic or Latino
cat("ETHNICITY: \nHispanic or Latino:", sum(rcsSubLevelWide_clean$ethnicityCode==1), 
        "\nNon-Hispanic or Latino:",sum(rcsSubLevelWide_clean$ethnicityCode==2))

# Gender code: 1 = Male, 2 = Female, 3 = Trans Male, 4 = Trans Female, 5 = Gender nonconforming, 6 = other, 7 = Decline to answer
cat("GENDER: \nMale:", sum(rcsSubLevelWide_clean$genderCode==1), 
        "\nFemale:",sum(rcsSubLevelWide_clean$genderCode==2), 
        "\nTrans Male:",sum(rcsSubLevelWide_clean$genderCode==3),
        "\nTrans Female:", sum(rcsSubLevelWide_clean$genderCode==4),
        "\nGender nonconforming:", sum(rcsSubLevelWide_clean$genderCode==5),
        "\nOther:", sum(rcsSubLevelWide_clean$genderCode==6),
        "\nDecline to answer:", sum(rcsSubLevelWide_clean$genderCode==7))


# Age:
cat("AGE (years): \nmean =", mean(rcsSubLevelWide_clean$age),
    "\nrange =", range(rcsSubLevelWide_clean$age),
    "\nmedian =", median(rcsSubLevelWide_clean$age))

```


#### Average change in risk-taking across conditions
```{r, risk-taking-across-rounds, echo=FALSE}

# What is the overall p(gamble) in each round (not separating by condition)
# some basic pgamble stuff
summary(rcsSubLevelWide_clean$round1_pgamble)
# range: 0.007692-0.885496; median: 0.538168 mean: 0.533754

summary(rcsSubLevelWide_clean$round2_pgamble)
# range: 0.0229-0.9160  median: 0.5249  mean: 0.5343  

t.test(rcsSubLevelWide_clean$round1_pgamble, rcsSubLevelWide_clean$round2_pgamble, paired = T); # no significant difference in mean pgamble across rounds

# differences in pgam from round 1 to round 2:
pgamDiff = rcsSubLevelWide_clean$round1_pgamble - rcsSubLevelWide_clean$round2_pgamble

# Risk-taking slightly decreased from round 1 to round 2, but the difference is not significant.

# What does the change in risk-taking from round 1 to round 2 look like for the different conditions?

# CONTROL- CONTROL
pgamDiffnatNat=mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode1)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode1)]);
cat("\n\nDifference in risk-taking across rounds \nnatural(round1) - natural (round2)\ndiff p(gamble)",pgamDiffnatNat);

# Risk-taking decreases from round 1 to round 2 in people are told to act natural in both rounds.


# CONTROL- STRATEGY
pgamDiffnatStrat = mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode2)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode2)]);
cat("\n\nDifference in risk-taking across rounds \nnatural(round1) - strategy (round2)\ndiff p(gamble)",pgamDiffnatStrat);

# Risk-taking increases from round 1 to round 2 when people go from act natural to strategy condition.


# STRATEGY-CONTROL
pgamDiffstratNat = mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode3)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode3)]);
cat("\n\nDifference in risk-taking across rounds \nstrategy(round1) - natural (round2)\ndiff p(gamble)",pgamDiffstratNat);

# Risk-taking decreases from round 1 to round 2 when people go from strategy to natural.


# STRATEGY-STRATEGY
pgamDiffstratStrat = mean(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode4)] - rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$subID %in% as.numeric(condcode4)]);
cat("\n\nDifference in risk-taking across rounds \nstrategy(round1) - strategy (round2)\ndiff p(gamble)",pgamDiffstratStrat);

# Risk-taking increases from round 1 to round 2 when people do strategy in both rounds. 

# SUMMARY: Generally, more risk-taking in the strategy condition when people do both natural and strategy (regardless of order). When people repeat act natural, they take less risks across time and when people repeat strategy, they take more risks over time.


pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamByRound_condition.pdf'))
par(pty="s", mfrow=c(2,2), mar = c(5,4,5,2))

plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==1], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==1], asp=1,col = "blue", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=1.5, main=sprintf("Natural-Natural\npgam diff = %.2f",pgamDiffnatNat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)


plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==2], asp=1,col = "green", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=1.5, main=sprintf("Natural-Strategy\npgam diff = %.2f",pgamDiffnatStrat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)

plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==3], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==3],col = "red", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", asp =1, axes=F, cex=1.5, main=sprintf("Strategy-Natural\npgam diff = %.2f",pgamDiffstratNat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)

plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==4], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==4], asp=1,col = "purple", pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=1.5, main=sprintf("Strategy-Strategy\npgam diff = %.2f",pgamDiffstratStrat))
abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)
axis(1, lwd=6)
axis(2, lwd=6)

mtext("Change in risk-taking", side = 3, line = -1, outer = TRUE)
dev.off();
```

Another version of plots above: Not super helpful plots with full dataset
```{r plot-basic-pgamacrossall, echo=FALSE}


par(pty="s")
plot(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==1], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==1], asp=1,col = rgb(red=0, green=0, blue=1, alpha = 0.4), pch=16, ylim=c(0,1), xlim=c(0,1), ylab="p(gamble round 1)", xlab="p(gamble round 2)", axes=F, cex=2)

abline(a = 0, b=1, lty="dashed", col="darkgrey",lwd=5)

points(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==2], col = rgb(red=0, green=1, blue=0, alpha = 0.4),asp=1, pch=16,cex=2)

points(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==3], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==3], asp=1, col = rgb(red=1, green=0, blue=0, alpha = 0.4), pch=16, cex=2)


points(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==4], rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==4], asp= 1,col = rgb(red=.5, green=0, blue=.5, alpha = 0.4), pch=16, cex=2)
axis(1, lwd=6)
axis(2, lwd=6)
legend("bottomright", legend=c("nat-nat","nat-strat", "strat-nat" ,"strat-strat"), pch=16, bty="n", col=c("blue", "green", "red", "purple"), cex=1)



plot(c(rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==2]- rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$round1_pgamble[rcsSubLevelWide_clean$condCode==3]- rcsSubLevelWide_clean$round2_pgamble[rcsSubLevelWide_clean$condCode==3]), pch=16, ylab="Risk-taking\n (round 1 - round 2)", xlab="participant", ylim=c(-.5,.5),cex= 2,col=c(rep("green",length(condcode2)), rep("red", length(condcode3))), axes=F)
axis(1, at =1:sum(rcsSubLevelWide_clean$condCode %in% c(2,3)), labels = as.numeric(c(rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==2], rcsSubLevelWide_clean$subID[rcsSubLevelWide_clean$condCode==3])), lwd=6, cex.axis=1)
axis(2, lwd=6, cex=1.5)
abline(h=0, col="darkgrey", lty="dashed", lwd=4)

legend("bottomright", legend=c("nat-strat", "strat-nat"), pch=16, bty="n", col=c("green","red"), cex=1)

```


#### Post round difficulty ratings
```{r instDifficulty-ratings}
# Participants rated how difficult the instructions were to follow on a scale from 1-100

# ACROSS CONDITIONS
summary(rcsSubLevelLong_clean$instDifficult[rcsSubLevelLong_clean$strategy==0]); 
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 1.00   12.89   25.83   30.95   49.80   79.59 
summary(rcsSubLevelLong_clean$instDifficult[rcsSubLevelLong_clean$strategy==1]);
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 1.00   11.62   27.49   34.18   56.98   99.80 
# Participants rated strategy instructions as more difficult, on average, relative to control. This does not account for condition/order


# NATURAL-NATURAL
natNatRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==1];
natNatRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==1];
cond1difficultydiff = mean(natNatRound1difficulty - natNatRound2difficulty);

# round 1, natural-natural
summary(natNatRound1difficulty);
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 1.00   12.79   22.75   27.48   38.13   64.36 

# round 2, natural-natural
summary(natNatRound2difficulty)
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 1.758  18.457  39.746  36.489  56.494  79.590 

t.test(natNatRound1difficulty, natNatRound2difficulty, paired=T); # significant difference, p = .02

# Difficulty ratings significantly higher in round 2 for people repeating natural.


# NATURAL-STRATEGY
natStratRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==2];
natStratRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==2];
cond2difficultydiff = mean(natStratRound1difficulty - natStratRound2difficulty);


summary(natStratRound1difficulty);
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 1.00   11.23   29.20   31.55   50.88   77.64 

summary(natStratRound2difficulty);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 2.637  16.699  33.691  41.777  66.602  92.578

t.test(natStratRound1difficulty, natStratRound2difficulty, paired=T); # trending difference, p = .09

# Difficulty higher in round 2 for people who start with natural and do strategy.


# STRATEGY-NATURAL
stratNatRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==3];
stratNatRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==3];
cond3difficultydiff = mean(stratNatRound1difficulty - stratNatRound2difficulty);


summary(stratNatRound1difficulty);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 1.074   8.398  24.707  31.096  51.465  99.805 

summary(stratNatRound2difficulty);
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 1.00   13.53   24.22   28.30   37.11   76.17 

t.test(stratNatRound1difficulty, stratNatRound2difficulty, paired=T); # n.s, p = .64

# Difficulty ratings are slightly lower for natural after strategy The difference is not significant and much smaller than people who go from natural to strategy


# STRATEGY-STRATEGY
stratStratRound1difficulty = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode==4];
stratStratRound2difficulty = rcsSubLevelWide_clean$round2_instDifficult[rcsSubLevelWide_clean$condCode==4];
cond4difficultydiff = mean(stratStratRound1difficulty - stratStratRound2difficulty)
  
summary(stratStratRound1difficulty);
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 1.00   13.23   30.76   33.84   57.37   87.11 

summary(stratStratRound2difficulty);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 2.930   9.521  23.828  30.015  41.602  86.816 

t.test(stratStratRound1difficulty, stratStratRound2difficulty, paired=T); # n.s, p = .35

# Difficulty ratings are slightly lower in round 2 for people who do strat-strat but the difference is not significant. This is not consistent with people who repeat nat-nat who found second round as more difficult.

# These ratings are odd, there isn't a clear pattern here. What about looking at strat vs nat in round 2 for people who experienced natural first and for people who experience strategy first
plot(c(1,2), c(mean(natNatRound1difficulty), mean(natNatRound2difficulty)), pch = 16, col="red", ylim=c(20,50), ylab="difficulty ratings", xlab="condition\nred = nat-nat\n blue=nat-strat", main="Difficulty ratings as fx of round 1 natural", axes=F);
points(c(1,2), c(mean(natStratRound1difficulty), mean(natStratRound2difficulty)), pch = 16, col="blue");
axis(1, at=c(1,2), label=c("round 1", "round 2"))
axis(2, at=c(20,30,40,50))

plot(c(1,2), c(mean(stratNatRound1difficulty), mean(stratNatRound2difficulty)), pch = 16, col="red", ylim=c(20,50), ylab="difficulty ratings", xlab="condition\nred = strat-nat\n blue=strat-strat", main="Difficulty ratings as fx of round 1 strategy", axes=F);
points(c(1,2), c(mean(stratStratRound1difficulty), mean(stratStratRound2difficulty)), pch = 16, col="blue");
axis(1, at=c(1,2), label=c("round 1", "round 2"))
axis(2, at=c(20,30,40,50))

# These plots suggest that if you start with natural, anything after that including natural is more difficult. If you start with strategy, anything after that is less difficult (inc. repeating strategy condition)

# Overall, these results suggests that we need to be careful about how we use the difficulty ratings because they are super variable and aren't as straightforward as we expected It is possible that mean is not the best measure. 
# it might worth looking at change in ratings instead of actual ratings


# What about comparing natural vs. strategy in round 1 only (N=62 per group)

natFirst = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode %in% c(1,2)]; # people who do nat first

summary(natFirst);
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 1.00   11.23   23.58   29.51   49.61   77.64 

stratFirst = rcsSubLevelWide_clean$round1_instDifficult[rcsSubLevelWide_clean$condCode %in% c(3,4)]; # people who do strat first

summary(stratFirst);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 1.000   9.912  26.709  32.468  55.688  99.805 

t.test(natFirst, stratFirst); # ns, p= .5

# No significant difference between difficulty ratings in natural and strategy for people who do natural and strategy first.


# Plot round 1 vs round 2 difficulty ratings for each condition:
pdf(file.path(config$path$directory, config$path$shlab_figures,'InstDifficultyRatingPlots.pdf'))
par(pty="s", mfrow= c(2,2), mar = c(5,4,5,2))
plot(natNatRound1difficulty, natNatRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue", main=sprintf("Natural-Natural\ndifficulty diff = %.2f",cond1difficultydiff))
abline(a=0, b=1, col="grey")

plot(natStratRound1difficulty, natStratRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green",main=sprintf("Natural-Strategy\ndifficulty diff = %.2f",cond2difficultydiff))
abline(a=0, b=1, col="grey")

plot(stratNatRound1difficulty, stratNatRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red", main=sprintf("Strategy-Natural\ndifficulty diff = %.2f",cond3difficultydiff))
abline(a=0, b=1, col="grey") 

plot(stratStratRound1difficulty, stratStratRound2difficulty, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple", main=sprintf("Strategy-Strategy\ndifficulty diff = %.2f",cond4difficultydiff))
abline(a=0, b=1, col="grey")

mtext("Instruction Difficulty Ratings", side = 3, line = -1, outer = TRUE)
dev.off()

```


#### Post round how often/frequency ratings
```{r instFrequency-ratings}
# Participants reported how often they were able to follow instructions in each round of the rdm task

# FREQUENCY RATINGS FOR INSTRUCTION TYPE OVERALL (not accounting for order/condition)
summary(rcsSubLevelLong_clean$instHowOften[rcsSubLevelLong_clean$strategy==0]);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 18.36   63.40   75.39   75.17   91.46   99.90 
summary(rcsSubLevelLong_clean$instHowOften[rcsSubLevelLong_clean$strategy==1]);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 22.17   63.45   79.30   75.06   90.72   99.90 

# Participants were able to follow instructions about the same across instructions 

#FREQUENCY RATINGS FOR INSTRUCTIONS ACROSS ROUNDS 
summary(rcsSubLevelWide_clean$round1_instHowOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 18.36   67.31   79.98   76.66   91.46   99.71 

summary(rcsSubLevelWide_clean$round2_instHowOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 22.17   60.50   75.20   73.57   90.87   99.90 

# participants reported following instructions less in round 2 but difference is small


# NATURAL-NATURAL
natNatRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==1];
natNatRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==1];
cond1freqdiff = mean(natNatRound1howOften-natNatRound2howOften);

summary(natNatRound1howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 18.36   66.70   76.66   73.10   90.09   98.73 

summary(natNatRound2howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 38.18   58.40   70.90   72.31   90.38   97.66 

t.test(natNatRound1howOften,natNatRound2howOften, paired= T); #not significant p =.8

# Participants followed instructions about the same amount of time in both natural rounds.


# NATURAL-STRATEGY
natStratRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==2];
natStratRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==2];
cond2freqdiff = mean(natStratRound1howOften-natStratRound2howOften);

summary(natStratRound1howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 48.44   65.14   75.49   76.87   90.82   99.71 
summary(natStratRound2howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 22.17   57.03   72.75   69.22   84.81   99.90 

t.test(natStratRound1howOften,natStratRound2howOften, paired= T); #significant difference p =.04

# Participants reporting following instructions less in strategy condition relative to first round of natural.

# STRATEGY-NATURAL
stratNatRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==3];
stratNatRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==3];
cond3freqdiff = mean(stratNatRound1howOften-stratNatRound2howOften);


summary(stratNatRound1howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 31.05   67.92   80.66   76.97   90.87   99.12

summary(stratNatRound2howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 38.77   64.31   81.54   78.40   97.61   99.90 

t.test(stratNatRound1howOften,stratNatRound2howOften, paired= T); #no significant difference, p = .7

# Participants reported no significant change in difficulty when going from strategy to natural (although mean difference is in expected direction with frequency higher in natural)


# STRATEGY-STRATEGY
stratStratRound1howOften = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode==4];
stratStratRound2howOften = rcsSubLevelWide_clean$round2_instHowOften[rcsSubLevelWide_clean$condCode==4];
cond4freqdiff = mean(stratStratRound1howOften-stratStratRound2howOften);

summary(stratStratRound1howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 35.84   72.61   80.96   79.69   95.90   98.54 

summary(stratStratRound2howOften);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 25.78   60.35   79.79   74.36   94.14   99.02 

t.test(stratStratRound1howOften,stratStratRound2howOften, paired= T); #not significant difference, p = .15

# Participants reported following instructions less often in second round when repeating strategy but difference is not significant.

# Overall, participants reported following instructions between 70-80% of the time. When participants repeat conditions, frequency ratings are similar. When participants switch conditions, frequency ratings are higher for natural relative to strategy condition but this difference is only significant when going from natural to strategy.


# What about comparing strat vs nat in round 1 only:

natFirstFreq = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode %in% c(1,2)]; # people who do nat first

summary(natFirstFreq);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 18.36   64.84   76.07   74.99   91.02   99.71 

stratFirstFreq = rcsSubLevelWide_clean$round1_instHowOften[rcsSubLevelWide_clean$condCode %in% c(3,4)]; # people who do strat first

summary(stratFirstFreq);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 31.05   68.48   80.81   78.33   93.46   99.12 

t.test(natFirstFreq, stratFirstFreq); # ns, p= .32

# No significant difference between natural and strategy frequency ratings for people who do natural and strategy first.



pdf(file.path(config$path$directory, config$path$shlab_figures,'InstFrequencyRatingPlots.pdf'))
par(pty="s", mfrow= c(2,2),mar = c(5,4,5,2))
plot(natNatRound1howOften, natNatRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue", main=sprintf("Natural-Natural\nfrequency diff = %.2f",cond1freqdiff))
abline(a=0, b=1, col="grey")

plot(natStratRound1howOften, natStratRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green", main=sprintf("Natural-Strategy\nfrequency diff = %.2f",cond2freqdiff))
abline(a=0, b=1, col="grey")

plot(stratNatRound1howOften, stratNatRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red", main=sprintf("Strategy-Natural\nfrequency diff = %.2f",cond3freqdiff))
abline(a=0, b=1, col="grey")

plot(stratStratRound1howOften, stratStratRound2howOften, ylim=c(0,100), xlim=c(0,100), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple",  main=sprintf("Strategy-Strategy\nfrequency diff = %.2f",cond4freqdiff))
abline(a=0, b=1, col="grey")

mtext("Instruction Frequency Ratings", side = 3, line = -1, outer = TRUE)
dev.off()


```

#### Reaction time
```{r RT-mean-of-means}
# using mean reaction time with two versions - all trials vs remove fast trials

# RTmean = mean with all trials
# RTmeanClean = mean removing fast trials 

# First, ran this analysis removing trials faster than 1s. There were 7600 trials across both rounds with RTs less than 1s and all 124 participants had trials with fast RTs ranging from 1 trial to 176 trials across both rounds. There were more fast trials in round 2 relative to round 1 but the range of number of missed trials per participant in round 2 was smaller. There were 3291 fast trials in round 1 and all participants have at least one fast trial and 4309 fast trials in round 2 and 121/124 participants have at least one fast trial

# Next, we did fast trials as those with RTs <500ms. This way, we are looking at trials where participants really couldn't have responded meaningfully in that period of time (still possible to respond meaningfully with RT = 1s).

fastTrialIndround1 = which(rdmDFclean$RT<.5 & rdmDFclean$roundRDM==1); # fast trials in round 1
fastTrialIndround2 = which(rdmDFclean$RT<.5 & rdmDFclean$roundRDM==2); # fast trials in round 2

subIDsFastTrialsround1 = rdmDFclean$subIDnum[fastTrialIndround1]; # subid of fast trials in round 1
subIDsFastTrialsround2 = rdmDFclean$subIDnum[fastTrialIndround2]; # subid of fast trials in round 2

length(unique(subIDsFastTrialsround1)); # 14 fast trials in round 1 and all participants have at least one fast trial
length(unique(subIDsFastTrialsround2)); # 7 fast trials in round 2 and 121/124 participants have at least one fast trial
fastTriPerSubround1 = vector();
fastTriPerSubround2 = vector();
# 
#How many trials per participant were fast?:
for (s in 1:nSub) {
  fastTriPerSubround1[s]= sum(subIDsFastTrialsround1==as.numeric(subIDchar[s]))
  fastTriPerSubround2[s]= sum(subIDsFastTrialsround2==as.numeric(subIDchar[s]))
};

#summary(fastTriPerSubround1);
# RTs less than .5s:    
  #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 0.0000  0.0000  0.0000  0.1129  0.0000  4.0000

# RTs less than 1s:
   # Min. 1st Qu.  Median    Mean  3rd Qu.    Max. 
   # 1.00    7.00   20.50   26.54   40.00  101.00 

#summary(fastTriPerSubround2);
# RTs less than .5s:
  #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 0.00000 0.00000 0.00000 0.05645 0.00000 2.00000 

# RTs less than 1s:
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 0.00   14.00   28.50   34.75   54.00   84.00 




# ACROSS INSTRUCTION TYPE
# all trials
summary(rcsSubLevelLong_clean$RTmean[rcsSubLevelLong_clean$strategy==0]);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9459  1.1345  1.3046  1.3399  1.4845  2.3205 
summary(rcsSubLevelLong_clean$RTmean[rcsSubLevelLong_clean$strategy==1]);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.1834  1.3807  1.3889  1.5570  2.2312 

# remove fast trials
summary(rcsSubLevelLong_clean$RTmeanClean[rcsSubLevelLong_clean$strategy==0]);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9459  1.1345  1.3046  1.3403  1.4845  2.3205 
summary(rcsSubLevelLong_clean$RTmeanClean[rcsSubLevelLong_clean$strategy==1]);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.1834  1.3807  1.3896  1.5570  2.2312 

t.test(rcsSubLevelLong_clean$RTmean[rcsSubLevelLong_clean$strategy==0],rcsSubLevelLong_clean$RTmean[rcsSubLevelLong_clean$strategy==1]); #ns, p =.15
t.test(rcsSubLevelLong_clean$RTmeanClean[rcsSubLevelLong_clean$strategy==0],rcsSubLevelLong_clean$RTmeanClean[rcsSubLevelLong_clean$strategy==1]); #ns, p =.15

# Reaction times are not significantly different from each other across instruction type



# ACROSS ROUNDS
# all trials
summary(rcsSubLevelWide_clean$round1_RTmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.2170  1.4111  1.4171  1.6038  2.3205 

summary(rcsSubLevelWide_clean$round2_RTmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9488  1.1198  1.3155  1.3118  1.4146  2.2312 

# remove fast trials
summary(rcsSubLevelWide_clean$round1_RTmeanClean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.2170  1.4111  1.4177  1.6038  2.3205  

summary(rcsSubLevelWide_clean$round2_RTmeanClean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9488  1.1198  1.3155  1.3121  1.4146  2.2312 

t.test(rcsSubLevelWide_clean$round1_RTmean, rcsSubLevelWide_clean$round2_RTmean); # p = 0.001895
t.test(rcsSubLevelWide_clean$round1_RTmeanClean, rcsSubLevelWide_clean$round2_RTmeanClean); # p = 0.001823

# Reaction times significantly faster in round 2


# NATURAL-NATURAL
# All trials
natNatRound1rtmean = rcsSubLevelWide_clean$round1_RTmean[rcsSubLevelWide_clean$condCode==1];
natNatRound2rtmean = rcsSubLevelWide_clean$round2_RTmean[rcsSubLevelWide_clean$condCode==1];
cond1rtdiffmean = mean(natNatRound1rtmean- natNatRound2rtmean);

summary(natNatRound1rtmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9459  1.1830  1.2996  1.3499  1.5016  1.9204 

summary(natNatRound2rtmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9861  1.0695  1.1347  1.2174  1.3385  1.7769 

t.test(natNatRound1rtmean,natNatRound2rtmean, paired=T); # significant difference, p = .0001

# remove fast trials
natNatRound1rtmeanclean = rcsSubLevelWide_clean$round1_RTmeanClean[rcsSubLevelWide_clean$condCode==1];
natNatRound2rtmeanclean = rcsSubLevelWide_clean$round2_RTmeanClean[rcsSubLevelWide_clean$condCode==1];
cond1rtdiffmeanclean = mean(natNatRound1rtmeanclean- natNatRound2rtmeanclean);

summary(natNatRound1rtmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9459  1.1830  1.2996  1.3504  1.5016  1.9204 

summary(natNatRound2rtmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9861  1.0735  1.1347  1.2182  1.3469  1.7769 

t.test(natNatRound1rtmeanclean,natNatRound2rtmeanclean, paired=T); # significant difference, p = 0.0001261

# Participants are significantly faster in round 2 when doing natural both rounds.


# NATURAL-STRATEGY
# all trials
natStratRound1rtmean = rcsSubLevelWide_clean$round1_RTmean[rcsSubLevelWide_clean$condCode==2];
natStratRound2rtmean = rcsSubLevelWide_clean$round2_RTmean[rcsSubLevelWide_clean$condCode==2];
cond2rtdiffmean = mean(natStratRound1rtmean- natStratRound2rtmean);

summary(natStratRound1rtmean);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 1.008   1.235   1.418   1.471   1.625   2.320 
summary(natStratRound2rtmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9968  1.1516  1.3546  1.3779  1.4246  2.2312 

t.test(natStratRound1rtmean,natStratRound2rtmean, paired=T); # significant difference, p = .009

# remove fast trials
natStratRound1rtmeanclean = rcsSubLevelWide_clean$round1_RTmeanClean[rcsSubLevelWide_clean$condCode==2];
natStratRound2rtmeanclean = rcsSubLevelWide_clean$round2_RTmeanClean[rcsSubLevelWide_clean$condCode==2];
cond2rtdiffmeanclean = mean(natStratRound1rtmeanclean- natStratRound2rtmeanclean);

summary(natStratRound1rtmeanclean);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 1.012   1.235   1.418   1.472   1.625   2.320  
summary(natStratRound2rtmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9968  1.1516  1.3546  1.3784  1.4246  2.2312 

t.test(natStratRound1rtmeanclean,natStratRound2rtmeanclean, paired=T); # significant p = 0.009351

# Participants are significantly faster in round 2 when doing natural then strategy.


# STRATEGY-NATURAL
# All trials
stratNatRound1rtmean = rcsSubLevelWide_clean$round1_RTmean[rcsSubLevelWide_clean$condCode==3];
stratNatRound2rtmean = rcsSubLevelWide_clean$round2_RTmean[rcsSubLevelWide_clean$condCode==3];
cond3rtdiffmean = mean(stratNatRound1rtmean- stratNatRound2rtmean);

summary(stratNatRound1rtmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.2494  1.4350  1.4397  1.6361  1.9239 

summary(stratNatRound2rtmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9585  1.1504  1.3378  1.3208  1.4315  1.8003 

t.test(stratNatRound1rtmean,stratNatRound2rtmean, paired=T); # significant difference, p =.0005

# remove fast trials
stratNatRound1rtmeanclean = rcsSubLevelWide_clean$round1_RTmeanClean[rcsSubLevelWide_clean$condCode==3];
stratNatRound2rtmeanclean = rcsSubLevelWide_clean$round2_RTmeanClean[rcsSubLevelWide_clean$condCode==3];
cond3rtdiffmeanclean = mean(stratNatRound1rtmeanclean- stratNatRound2rtmeanclean);

summary(stratNatRound1rtmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.2494  1.4350  1.4408  1.6361  1.9239 

summary(stratNatRound2rtmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9585  1.1504  1.3378  1.3208  1.4315  1.8003 

t.test(stratNatRound1rtmeanclean,stratNatRound2rtmeanclean, paired=T); # significant difference, p =0.000453

# participants significantly faster in round 2 when doing strategy then natural

# STRATEGY-STRATEGY
# All trials
stratStratRound1rtmean = rcsSubLevelWide_clean$round1_RTmean[rcsSubLevelWide_clean$condCode==4];
stratStratRound2rtmean = rcsSubLevelWide_clean$round2_RTmean[rcsSubLevelWide_clean$condCode==4];
cond4rtdiffmean = mean(stratStratRound1rtmean- stratStratRound2rtmean);

summary(stratStratRound1rtmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9161  1.2033  1.4671  1.4071  1.5740  2.0312 
summary(stratStratRound2rtmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9488  1.1278  1.3546  1.3309  1.4426  2.1852 

t.test(stratStratRound1rtmean,stratStratRound2rtmean, paired=T); # not significant, p =.174

# Remove fast trials
stratStratRound1rtmeanclean = rcsSubLevelWide_clean$round1_RTmeanClean[rcsSubLevelWide_clean$condCode==4];
stratStratRound2rtmeanclean = rcsSubLevelWide_clean$round2_RTmeanClean[rcsSubLevelWide_clean$condCode==4];
cond4rtdiffmeanclean = mean(stratStratRound1rtmeanclean- stratStratRound2rtmeanclean);

summary(stratStratRound1rtmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9196  1.2033  1.4671  1.4081  1.5775  2.0312 
summary(stratStratRound2rtmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9488  1.1278  1.3546  1.3311  1.4426  2.1852 

t.test(stratStratRound1rtmeanclean,stratStratRound2rtmeanclean, paired=T); # not significant, p =.17

# Faster RTs in round 2 when repeating strategy, but differences are not significant

# Overall, people are faster in round 2, regardless of condition/instructions. Results are also consistent across fast trial thresholds (1s, .5s).


# What about comparing strat vs nat in round 1 only:
# ALL TRIALS
natFirstRTmean = rcsSubLevelWide_clean$round1_RTmean[rcsSubLevelWide_clean$condCode %in% c(1,2)]; # people who do nat first

summary(natFirstRTmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9459  1.2087  1.3528  1.4107  1.5822  2.3205 

stratFirstRTmean = rcsSubLevelWide_clean$round1_RTmean[rcsSubLevelWide_clean$condCode %in% c(3,4)]; # people who do strat first

summary(stratFirstRTmean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.2418  1.4595  1.4234  1.6064  2.0312 

t.test(natFirstRTmean, stratFirstRTmean); # ns, p= .7966

# No significant difference between natural and strategy RTs for people who do natural and strategy first.

# REMOVE FAST TRIALS
natFirstRTmeanclean = rcsSubLevelWide_clean$round1_RTmeanClean[rcsSubLevelWide_clean$condCode %in% c(1,2)]; # people who do nat first

summary(natFirstRTmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9459  1.2087  1.3528  1.4110  1.5822  2.3205

stratFirstRTmeanclean = rcsSubLevelWide_clean$round1_RTmeanClean[rcsSubLevelWide_clean$condCode %in% c(3,4)]; # people who do strat first

summary(stratFirstRTmeanclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8911  1.2418  1.4595  1.4245  1.6064  2.0312 

t.test(natFirstRTmeanclean, stratFirstRTmeanclean); # ns, p= 0.7845

# No significant difference between natural and strategy RTs for people who do natural and strategy first.



# Plot round 1 vs round 2 RT for each condition for all trials
# All trials
pdf(file.path(config$path$directory, config$path$shlab_figures,'meanRTAcrossRndsStratPlotsAlltrials.pdf'))
par(pty="s", mfrow= c(2,2), mar = c(5,4,5,2))
plot(natNatRound1rtmean, natNatRound2rtmean, ylim=c(0,3), xlim=c(0,3), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue", main=sprintf("Natural-Natural\n RT mean diff = %.2f",cond1rtdiffmean))
abline(a=0, b=1, col="grey")

plot(natStratRound1rtmean, natStratRound2rtmean, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green", main=sprintf("Natural-Strategy\n RT mean diff = %.2f",cond2rtdiffmean))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmean, stratStratRound2rtmean, ylim=c(0,3), xlim=c(0,3), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red", main=sprintf("Strategy-Natural\n RT mean diff = %.2f",cond3rtdiffmean))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmean, stratStratRound2rtmean, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple", main=sprintf("Strategy-Strategy\n RT mean diff = %.2f",cond4rtdiffmean))
abline(a=0, b=1, col="grey")

mtext("Average Reaction Time (all trials)", side = 3, line = - 1, outer = TRUE)
dev.off()



# Remove fast trials
pdf(file.path(config$path$directory, config$path$shlab_figures,'meanRTAcrossRndsStratPlotsNoFastTrials.pdf'))
par(pty="s", mfrow= c(2,2),mar = c(5,4,5,2))
plot(natNatRound1rtmeanclean, natNatRound2rtmeanclean, ylim=c(0,3), xlim=c(0,3), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue", main=sprintf("Natural-Natural\n RT mean diff = %.2f",cond1rtdiffmeanclean))
abline(a=0, b=1, col="grey")

plot(natStratRound1rtmeanclean, natStratRound2rtmeanclean, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green", main=sprintf("Natural-Strategy\n RT mean diff = %.2f",cond2rtdiffmeanclean))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmeanclean, stratStratRound2rtmeanclean, ylim=c(0,3), xlim=c(0,3), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red", main=sprintf("Strategy-Natural\n RT mean diff = %.2f",cond3rtdiffmeanclean))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmeanclean, stratStratRound2rtmeanclean, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple", main=sprintf("Strategy-Strategy\n RT mean diff = %.2f",cond4rtdiffmeanclean))
abline(a=0, b=1, col="grey")

mtext("Average Reaction Time (removed fast trials)", side = 3, line = - 1, outer = TRUE)
dev.off()


# Effect of speeding across rounds might be practice effects within round 1. Plot mean RT on each trial across round 1 and round 2



round1RTmeanxtri = rdmDFclean[rdmDFclean$roundRDM==1,] %>% group_by(trial) %>%
   summarise(mean=mean(RT)); # get the mean for each trial

round2RTmeanxtri = rdmDFclean[rdmDFclean$roundRDM==2,] %>% group_by(trial) %>%
  summarise(mean=mean(RT)); # get the mean for each trial

# plot RT across round

png(filename = file.path(config$path$directory, config$path$shlab_figures, "meanRTacrossrounds.png"))
par(mfrow=c(1,2), pty="s")
plot(round1RTmeanxtri$mean, ylim=c(1,2), pch=16, col = "blue", main = "Mean RT round 1", ylab="RT(sec)", xlab="trial", axes=F)
axis(1, at = c(1,65,131))
axis(2, at = c(1, 1.5,2))
plot(round2RTmeanxtri$mean, ylim=c(1,2), pch = 16, col = "red", main = "Mean RT round 2", ylab=" ", xlab="trial", axes=F)
axis(1, at = c(1,65,131))
axis(2, at = c(1, 1.5,2))
# Plot shows a big decrease in RT in round 1 and a slight decrease across round 2 but the biggest change is in round 1.
dev.off()

```


```{r RT-mean-of-medians}
# using MEANS OF THE MEDIAN reaction timse with two versions - all trials vs remove fast trials

# RTmedian = median with all trials
# RTmedianClean = mean removing fast trials (<1s) 


#summary(fastTriPerSubround1);
# fast trials <1s:
   # Min. 1st Qu.  Median    Mean  3rd Qu.    Max. 
   # 1.00    7.00   20.50   26.54   40.00  101.00 

# fast trials <.5s:
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.0000  0.0000  0.0000  0.1129  0.0000  4.0000 


#summary(fastTriPerSubround2);
# fast trials <1s
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 0.00   14.00   28.50   34.75   54.00   84.00 

# fast trials <.5s
  #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 0.00000 0.00000 0.00000 0.05645 0.00000 2.00000




# ACROSS INSTRUCTION TYPE
# all trials
summary(rcsSubLevelLong_clean$RTmedian[rcsSubLevelLong_clean$strategy==0]);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8944  1.0831  1.1989  1.2481  1.3834  2.2637 

summary(rcsSubLevelLong_clean$RTmedian[rcsSubLevelLong_clean$strategy==1]);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1291  1.2684  1.2994  1.4408  2.1901 


# remove fast trials
summary(rcsSubLevelLong_clean$RTmedianClean[rcsSubLevelLong_clean$strategy==0]);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8944  1.0831  1.1989  1.2482  1.3834  2.2637

summary(rcsSubLevelLong_clean$RTmedianClean[rcsSubLevelLong_clean$strategy==1]);
 #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1291  1.2684  1.2998  1.4408  2.1901 


t.test(rcsSubLevelLong_clean$RTmedian[rcsSubLevelLong_clean$strategy==0],rcsSubLevelLong_clean$RTmedian[rcsSubLevelLong_clean$strategy==1]); #p=.1
t.test(rcsSubLevelLong_clean$RTmedianClean[rcsSubLevelLong_clean$strategy==0],rcsSubLevelLong_clean$RTmedianClean[rcsSubLevelLong_clean$strategy==1]); #p=.1

# Reaction times are not significantly different from each other across instruction type but direction is that people are slower in strategy



# ACROSS ROUNDS
# all trials
summary(rcsSubLevelWide_clean$round1_RTmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1479  1.3061  1.3209  1.4776  2.2637

summary(rcsSubLevelWide_clean$round2_RTmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9176  1.0485  1.2050  1.2266  1.3312  2.1901 

# remove fast trials
summary(rcsSubLevelWide_clean$round1_RTmedianClean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1479  1.3061  1.3212  1.4776  2.2637 

summary(rcsSubLevelWide_clean$round2_RTmedianClean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9183  1.0485  1.2050  1.2268  1.3312  2.1901 

t.test(rcsSubLevelWide_clean$round1_RTmedian, rcsSubLevelWide_clean$round2_RTmedian); # p = .003
t.test(rcsSubLevelWide_clean$round1_RTmedianClean, rcsSubLevelWide_clean$round2_RTmedianClean); # p = .003

# Reaction times significantly faster in round 2 relative to round 1


# NATURAL-NATURAL
# All trials
natNatRound1rtmedian = rcsSubLevelWide_clean$round1_RTmedian[rcsSubLevelWide_clean$condCode==1];
natNatRound2rtmedian = rcsSubLevelWide_clean$round2_RTmedian[rcsSubLevelWide_clean$condCode==1];
cond1rtdiffmedian = mean(natNatRound1rtmedian- natNatRound2rtmedian);

summary(natNatRound1rtmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8944  1.1328  1.1876  1.2538  1.4286  1.7661 

summary(natNatRound2rtmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9634  1.0189  1.0903  1.1465  1.2487  1.6210

t.test(natNatRound1rtmedian,natNatRound2rtmedian, paired=T); # significant difference, p = .0003

# remove fast trials
natNatRound1rtmedianclean= rcsSubLevelWide_clean$round1_RTmedianClean[rcsSubLevelWide_clean$condCode==1];
natNatRound2rtmedianclean = rcsSubLevelWide_clean$round2_RTmedianClean[rcsSubLevelWide_clean$condCode==1];
cond1rtdiffmedianclean = mean(natNatRound1rtmedianclean- natNatRound2rtmedianclean);

summary(natNatRound1rtmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8944  1.1328  1.1876  1.2540  1.4286  1.7661 

summary(natNatRound2rtmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9634  1.0189  1.0903  1.1466  1.2487  1.6210 

t.test(natNatRound1rtmedianclean,natNatRound2rtmedianclean, paired=T); # trending difference, p = 0.0003205

# Participants are faster in round 2 when repeating natural condition


# NATURAL-STRATEGY
# all trials
natStratRound1rtmedian = rcsSubLevelWide_clean$round1_RTmedian[rcsSubLevelWide_clean$condCode==2];
natStratRound2rtmedian = rcsSubLevelWide_clean$round2_RTmedian[rcsSubLevelWide_clean$condCode==2];
cond2rtdiffmedian = mean(natStratRound1rtmedian- natStratRound2rtmedian);

summary(natStratRound1rtmedian);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 0.961   1.167   1.302   1.368   1.482   2.264 
summary(natStratRound2rtmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9176  1.0782  1.2473  1.2804  1.3047  2.1901

t.test(natStratRound1rtmedian,natStratRound2rtmedian, paired=T); # significant difference, p = .005

# remove fast trials
natStratRound1rtmedianclean = rcsSubLevelWide_clean$round1_RTmedianClean[rcsSubLevelWide_clean$condCode==2];
natStratRound2rtmedianclean = rcsSubLevelWide_clean$round2_RTmedianClean[rcsSubLevelWide_clean$condCode==2];
cond2rtdiffmedianclean = mean(natStratRound1rtmedianclean- natStratRound2rtmedianclean);

summary(natStratRound1rtmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9613  1.1668  1.3015  1.3680  1.4822  2.2637 
summary(natStratRound2rtmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9189  1.0782  1.2473  1.2804  1.3047  2.1901 

t.test(natStratRound1rtmedianclean,natStratRound2rtmedianclean, paired=T); # trending p =0.004802

# Participants are faster in round 2 relative to round 1


# STRATEGY-NATURAL
# All trials
stratNatRound1rtmedian = rcsSubLevelWide_clean$round1_RTmedian[rcsSubLevelWide_clean$condCode==3];
stratNatRound2rtmedian = rcsSubLevelWide_clean$round2_RTmedian[rcsSubLevelWide_clean$condCode==3];
cond3rtdiffmedian = mean(stratNatRound1rtmedian- stratNatRound2rtmedian);

summary(stratNatRound1rtmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1792  1.3711  1.3480  1.5731  1.7637 

summary(stratNatRound2rtmedian);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 0.926   1.089   1.208   1.224   1.344   1.590 

t.test(stratNatRound1rtmedian,stratNatRound2rtmedian, paired=T); # significant difference, p =3.72x10-5

# remove fast trials
stratNatRound1rtmedianclean = rcsSubLevelWide_clean$round1_RTmedianClean[rcsSubLevelWide_clean$condCode==3];
stratNatRound2rtmedianclean = rcsSubLevelWide_clean$round2_RTmedianClean[rcsSubLevelWide_clean$condCode==3];
cond3rtdiffmedianclean = mean(stratNatRound1rtmedianclean- stratNatRound2rtmedianclean);

summary(stratNatRound1rtmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1796  1.3711  1.3485  1.5731  1.7637 

summary(stratNatRound2rtmedianclean);
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 0.926   1.089   1.208   1.224   1.344   1.590 

t.test(stratNatRound1rtmedianclean,stratNatRound2rtmedianclean, paired=T); # significant difference, p =3.562e-05

# participants significantly faster in round 2 when doing strategy then natural

# STRATEGY-STRATEGY
# All trials
stratStratRound1rtmedian = rcsSubLevelWide_clean$round1_RTmedian[rcsSubLevelWide_clean$condCode==4];
stratStratRound2rtmedian = rcsSubLevelWide_clean$round2_RTmedian[rcsSubLevelWide_clean$condCode==4];
cond4rtdiffmedian = mean(stratStratRound1rtmedian- stratStratRound2rtmedian);

summary(stratStratRound1rtmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8704  1.1459  1.3738  1.3137  1.4766  1.9314
summary(stratStratRound2rtmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9183  1.0485  1.2593  1.2557  1.3385  2.1575 

t.test(stratStratRound1rtmedian,stratStratRound2rtmedian, paired=T); # not significant, p =.289

# Remove fast trials
stratStratRound1rtmedianclean = rcsSubLevelWide_clean$round1_RTmedianClean[rcsSubLevelWide_clean$condCode==4];
stratStratRound2rtmedianclean = rcsSubLevelWide_clean$round2_RTmedianClean[rcsSubLevelWide_clean$condCode==4];
cond4rtdiffmedianclean = mean(stratStratRound1rtmedianclean- stratStratRound2rtmedianclean);

summary(stratStratRound1rtmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8716  1.1459  1.3738  1.3144  1.4766  1.9314 
summary(stratStratRound2rtmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.9183  1.0485  1.2593  1.2560  1.3385  2.1575 

t.test(stratStratRound1rtmedianclean,stratStratRound2rtmedianclean, paired=T); # not significant, p =.28

# Faster RTs in round 2 when repeating strategy, but differences are not significant

# Overall, people tend to be faster in round 2, regardless of condition/instructions.


# What about comparing strat vs nat in round 1 only:
# ALL TRIALS
natFirstRTmedian = rcsSubLevelWide_clean$round1_RTmedian[rcsSubLevelWide_clean$condCode %in% c(1,2)]; # people who do nat first

summary(natFirstRTmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8944  1.1419  1.2422  1.3109  1.4607  2.2637 

stratFirstRTmedian = rcsSubLevelWide_clean$round1_RTmedian[rcsSubLevelWide_clean$condCode %in% c(3,4)]; # people who do strat first

summary(stratFirstRTmedian);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1609  1.3726  1.3309  1.4840  1.9314 

t.test(natFirstRTmedian, stratFirstRTmedian); # ns, p= .6621

# No significant difference between natural and strategy RTs for people who do natural and strategy first.

# REMOVE FAST TRIALS
natFirstRTmedianclean = rcsSubLevelWide_clean$round1_RTmedianClean[rcsSubLevelWide_clean$condCode %in% c(1,2)]; # people who do nat first

summary(natFirstRTmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8944  1.1419  1.2422  1.3110  1.4607  2.2637  

stratFirstRTmedianclean = rcsSubLevelWide_clean$round1_RTmedianClean[rcsSubLevelWide_clean$condCode %in% c(3,4)]; # people who do strat first

summary(stratFirstRTmedianclean);
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # 0.8293  1.1609  1.3726  1.3314  1.4840  1.9314 

t.test(natFirstRTmedianclean, stratFirstRTmedianclean); # ns, p= 0.6548

# No significant difference between natural and strategy RTs for people who do natural and strategy first.

# Plot round 1 vs round 2 RT for each condition for all trials
# All trials
pdf(file.path(config$path$directory, config$path$shlab_figures,'medianRTAcrossRndsStratPlotsAlltrials.pdf'))
par(pty="s", mfrow= c(2,2), mar = c(5,4,5,2))
plot(natNatRound1rtmedian, natNatRound2rtmedian, ylim=c(0,3), xlim=c(0,3), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue", main=sprintf("Natural-Natural\n RT mean of median diff = %.2f",cond1rtdiffmedian))
abline(a=0, b=1, col="grey")

plot(natStratRound1rtmedian, natStratRound2rtmedian, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green", main=sprintf("Natural-Strategy\n RT mean of median diff = %.2f",cond2rtdiffmedian))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmedian, stratStratRound2rtmedian, ylim=c(0,3), xlim=c(0,3), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red", main=sprintf("Strategy-Natural\n RT mean of median diff = %.2f",cond3rtdiffmedian))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmedian, stratStratRound2rtmedian, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple", main=sprintf("Strategy-Strategy\n RT mean of median diff = %.2f",cond4rtdiffmedian))
abline(a=0, b=1, col="grey")

mtext("Mean of median Reaction Time (all trials)", side = 3, line = -1, outer = TRUE)
dev.off()



# Remove fast trials
pdf(file.path(config$path$directory, config$path$shlab_figures,'medianRTAcrossRndsStratPlotsNoFastTrials.pdf'))
par(pty="s", mfrow= c(2,2), mar=c(5,4,5,2))
plot(natNatRound1rtmedianclean, natNatRound2rtmedianclean, ylim=c(0,3), xlim=c(0,3), ylab="Act natural Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="blue", main=sprintf("Natural-Natural\n RT mean of median diff = %.2f",cond1rtdiffmedianclean))
abline(a=0, b=1, col="grey")

plot(natStratRound1rtmedianclean, natStratRound2rtmedianclean, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Act natural Round 1", pch=16, cex = 1.5, col="green", main=sprintf("Natural-Strategy\n RT mean of median diff = %.2f",cond2rtdiffmedianclean))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmedianclean, stratStratRound2rtmedianclean, ylim=c(0,3), xlim=c(0,3), ylab="Act Natural Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="red", main=sprintf("Strategy-Natural\n RT mean of median diff = %.2f",cond3rtdiffmedianclean))
abline(a=0, b=1, col="grey")

plot(stratStratRound1rtmedianclean, stratStratRound2rtmedianclean, ylim=c(0,3), xlim=c(0,3), ylab="Strategy Round 2", xlab="Strategy Round 1", pch=16, cex = 1.5, col="purple", main=sprintf("Strategy-Strategy\n RT mean of median diff = %.2f",cond4rtdiffmedianclean))
abline(a=0, b=1, col="grey")

mtext("Mean of median Reaction Time (removed fast trials)", side = 3, line = -1, outer = TRUE)
dev.off()



```

### In all comparisons, both mean of mean and mean of median reaction times are faster in round 2 relative to round 1, regardless of strategy condition. 


```{r motivation-and-round-independence}
# How motivated were people?
rcsSubLevelWide_clean$motivationNumeric = as.numeric(rcsSubLevelWide_clean$motivation)
summary(rcsSubLevelWide_clean$motivationNumeric); # mean = 5.17; median = 5; min = 2; max = 7 (scale was 1-7)
sd(rcsSubLevelWide_clean$motivationNumeric); # 1.12

# are there any differences in motivation across conditions (not that we'd expect this to happen on purpose but should check)
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==1]); # mean = ~5
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==2]); # mean = 5.26
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==3]); # mean = 5.34
summary(rcsSubLevelWide_clean$motivationNumeric[rcsSubLevelWide_clean$condCode==4]); # mean = 5.1

pdf(file.path(config$path$directory, config$path$shlab_figures,'MotivationHist.pdf'))
hist(rcsSubLevelWide_clean$motivationNumeric, breaks=seq(from=0.5, to = 7.5, by = 1), main= "Motivation ratings (n=124)\n mean(sd) = 5.17(1.12), range = 2-7", xlab="motivation (1-7)")#, #xlim=c(1,7))
dev.off();

# did the rounds feel independent to people? and did this depend on condition?

rcsSubLevelWide_clean$rdmRoundsIndepNumeric = as.numeric(rcsSubLevelWide_clean$rdmRoundsIndep)
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric); # mean= 4.99; median = 5; range = 1-7 (on a scale from 1-7)
sd(rcsSubLevelWide_clean$rdmRoundsIndepNumeric); # 1.553888

summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==1]); # mean = 4.48
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==2]); # mean = 5.355
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==3]); # mean = 4.871
summary(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==4]); # mean = 5.258

pdf(file.path(config$path$directory, config$path$shlab_figures,'RDMroundIndepHist.pdf'))
hist(rcsSubLevelWide_clean$rdmRoundsIndepNumeric, breaks=seq(from=0.5, to = 7.5, by = 1), main= "RDM round independence (n=124)\nmean(sd) = 5(1.55); range = 1-7", xlab="independence ratings (1-7)") 
dev.off()

# look at hists by condition:
pdf(file.path(config$path$directory, config$path$shlab_figures,'RDMroundIndepByCondition.pdf'))
par(mfrow=c(2,2), mar=c(5,4,5,2))
hist(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==1], breaks=seq(from=0.5, to = 7.5, by = 1), main="Natural-Natural\nmean=4.48", xlab="independence ratings (1-7)"); 
hist(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==2], breaks=seq(from=0.5, to = 7.5, by = 1), main= "Natural-Strategy\nmean=5.36", xlab="independence ratings (1-7)")
hist(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==3], breaks=seq(from=0.5, to = 7.5, by = 1), main= "Strategy-Natural\nmean=4.87", xlab="independence ratings (1-7)")
hist(rcsSubLevelWide_clean$rdmRoundsIndepNumeric[rcsSubLevelWide_clean$condCode==4], breaks=seq(from=0.5, to = 7.5, by = 1), main= "Strategy-Strategy\nmean=5.26", xlab="independence ratings (1-7)")
mtext("RDM round independence by condition",side = 3, line = -1, outer = TRUE)
dev.off()

```


```{r complex-span-tasks-ERQ}
 summary(rcsSubLevelWide_clean$ospan);# range = 0-25; mean =14.53; median = 13
 summary(rcsSubLevelWide_clean$symspan); # range = 0-14; mean = 7.657; median = 9
 summary(rcsSubLevelWide_clean$compositeSpanScore); # range = 0.06 - 1; median = .5743, mean = .5720

# are ospan and symspan correlated?
cor.test(rcsSubLevelWide_clean$ospan, rcsSubLevelWide_clean$symspan); # yes - r = .26, p = .009; spearman = rho = .23, p = .02.

# Foster et al correlation is .53 with n=589

pdf(file.path(config$path$directory, config$path$shlab_figures,'compositeSpanScoreHist.pdf'))
hist(rcsSubLevelWide_clean$compositeSpanScore, breaks=seq(from=-0.05, to = 1.05, by = .1), xlab="Composite Span Score", main="Composite Span Scores (n=124)\nmean = .57, range = .06-1", ylim=c(0,25))
dev.off()

# are complex span and motivation correlated?
cor.test(rcsSubLevelWide_clean$compositeSpanScore, rcsSubLevelWide_clean$motivationNumeric); 
# slightly negative but not significant. This is good evidence that composite span is mostly capacity rather than motivation (we can't totally rule this out)

# ERQ
 summary(rcsSubLevelWide_clean$ERQreapp); # range = 14-42; mean = 29.69; median =30
 summary(rcsSubLevelWide_clean$ERQsupp); # range = 4 - 27; mean = 14.89; median = 15
 
pdf(file.path(config$path$directory, config$path$shlab_figures,'ERQHist.pdf'))
par(mfrow=c(2,1))
hist(rcsSubLevelWide_clean$ERQreapp, breaks=seq(from=13.5, to = 42.5, by = 1), xlab="ERQ Reappraisal Score", main="ERQ Reappraisal (n=122)\nmean = 29.7, range = 14-42", ylim=c(0,15), axes=F)
axis(1, at = seq(14,42, by=2))
axis(2)
hist(rcsSubLevelWide_clean$ERQsupp, breaks=seq(from=3.5, to = 27.5, by = 1),  xlab="ERQ Suppression Score", main="ERQ Suppression (n=122)\nmean = 14.9, range = 4-27", ylim=c(0,15), axes=F)
axis(1, at = seq(4, 28, by=2))
axis(2)
dev.off()

# Is suppression correlated with reappraisal?
cor.test(rcsSubLevelWide_clean$ERQreapp, rcsSubLevelWide_clean$ERQsupp, paired=T); # p =.4

# Is ERQ related to composite span?
erqCompSpan = lm(rcsSubLevelWide_clean$compositeSpanScore~rcsSubLevelWide_clean$ERQreapp + rcsSubLevelWide_clean$ERQsupp, data=rcsSubLevelWide_clean);
summary(erqCompSpan); # no relationship between suppression or reappraisal and composite span score; mixed effects doesn't work here.

erqMotivation = lm(rcsSubLevelWide_clean$motivationNumeric~rcsSubLevelWide_clean$ERQreapp + rcsSubLevelWide_clean$ERQsupp, data=rcsSubLevelWide_clean);
summary(erqMotivation);
# relationship between suppression and motivation (lower motivation associated with higher suppression scores)
# no relationship between motivation and reappraisal


# Are instruction difficulty ratings related to ERQ, motivation, or complex span?
# scale motivation and ERQ and instr. freq and difficulty
rcsSubLevelLong_clean$ERQreappSC = rcsSubLevelLong_clean$ERQreapp/max(rcsSubLevelLong_clean$ERQreapp, na.rm=T)
rcsSubLevelLong_clean$ERQsuppSC = rcsSubLevelLong_clean$ERQsupp/max(rcsSubLevelLong_clean$ERQsupp, na.rm=T)
rcsSubLevelLong_clean$motivationSC =as.numeric(rcsSubLevelLong_clean$motivation)/as.numeric(max(rcsSubLevelLong_clean$motivation, na.rm=T))
rcsSubLevelLong_clean$instDifficultSC = rcsSubLevelLong_clean$instDifficult/max(rcsSubLevelLong_clean$instDifficult, na.rm=T);
rcsSubLevelLong_clean$instHowOftenSC = rcsSubLevelLong_clean$instHowOften/max(rcsSubLevelLong_clean$instHowOften, na.rm=T);

instDiff_SpanERQMotiv = lmer(instDifficultSC ~ 1+ compositeSpanScore + ERQreappSC +  ERQsuppSC + motivationSC + (1|subID), data=rcsSubLevelLong_clean);
summary(instDiff_SpanERQMotiv); # no main effects, intercept is significant, lots of variability amongst participants in starting point.

# Are instruction frequency related to ERQ, motivation, or complex span?
instFreq_SpanERQMotiv = lmer(instHowOftenSC ~ 1+ compositeSpanScore + ERQreappSC +  ERQsuppSC + motivationSC + (1|subID), data=rcsSubLevelLong_clean);
summary(instFreq_SpanERQMotiv); # no main effects, intercept is significant, lots of variability in where participants start.


# Does the effect of ERQ, motivation and complex span depend on strategy?
# recode strategy
rcsSubLevelLong_clean$strategyRecode = rcsSubLevelLong_clean$strategy;
rcsSubLevelLong_clean$strategyRecode[rcsSubLevelLong_clean$strategyRecode==0] = -1; # change 0s to -1


instDiff_SpanERQMotiv_strategy = lmer(instDifficultSC ~ 1+ compositeSpanScore*strategyRecode + ERQreappSC*strategyRecode +  ERQsuppSC*strategyRecode + motivationSC*strategyRecode + (1|subID), data=rcsSubLevelLong_clean);
summary(instDiff_SpanERQMotiv_strategy); # no main effects, intercept is significant

instFreq_SpanERQMotiv_strategy = lmer(instHowOftenSC ~ 1+ compositeSpanScore*strategyRecode + ERQreappSC*strategyRecode +  ERQsuppSC*strategyRecode + motivationSC*strategyRecode + (1|subID), data=rcsSubLevelLong_clean);
summary(instFreq_SpanERQMotiv_strategy); # main effect of strategy only; intxn with strategy and motivation
# Positive effect of strategy means that instruction frequency ratings increase in strategy condition
# Negative interaction between strategy and motivation:
stratBeta =  0.20730;
motivBeta = -0.04806;
stratMotivBeta = -0.25232;
motivationValues = rep(seq(from = .29, to = 1, length.out=4), times = 2)
stratValues = rep(c(-1,1), each = 4)

instFreq_stratMotivIntxn = (stratBeta*stratValues) + (motivBeta*motivationValues) + (stratMotivBeta*stratValues*motivationValues);

plot(instFreq_stratMotivIntxn[1:4], type="l", lwd=4, col="goldenrod1", ylim=c(-.15, .15), xlab="motivation rating", ylab="% change in instruction Frequency", main = "Instruction Frequency Ratings:\nmotivation x instruction type", axes= F);
points(instFreq_stratMotivIntxn[5:8], type="l", lwd=4, col="tomato1");
axis(1, at = c(1,4), labels=c(2,7))
axis(2, at = c(-.15,0,.15), labels=c(-15,0,15))
# this is weird but it seems like the biggest impact on frequency ratings is low motivation - when motivation is low, frequency ratings are higher in strategy and lower in act natural(?). When movitation is high, there is no effect on frequency in natural condition and a slight negative effect in the strategy condition.


# What if we account for round and strategy for instruction ratings and difficulty
# could use condCode to account for round and strategy = 1,2,3,4
instDiff_SpanERQMotiv_strategyRound = lmer(instDifficultSC ~ 1+ compositeSpanScore*condCode + ERQreapp*condCode +  ERQsupp*condCode+ motivationSC*condCode + (1|subID), data= rcsSubLevelLong_clean);
summary(instDiff_SpanERQMotiv_strategyRound); # no main effect of condition code

instFreq_SpanERQMotiv_strategyRound = lmer(instHowOftenSC ~ 1+ compositeSpanScore*condCode + ERQreapp*condCode +  ERQsupp*condCode+ motivationSC*condCode + (1|subID), data= rcsSubLevelLong_clean);
summary(instFreq_SpanERQMotiv_strategyRound); # no main effect of condition code
# only motivation is related to condCode with an interaction

condCodeVals = rep(c(1,2,3,4), each =4);
motivationValues = rep(motivationValues, times = 2);
condCodeBeta = 0.119517;
motivBeta =  0.412336;
condMotivBeta = -0.184793;

freqRatingCondCodeMotiv = condCodeBeta*condCodeVals + motivBeta*motivationValues + condMotivBeta*motivationValues*condCodeVals

plot(freqRatingCondCodeMotiv[1:4], type="l", lwd=4, col="blue", ylab="% change in frequency ratings", xlab="motivation ratings", ylim=c(0, .4));
lines(freqRatingCondCodeMotiv[5:8], type="l", lwd=4, col="green")
lines(freqRatingCondCodeMotiv[9:12], type="l", lwd=4, col="red")
lines(freqRatingCondCodeMotiv[13:16], type="l", lwd=4, col="purple")

legend("bottomright", legend=c("Nat-Nat", "Nat-Strat", "Strat-Nat", "Strat-Strat"), lty=1, bty="n", col=c("blue","green", "red", "purple"), cex=1, lwd=3);

# When accounting for both round and strategy:
# when people repeat natural, motivation increases how often they follow instructions
# when people switch from natural to strategy, motivation doesn't really change how often people follow instructions
# when people switch from strategy to natural, motivation has a negative effect on how often people follow instructions, and same but more negative for people who repeat strategy
# This is tricky to understand because the condition codes are 1,2,3,4 and what that means for this figure is unclear.


# Lets just look at round 1 and round 2 data separately
# need to create round variable 
rcsSubLevelLong_clean$roundRDM = rep(c(-1,1), times = nSub); # round 1 = -1 and round 2 = 1

# inst difficulty in round 1
instDiff_SpanERQMotiv_strategy_round1data = lm(instDifficultSC ~ 1+ compositeSpanScore*strategyRecode + ERQreapp*strategyRecode +  ERQsupp*strategyRecode+ motivationSC*strategyRecode, data= rcsSubLevelLong_clean[rcsSubLevelLong_clean$roundRDM==-1,]);
summary(instDiff_SpanERQMotiv_strategy_round1data); 
# negative effect of ERQ suppression in round 1 (lower ERQ sup, higher difficulty ratings?), but no interaction with strategy

# inst difficulty in round 2
instDiff_SpanERQMotiv_strategy_round2data = lm(instDifficultSC ~ 1+ compositeSpanScore*strategyRecode + ERQreapp*strategyRecode +  ERQsupp*strategyRecode+ motivationSC*strategyRecode, data= rcsSubLevelLong_clean[rcsSubLevelLong_clean$roundRDM==1,]);
summary(instDiff_SpanERQMotiv_strategy_round2data); 
# trending interaction between strategy and motivation, p = .08

# inst frequency in round 1
instFreq_SpanERQMotiv_strategy_round1data = lm(instHowOftenSC ~ 1+ compositeSpanScore*strategyRecode + ERQreapp*strategyRecode +  ERQsupp*strategyRecode+ motivationSC*strategyRecode, data= rcsSubLevelLong_clean[rcsSubLevelLong_clean$roundRDM==-1,]);
summary(instFreq_SpanERQMotiv_strategy_round1data); 
# trending main effect of ERQ suppression (p =.07)
# interaction between ERQreapp and strategy, p = .04
# negative interaction between strategy and motivation, p =.047

instFreq_SpanERQMotiv_strategy_round2data = lm(instHowOftenSC ~ 1+ compositeSpanScore*strategyRecode + ERQreapp*strategyRecode +  ERQsupp*strategyRecode+ motivationSC*strategyRecode, data= rcsSubLevelLong_clean[rcsSubLevelLong_clean$roundRDM==1,]);
summary(instFreq_SpanERQMotiv_strategy_round2data); 
# main effect of strategy (positive and p = .02); freq ratings higher in strategy but only in round 2
# trending interaction between strategy and ERQ suppression, p = .08
# negative interaction between strategy and motivation, p =.02

# the consistent effect across rounds is that there is an interaction between strategy and motivation on inst freq

# ROUND 1: MOTIVATION X STRATEGY ON FREQUENCY
motivationValues = rep(seq(from = .29, to = 1, length.out=4), times = 2)
stratValues = rep(c(-1,1), each = 4)
stratBetaRound1 = 0.0372164;
motivBetaRound1 =  -0.1243150;
stratMotivBetaRound1 = -0.2260434;

instFreq_stratMotivIntxn_round1 = (stratBetaRound1*stratValues) + (motivBetaRound1*motivationValues) + (stratMotivBetaRound1*stratValues*motivationValues);

# ROUND 2: MOTIVATION X STRATEGY ON FREQUENCY
stratBetaRound2 =  0.4020089;
motivBetaRound2 =  0.0043657;
stratMotivBetaRound2 = -0.2817538;

instFreq_stratMotivIntxn_round2 = (stratBetaRound2*stratValues) + (motivBetaRound2*motivationValues) + (stratMotivBetaRound2*stratValues*motivationValues);


par(mfrow=c(1,2), mar=c(4,2,5,2))
plot(instFreq_stratMotivIntxn_round1[1:4], type="l", lwd=4, col="goldenrod1", ylim=c(-.4, .4), xlab="motivation rating", ylab="% change in instruction Frequency", main = "ROUND 1:", axes= F);
points(instFreq_stratMotivIntxn_round1[5:8], type="l", lwd=4, col="tomato1");
axis(1, at = c(1,4), labels=c(2,7))
axis(2, at = c(-.4,0,.4))
legend("topright", legend=c("Natural", "Strategy"), lty=1, bty="n", col=c("goldenrod1", "tomato1"), cex=1, lwd=3);
plot(instFreq_stratMotivIntxn_round2[1:4], type="l", lwd=4, col="goldenrod1", ylim=c(-.4, .4), xlab="motivation rating", ylab="", main = "ROUND 2", axes= F);
points(instFreq_stratMotivIntxn_round2[5:8], type="l", lwd=4, col="tomato1");
axis(1, at = c(1,4), labels=c(2,7))
axis(2, at = c(-.4,0,.4))

mtext("Frequency ratings: motivation x strategy", side =3, line =-1, outer=TRUE)

# Across rounds, the effect of motivation on frequency instruction is negative for strategy condition and is positive for natural condition. So higher motivation is good for natural but bad for following strategy instructions. This seems to be the takeaway.

```


### Generalized linear mixed effects models
#### Trial-level
##### There are a couple of possibilities here. Account for round and strategy in trial-level models or leave out to help detect interactions in subsequent (context models)
```{r trial-level-glmer}
# For our trial-level models, we tested two versions. Both included gain, safe and ev on trial t, but the second one included strategy and round. 
# We are going to move forward with model that accounts for strategy and round but will include the results from the basic model below.
# Because we find an interaction between strategy and round, we will account for both strategy and round in the contextual models as well.


# # model with gain, safe and EV level (magnitude)
# model1_trialLev =glmer(choice ~ 1 +  gainScaled + safeScaled + evLevScaled + (1|subID), data=rdmDFclean , family = "binomial")
# summary(model1_trialLev)
# # risk-taking increases as gain amounts increases and decreases as safe values increase and magnitude increases


# model with round and strategy (and interaction)
model2_trialLevRoundStrat= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + (1|subID), data=rdmDFclean , family = "binomial")
summary(model2_trialLevRoundStrat)
# gain, safe, EV as above
# no main effect of round 
# main effect of strategy (more risk-taking in strategy condition)
# positive interaction between round and strategy 
  # this interaction means that the effect of each condition is stronger in round 2 (i.e. more risk-taking for strategy, esp in round 2 and less risk-taking in natural, esp round 2)

# Notes: because there is an interaction between round and strategy, we need to include both or neither.


```


```{r trial-level-model-NOroundorstrategy, eval=FALSE, include=FALSE}
# these results are using trial-level model with just gain, safe and ev (no round or strategy)
# then including both round and strategy in the contextual models

# # model with gain, safe and EV level (magnitude)
model1_trialLev =glmer(choice ~ 1 +  gainScaled + safeScaled + evLevScaled + (1|subID), data=rdmDFclean , family = "binomial");
summary(model1_trialLev);
# risk-taking increases as gain amounts increases and decreases as safe values increase and magnitude increases

# save predicted values
rdmDFclean$predModel1= predict(model1_trialLev,type="link"); 

# using predicted values from model 1 above (gain, safe, ev)
model_roundStrat_pred1= glm(choice ~ 0 + roundRecode*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_roundStrat_pred1)
# strategy is significant and positive, 
# positive interaction between round and strategy 
# more risk-taking when people are told to ignore context and this effect is stronger in round 2
# AIC = 30533

#PAST OUTCOME
model_poc_pred1 = glm(choice ~ 0 + pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_poc_pred1)
# trending, negative beta is trending at p=.07
# AIC = 30289

# PAST OUTCOME INTXN WITH STRATEGY
model_pocStrat_pred1 = glm(choice ~ 0 + pastOC1sc*strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_pocStrat_pred1)
#no interaction, but outcome is still negative and trending
#AIC = 30281

#SHIFT
model_signedShiftStrat_pred1 = glm(choice ~ 0 + signedShiftsc*strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_signedShiftStrat_pred1)
# positive interaction bewteen strategy and round
# positive interaction between strategy, round and signed shift 
# AIC = 30527

#POSITIVE AND NEGATIVE SHIFT
model_posNegShift_pred1 = glm(choice ~ 0 + posShiftsc  + negShiftsc + strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_posNegShift_pred1) 
# trending effect of positive shift, significant effect of negative shift, positive interaction between strategy and round
# AIC = 30529

# POSITIVE AND NEGATIVE SHIFT WITH STRATEGY
model_posNegShiftStrat_pred1 = glm(choice ~ 0 + posShiftsc*strategyRecode*roundRecode + negShiftsc*strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_posNegShiftStrat_pred1) 
# AIC: 30527 (same as signedShift model with round x strategy)
# trending effect of positive shift
# main effect of stratgey, negative shift
# interaction bewteen strategy and positive shift, strategy and round
# interaction between strategy and round, interaction between strategy and negative shift (making negative shift stronger in strategy condition) 
# 0.774618*1*-.33 + 0.774618*-.33 - 0.041001*1 = -0.5522489 # strategy, large negative shift - effect on gambling is negative
# 0.774618*-1*-.33 + 0.774618*-.33 - 0.041001*-1 = 0.041001; # natural, large negative shift - effect on gambling is positive

# EARNINGS X EXPECTATIONS (I.E. TRIAL NORMALIZED)
model_earnsExp_pred1 = glm(choice ~ 0 + earnNormalizedOverall + trialSC, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_earnsExp_pred1)
# betas are in direction as expected and significant
# AIC = 30526


# EARNINGS AND EXPECTATIONS (TIME) INTERACTING
model_earnsExpIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*trialSC, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_earnsExpIntxn_pred1)
# effect of earnigns enx expectations as we'd expect, trending interaction between trial and earnings is positive
# beta estimates are so similar between expectations and earnings
# AIC: 30524

#EARNINGS, EXPECTATIONS AND STRATEGY x ROUND
model_earnsExpIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*trialSC*strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_earnsExpIntxn_pred1)
# main effect of expectation and earnings
# trending interaction bewteen earnings and expectations
# trending interaction beweeen earnings, expectation and strategy (positive)
# AIC: 30517

model_earnsExpIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*trialSC*strategyRecode + strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_earnsExpIntxn_pred1)
# main effect of expectation and earnings
# trending interaction bewteen earnings and expectations
# trending interaction beweeen earnings, expectation and strategy (positive)
# AIC: 30510
# better model is to account for interaction with strategy and separate interaction with strategy and round


# EARNINGS AND OUTCOME INTERACTION

model_earnsOCExpIntxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*pastOC1sc*trialSC + strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_earnsOCExpIntxn_pred1)
# AIC = AIC: 30237 (AIC = 30248 (when not accounting for roundxstrat))
# negative effect of past outcome
# positive effect of strategy
# intxn between earnings, poc; earnings and expectations; expectations and poc; and strategy x round

model_earnsOC_expOC_Intxn_pred1 = glm(choice ~ 0 + earnNormalizedOverall*pastOC1sc + earnNormalizedOverall*trialSC + trialSC*pastOC1sc + strategyRecode*roundRecode, data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_earnsOC_expOC_Intxn_pred1);
# AIC = 30235
# removing the 3-way interaction between poc, earnings and expectation improves model
# results same as above

# PUT ALL TIMESCALES IN MODEL
model_3timescales_pred1 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall + posShiftsc + negShiftsc + trialSC*pastOC1sc + strategyRecode*roundRecode,  data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_3timescales_pred1);
# AIC: 30230
# negative past outcome effect
# no positive shift effect
# negative shift effect
# positive effect of strategy
# interaction bewteen poc earnings and poc and expectations
# strategy x round interaction


model_3timescalesStrategy_pred1 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode*roundRecode + posShiftsc*strategyRecode*roundRecode + negShiftsc*strategyRecode*roundRecode + trialSC*pastOC1sc*strategyRecode*roundRecode,  data=rdmDFclean, family="binomial", offset=predModel1)
summary(model_3timescalesStrategy_pred1)
# AIC: 30230
# big model
# main effect of past outcome and negative shift
# immediate timescale: negative past outcome effect that has a trending interaction with round
# neighborhood timescale: negative effect of shift, interaction between positive shift and strategy, interaction between negative eshift, round and strategy
# global timescale: round interacts with earnings (trending) and expectations
# immediate x global: poc interacts with earnings and expectations. there is also a 3-way interaction bewteen earnings, poc and round as well as poc round and expectations. 4-way interaction between poc, earnings, strategy and round as well as poc, expectations, earnings and round.


```

```{r plot-strategy-round-effect}

# using estimates from model2_trialLevRoundStrat:
model2summary = summary(model2_trialLevRoundStrat)

conditionBeta = model2summary$coefficients[6]
roundBeta = model2summary$coefficients[5]
condRoundIntxnBeta =model2summary$coefficients[7]

rounds = c(-1,-1,1,1); # round 1, round 1, round 2, round 2
conditions = c(-1,1,-1,1) # natural, strategy, natural, strategy

pgamRoundxCondition = 1/(1+exp(-1*( (conditionBeta*conditions) + (roundBeta*rounds) + (condRoundIntxnBeta*conditions*rounds) )));

# natural, round 1 pgam = 0.4909277
# natural, round 2  pgam = 0.4593623
# strategy, round 1 pgam = 0.5125908
# strategy, round 2 pgam = 0.5371388

pdf(file.path(config$path$directory, config$path$shlab_figures,'pgamRoundxCondition.pdf'))
#par(pty="s")

plot(c(pgamRoundxCondition[1], pgamRoundxCondition[3]),  ylim = c(.4,.6), pch=16, axes = F, lwd = 5, col="goldenrod1", ylab="P(gamble)", xlab="Round", cex = 2)
points(c(pgamRoundxCondition[2], pgamRoundxCondition[4]), pch=16, cex=2, col="tomato1")
axis(1, at=c(1,2), label=c("1", "2"), lwd=6, cex=1.5)
axis(2, lwd =6, cex=1.5)
abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)

legend("bottomright", legend=c("Act Natural", "Strategy"),pch =16, bty="n", col=c("goldenrod1","tomato1"), cex=1)
dev.off()
```

```{r save-predicted-values, echo=FALSE}
rdmDFclean$predModel2= predict(model2_trialLevRoundStrat,type="link"); 
```


### Recent event models
#### glmer models are showing up as singular - we will use glm, effects are nearly identical between glmer and glm versions
```{r recent-events-model-alldata}

# what happens when we account for strategy and round using predicted values from both of our trial level models

# using predicted avlues from model 3 above (gain, safe, ev, round and strategy)
model_roundStrat_pred2= glm(choice ~ 0 + roundRecode*strategyRecode, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_roundStrat_pred2)
# no additional effects of round, strategy or interaction
# AIC = 30519

# PAST OUTCOME
model_poc_pred2 = glm(choice ~ 0 + pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_poc_pred2)
# negative trending effect of poc; p = 0.0703 .

# SHIFT
model_pocSignedShift_pred2 = glm(choice ~ 0 + pastOC1sc + signedShiftsc, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocSignedShift_pred2); #  positive main effect of signed shift
# AIC = 30256

model_pocPosNegShift_pred2 = glm(choice ~ 0 + pastOC1sc + posShiftsc + negShiftsc, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocPosNegShift_pred2); #  trending effect of negative shift, no other main effects (ps~.1)
# AIC = 30258

# better AIC when accounting for signed shift rather than splitting it up
# Best to go with signed shift? Even though this wasn't always the case across studies, this is the measurement that is the most inconsistent across datasets (and the number of occurances is less than the rest of the other timescales
# Could make a foot note about this exact thing and then explore additional analyses in the supplement that splits up positive and negative shift

# How far back does shift effect go?
model_pocSignedShift_howfarback_pred2 = glm(choice ~ 0 + pastOC1sc + signedShiftsc + signedShift_1triback, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocSignedShift_howfarback_pred2); 
# AIC = 30258; no effect of shift 1 trial back
# consistent with previous work, shift effect is short-lasting


model_pocPosNegShift_howfarback_pred2 = glm(choice ~ 0 + pastOC1sc + posShiftsc + negShiftsc + posShift_1triback + negShift_1triback, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocPosNegShift_howfarback_pred2); 
# AIC = 30262; 
# pos/neg shift model also shows short-lasting shift effect.


# EARNINGS AND EXPECTATIONS

model_pocSignedShiftEarnExp_pred2 = glm(choice ~ 0 + pastOC1sc + signedShiftsc + earnNormalizedOverall + linExpectation, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocSignedShiftEarnExp_pred2); 
# AIC = 30226
# all significant effects in expected directions - best AIC of these 3 models

# check with positive and negative shift
model_pocPosNegShiftEarnExp_pred2 = glm(choice ~ 0 + pastOC1sc + posShiftsc + negShiftsc + earnNormalizedOverall + linExpectation, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocPosNegShiftEarnExp_pred2); 
# AIC = 30228 - AIC is still better with signed shift.

# interaction between earnings and expectations?
model_pocSignedShiftEarnExpIntxn_pred2 = glm(choice ~ 0 + pastOC1sc + signedShiftsc + earnNormalizedOverall*linExpectation, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocSignedShiftEarnExpIntxn_pred2); 
# AIC = 30227
# all significant as expected, but no interaction between earnings and expectations
# model without the interaction with signed shift has best AIC.


# EARNINGS, EXPECTATIONS AND PAST OUTCOME
model_pocSignedShiftEarnExp_pocIntxn_pred2 = glm(choice ~ 0 + pastOC1sc + signedShiftsc + earnNormalizedOverall*pastOC1sc + linExpectation*pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocSignedShiftEarnExp_pocIntxn_pred2); 
# AIC = 30211
# main effects of past outcome and signed shift
# interaction between past outcome and earnings and past outcome and expectations

# checked pos/neg shift instead of signed shift for AIC
model_pocPosNegShiftEarnExp_pocIntxn_pred2 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall + posShiftsc + negShiftsc + linExpectation*pastOC1sc,  data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocPosNegShiftEarnExp_pocIntxn_pred2)
# AIC = 30212
# AIC worse than signed shift model

# In vic, we found that past outcome interacted with earnings but not expectations:
model_pocSignedShiftEarnExp_pocIntxnEarnOnly_pred2 = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall + signedShiftsc + linExpectation,  data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocSignedShiftEarnExp_pocIntxnEarnOnly_pred2);
# AIC =  30218- worse than model that includes both interactions between past outcome and earnings

# check if there is an interaction between poc, earnings and expectations?
model_pocSignedShiftEarnExp_poc3wayIntxn_pred2 = glm(choice ~ 0 + pastOC1sc + signedShiftsc + earnNormalizedOverall*linExpectation*pastOC1sc, data=rdmDFclean, family="binomial", offset=predModel2)
summary(model_pocSignedShiftEarnExp_poc3wayIntxn_pred2); 
# no 3-way interaction and only the 2-way interactions are significant, model AIC is worse too = 30214


# For consistency with previous models: model_pocSignedShiftEarnExp_pred2 is the second best model that doesn't account for interaction between the immediate and global timescale. Perhaps we include the bigger model in supplement 
# 

# Plot each of these effects/interactions

expVals = seq(from = .008, to= 1, length.out = 5)
pocVals = seq(from = 0, to = 1, length.out = 5)
shiftVals = seq(from = min(rdmDFclean$signedShiftsc), to = max(rdmDFclean$signedShiftsc), length.out = 5)

contextModelSummary = summary(model_pocSignedShiftEarnExp_pred2)

pocBeta = contextModelSummary$coefficients[1]
shiftBeta = contextModelSummary$coefficients[2]
earnBeta = contextModelSummary$coefficients[3]
expBeta = contextModelSummary$coefficients[4]


# PLOT PAST OUTCOME EFFECT
pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_pocES.pdf'))
pgamPOC= 1/(1+exp(-1*(pocBeta*pocVals)))
par(pty="s")
plot(pgamPOC, type="l", lwd=3, axes=F, ylim=c(.45, .55), ylab="p(gamble)", xlab="Outcome (t-1) amount", main="Effect size of past outcome on risk-taking (n=124)")
axis(1, at = c(1,3,5), labels = c("$0", "$30.50", "$60.98"), lwd=3)
axis(2, at = c(.55, .5, .45), labels = c(.55, .50, .45), lwd=3)
abline(h=0.5, col="grey", lwd=3, lty="dotted")
dev.off()

# PLOT SIGNED SHIFT EFFECT
pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_shiftES.pdf'))
pgamSignedShift= 1/(1+exp(-1*(shiftBeta*shiftVals)))
par(pty="s")
plot(pgamSignedShift, type="l", lwd=3, axes=F, ylim=c(.45, .55), ylab="p(gamble)", xlab="Shift amount", main="Effect size of signed shift on risk-taking (n=124)")
axis(1, at = c(1:5), labels = c("-$20", "-$10", "$0", "+$10", "+$20"), lwd=3)
axis(2, at = c(.55, .5, .45), labels = c(.55, .50, .45), lwd=3)
abline(h=0.5, col="grey", lwd=3, lty="dotted")
dev.off()

# PLOT EARNINGS RELATIVE TO EXPECTATIONS
# for several participants, plot the effect of earnings relative to expectations on pgam
# just use round 1 data for now
# subs with round 1 earn/exp that drop below .5: 5,8, 18, 19, 24, 25, 29, 34, 39, 43, 45, 46, 48, 52, 54, 59, 62, 63, 74, 86, 100, 110, 123, 132

sub1 = rdmDFclean[rdmDFclean$subIDnum==1,];
PgamSub1EarnExp =1/(1+exp(-1*( (expBeta*sub1$trialSC[sub1$roundRDM==1]) + (earnBeta*sub1$earnNormalizedOverall[sub1$roundRDM==1]) )));

sub2 = rdmDFclean[rdmDFclean$subIDnum==24,];
PgamSub2EarnExp =1/(1+exp(-1*( (expBeta*sub2$trialSC[sub2$roundRDM==1]) + (earnBeta*sub2$earnNormalizedOverall[sub2$roundRDM==1]) )))

sub3 = rdmDFclean[rdmDFclean$subIDnum==40,];
PgamSub3EarnExp =1/(1+exp(-1*( (expBeta*sub3$trialSC[sub3$roundRDM==1]) + (earnBeta*sub3$earnNormalizedOverall[sub3$roundRDM==1]) )))

sub4 = rdmDFclean[rdmDFclean$subIDnum==71,];
PgamSub4EarnExp =1/(1+exp(-1*( (expBeta*sub4$trialSC[sub4$roundRDM==1]) + (earnBeta*sub4$earnNormalizedOverall[sub4$roundRDM==1]) )))

sub5 = rdmDFclean[rdmDFclean$subIDnum==86,];
PgamSub5EarnExp =1/(1+exp(-1*( (expBeta*sub5$trialSC[sub5$roundRDM==1]) + (earnBeta*sub5$earnNormalizedOverall[sub5$roundRDM==1]) )))

sub6 = rdmDFclean[rdmDFclean$subIDnum==116,];
PgamSub6EarnExp =1/(1+exp(-1*( (expBeta*sub6$trialSC[sub6$roundRDM==1]) + (earnBeta*sub6$earnNormalizedOverall[sub6$roundRDM==1]) )))

sub7 = rdmDFclean[rdmDFclean$subIDnum==132,];
PgamSub7EarnExp =1/(1+exp(-1*( (expBeta*sub7$trialSC[sub7$roundRDM==1]) + (earnBeta*sub7$earnNormalizedOverall[sub7$roundRDM==1]) )))

pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_earnExpOnPgam.pdf'))
plot(PgamSub1EarnExp, type="l", col="darkgreen", lwd=3, ylim=c(.4,.6), ylab="p(gamble)", xlab="trial", main="risk taking as a function\n of earnings and expectations; round1", axes=F, cex.lab=1, xlim=c(1,131))
abline(a=.5, b=0, lty="dashed", col="darkgrey", lwd=2)
lines(PgamSub2EarnExp, col="darkred", lwd=3);
lines(PgamSub3EarnExp, col="darkblue", lwd=3);
lines(PgamSub4EarnExp, col="darkorange", lwd=3);
lines(PgamSub5EarnExp, col="goldenrod", lwd=3);
lines(PgamSub6EarnExp, col="cadetblue", lwd=3);
lines(PgamSub7EarnExp, col="purple4", lwd=3);

legend("bottomright", legend=c("sub 1", "sub 24" , "sub 40","sub 71","sub 86", "sub 116", "sub 132"), lty = 1, lwd=3, bty="n", col=c("darkgreen","darkred",  "darkblue", "darkorange","goldenrod","cadetblue", "purple4"), cex=.75)
axis(1, at=c(1,131),tick =T, cex.axis = 1.25, cex=2, lwd = 4)
axis(2, tick =T, cex.axis = 1.25, cex=2, lwd = 4)
dev.off()



# Best contextual model (based on AIC) is model_pocSignedShiftEarnExp_pocIntxn_pred2:
# Negative effect of past outcome: beta = -0.34588, p = 1.1e-05 (less risk-taking as past outcome increases)
# Positive effect of signed shift: beta = 0.53988, p = 0.00759 (more risk-taking as shift gets more positive)
# Positive interaction between earnings and past outcome: beta = 3.42749, p = 0.00038 
# Negative interaction between expectations and past outcome: beta = -2.39657, p =0 .00257

# Plot each of these effects/interactions

expVals = seq(from = .008, to= 1, length.out = 5)
pocVals = seq(from = 0, to = 1, length.out = 5)
shiftVals = seq(from = min(rdmDFclean$signedShiftsc), to = max(rdmDFclean$signedShiftsc), length.out = 5)

contextModelSummary = summary(model_pocSignedShiftEarnExp_pocIntxn_pred2)

pocBeta = contextModelSummary$coefficients[1]
shiftBeta = contextModelSummary$coefficients[2]
earnBeta = contextModelSummary$coefficients[3]
expBeta = contextModelSummary$coefficients[4]
pocEarnBeta = contextModelSummary$coefficients[5]
pocExpBeta = contextModelSummary$coefficients[6]

# PLOT PAST OUTCOME EFFECT
pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_pocIntxns_pocES.pdf'))
pgamPOC= 1/(1+exp(-1*(pocBeta*pocVals)))
par(pty="s")
plot(pgamPOC, type="l", lwd=3, axes=F, ylim=c(.4, .55), ylab="p(gamble)", xlab="Outcome (t-1) amount", main="Effect size of past outcome on risk-taking (n=124)")
axis(1, at = c(1,3,5), labels = c("$0", "$30.50", "$60.98"), lwd=3)
axis(2, at = c(.55, .5, .45, .4), labels = c(.55, .50, .45, .40), lwd=3)
abline(h=0.5, col="grey", lwd=3, lty="dotted")
dev.off()

# PLOT SIGNED SHIFT EFFECT
pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_pocIntxns_shiftES.pdf'))
pgamSignedShift= 1/(1+exp(-1*(shiftBeta*shiftVals)))
par(pty="s")
plot(pgamSignedShift, type="l", lwd=3, axes=F, ylim=c(.45, .55), ylab="p(gamble)", xlab="Shift amount", main="Effect size of signed shift on risk-taking (n=124)")
axis(1, at = c(1:5), labels = c("-$20", "-$10", "$0", "+$10", "+$20"), lwd=3)
axis(2, at = c(.55, .5, .45), labels = c(.55, .50, .45), lwd=3)
abline(h=0.5, col="grey", lwd=3, lty="dotted")
dev.off()

# PLOT INTERACTION BETWEEN POC AND EARNINGS
pocValsLong = rep(pocVals, times=3)
earnVals = rep(seq(from = 0, to =1, length.out=3), each=5)
pgamPOCearnings= 1/(1+exp(-1*(pocBeta*pocValsLong + earnBeta*earnVals + pocEarnBeta*pocValsLong*earnVals )))

pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_pocIntxns_pocEarnES.pdf'))
par(pty="s")
plot(pgamPOCearnings[1:5], type="l", lwd=3, axes=F, ylim=c(0,1), ylab="p(gamble)", xlab="Outcome (t-1) amount", main="Effect size of outcome(t-1) x earnings \n on risk-taking (n=124)")
lines(pgamPOCearnings[6:10], lwd=3)
lines(pgamPOCearnings[11:15], lwd=3)
axis(1, at = c(1,3,5), labels = c("$0", "$30.50", "$60.98"), lwd=3)
axis(2, at = c(0,.5,1), labels = c(0, .5, 1), lwd=3)
abline(h=0.5, col="grey", lwd=3, lty="dotted")
dev.off()
# past outcome effect is stronger as earnings increase


# PLOT INTERACTION BETWEEN POC AND EXPECTATIONS
pocValsLong = rep(pocVals, times=3)
expVals = rep(seq(from = 0, to =1, length.out=3), each=5)
pgamPOCexpectations= 1/(1+exp(-1*(pocBeta*pocValsLong + expBeta*expVals + pocExpBeta*pocValsLong*expVals)))

pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_pocIntxns_pocExpES.pdf'))
par(pty="s")
plot(pgamPOCexpectations[1:5], type="l", lwd=3, axes=F, ylim=c(0,1), ylab="p(gamble)", xlab="Outcome (t-1) amount", main="Effect size of outcome(t-1) x expectations \n on risk-taking (n=124)")
lines(pgamPOCexpectations[6:10], lwd=3)
lines(pgamPOCexpectations[11:15], lwd=3)
axis(1, at = c(1,3,5), labels = c("$0", "$30.50", "$60.98"), lwd=3)
axis(2, at = c(0,.5,1), labels = c(0, .5, 1), lwd=3)
abline(h=0.5, col="grey", lwd=3, lty="dotted")
dev.off()
# past outcome effect flips as expectations increase

# What does it mean that earnings and expectations have opposite effects on past outcome?

# Lets plot past outcome, earnings and expectations
# pick a point in the task (say half way, so .5)
# what is the effect of outcome (small, medium, large) as cumulative earnings increase (small, medium, large)?
pocIntxnEarnExpModelSummary = summary(model_pocSignedShiftEarnExp_pocIntxn_pred2)
pocBeta = pocIntxnEarnExpModelSummary$coefficients[1]
earnBeta = pocIntxnEarnExpModelSummary$coefficients[3]
linExpBeta = pocIntxnEarnExpModelSummary$coefficients[4]
potcEarnBeta = pocIntxnEarnExpModelSummary$coefficients[5];
potcExpBeta = pocIntxnEarnExpModelSummary$coefficients[6];


linExp = .5; # middle of the task
earnings = c(.2,.5,.8); # below, at, and above linear expectation


#earnings below expectation:
lowEarnGam = 1/(1+exp(-1*(pocBeta*pocVals + earnBeta*earnings[1]+ potcEarnBeta*earnings[1]*pocVals + linExpBeta*linExp + potcExpBeta*linExp*pocVals)))

#earnings equal expectations
equalEarnGam = 1/(1+exp(-1*(pocBeta*pocVals + earnBeta*earnings[2]+ potcEarnBeta*earnings[2]*pocVals + linExpBeta*linExp + potcExpBeta*linExp*pocVals )))

#earnings above expectations
aboveEarnGam= 1/(1+exp(-1*(pocBeta*pocVals + earnBeta*earnings[3]+ potcEarnBeta*earnings[3]*pocVals + linExpBeta*linExp +potcExpBeta*linExp*pocVals)))

pdf(file.path(config$path$directory, config$path$shlab_figures,'model_pocSignedShiftEarnExp_pocIntxns_pocEarnExpES.pdf'))
par(mar=c(5,6,6,3), pty="s");#change margin so ylab is not cut off
plot(lowEarnGam, type="l", ylim = c(0,1),axes = FALSE, xaxt="n", ann=F, lwd = 6, cex.lab=1, col="black", lty="twodash")
lines(equalEarnGam, lwd=6, lty="dashed",col="gray33")
lines(aboveEarnGam, lwd=6, lty ="dotted",col ="gray60")
title(ylab = "p(gamble)", line = 3.75, cex.lab=1.35, cex=2)
title(xlab = "Past outcome", line = 2.5, cex.lab=1.35, cex=2)
title(main = "Risk-taking as a function of outcome, earnings and expectations")

axis(1, at = c(1,3,5), labels =c("$0", "$30.50", "$60.98"), tick =T, cex.axis = 1.25, cex=2, lwd = 4)
axis(2, at = c(0, .5, 1), tick = T, las =2,las=2, cex.axis = 1.25, cex=2, lwd=4)
legend("bottomleft", legend=c("earn>exp", "earn=exp" , "earn<exp"), lty = c(3,2,4), lwd=4, bty="n", col=c("gray60","gray33",  "black"), cex=1)
dev.off()
```

```{r strategy-round-temporal-context}
# Does strategy and/or round interact with temporal context effects?

# Our base models are 
# 1) model_pocSignedShiftEarnExp_pred2  (poc, signed shift, earnings and linear expectations)
# 2) model_pocSignedShiftEarnExp_pocIntxn_pred2 (same as above with poc x earn and poc x lin exp)

# We know that strategy and round interact but it might not be the case for each of the temporal context effects, so we will test either/both for each level

# Start with base model 1:model_pocSignedShiftEarnExp_pred2 
# interact everything with strategy:
model_pocSignedShiftEarnExp_strategy_pred2= glm(formula = choice ~ 0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + earnNormalizedOverall*strategyRecode + linExpectation*strategyRecode, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocSignedShiftEarnExp_strategy_pred2)
# adding strategy slightly improves AIC: 30225 
# main effects hold up. 
# trending interaction between past outcome and strategy (p=.098)
# trending interaction between signed shift and strategy (p=.089)
# this is the best model interacting strategy with base model 1 - even though no interactions between strategy and earnings/linear expectations. When you remove the interaction between either earnings and strategy or exp and strategy in the same model, the other interaction that stays in the model is significant. Could this mean there is something going on at that level and we aren't looking at it the best way?

# interact everything with round:
model_pocSignedShiftEarnExp_round_pred2= glm(formula = choice ~ 0 + pastOC1sc*roundRecode + signedShiftsc*roundRecode + earnNormalizedOverall*roundRecode + linExpectation*roundRecode, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocSignedShiftEarnExp_round_pred2)
# AIC: 30233 - much worse AIC with just round
# no interactions with round

# interact everything with round and strategy
model_pocSignedShiftEarnExp_strategyRound_pred2= glm(formula = choice ~ 0 + pastOC1sc*strategyRecode*roundRecode + signedShiftsc*strategyRecode*roundRecode + earnNormalizedOverall*strategyRecode*roundRecode + linExpectation*strategyRecode*roundRecode, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocSignedShiftEarnExp_strategyRound_pred2)
# AIC: 30238 - adding both round and strategy to everything is worse AIC


model_pocSignedShiftEarnExp_strategyRoundShift_pred2= glm(formula = choice ~ 0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode*roundRecode + earnNormalizedOverall*strategyRecode + linExpectation*strategyRecode, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocSignedShiftEarnExp_strategyRoundShift_pred2)
# Tried multiple versions of this model to see if round interacts with just one or a couple timescale effects. The best model with round is one that interacts strategy with round and shift but nothing else.
# AIC: 30230 - this is still worse than model with just strategy interacting with each level 
# We still have main effects of past outcome, signed shift, strategy, earnings and linear expectations.
# Trending interaction between past outcome and strategy and signed shift and strategy
# now trending interaction between strategy, round and shift

# let's plot trending interactions from model  about: model_pocSignedShiftEarnExp_strategyRoundShift_pred2
pocVals = rep(seq(from = 0, to = 1, length.out = 5),times=2)

roundVals = rep(c(-1,1), each = 10)
stratVals = rep(c(-1,-1,-1,-1,-1,1,1,1,1,1), times = 2)
shiftValsLong = rep(shiftVals, times=4)

contextStratModel1Summary = summary(model_pocSignedShiftEarnExp_strategyRoundShift_pred2); 

pocBeta = contextStratModel1Summary$coefficients[1]
stratBeta = contextStratModel1Summary$coefficients[2]
shiftBeta = contextStratModel1Summary$coefficients[3]
roundBeta = contextStratModel1Summary$coefficients[4]
pocStratBeta = contextStratModel1Summary$coefficients[7]
shiftStratBeta = contextStratModel1Summary$coefficients[8]
shiftRoundBeta = contextStratModel1Summary$coefficients[9]
stratRoundBeta = contextStratModel1Summary$coefficients[10]
shiftStratRoundBeta = contextStratModel1Summary$coefficients[13]


# PAST OUTCOME X STRATEGY TRENDING INTXN
pgamPOCstrategy= 1/(1+exp(-1*(pocBeta*pocValsLong[1:10] + stratBeta*stratVals[1:10] + pocStratBeta*pocValsLong[1:10]*stratVals[1:10])))
#pgamPOCstrategy= 1/(1+exp(-1*(pocStratBeta*pocValsLong[1:10]*stratVals[1:10]))); # this only plots strategy poc interaction but not main effects

plot(pgamPOCstrategy[1:5], type="l", col="goldenrod", lwd=3, ylim=c(.45,.55), ylab="p(gamble)", xlab="outcome (t-1) amount", main="Past outcome x Strategy (n=124)\ntrending, p = .099731", axes=F);
lines(pgamPOCstrategy[6:10], lwd=3, col="tomato1")
axis(1,at = c(1,3,5), labels = c("$0", "$30.50", "$60.98"), lwd=3);
axis(2, at = c(.45, .5, .55), lwd =3);
abline(h=.5, col="gray", lwd=3, lty="dotted");
legend("topright", legend=c("Act Natural", "Strategy"), lty=1, bty="n", col=c("goldenrod1","tomato1"), cex=1, lwd=3)


# SIGNED SHIFT X STRATEGY X ROUND INTXN
pgamShiftxStrategyxRound= 1/(1+exp(-1*(shiftBeta*shiftValsLong + stratBeta*stratVals + stratRoundBeta*stratVals*roundVals + shiftStratBeta*shiftValsLong*stratVals + shiftRoundBeta*shiftValsLong*roundVals + shiftStratRoundBeta*shiftValsLong*stratVals*roundVals)));

# 1:5 - low to high shift; natural, round 1
# 6:10 - low to high shift; strategy, round 1
# 11:15 - low to high shift; natural, round 2
# 16:20 - low to high shift; strategy, round 2

plot(pgamShiftxStrategyxRound[1:5], type="l", col="goldenrod", lwd=3, ylim=c(.3,.6), ylab="p(gamble)", xlab="shift amount", main="Signed shift x Strategy x Round (n=124)\ntrending, p = .084", axes=F)
lines(pgamShiftxStrategyxRound[6:10], lwd=3, col="tomato1")
lines(pgamShiftxStrategyxRound[11:15], lwd=3, col="goldenrod", lty=2)
lines(pgamShiftxStrategyxRound[16:20], lwd=3, col="tomato1", lty=2)
axis(1, at = c(1,3,5), labels=c("-$20", "$0", "+$20"), lwd=3)
axis(2, at = c(.3,.4,.5,.6), lwd=3)
abline(h=.5, lwd=3, col="gray", lty="dotted")
legend("bottomright", legend=c("Nat-Rnd1", "Strat-Rnd1", "Nat-Rnd2", "Strat-Rnd2"), lty=c(1,1,2,2), bty="n", col=c("goldenrod1","tomato1","goldenrod1","tomato1"), cex=1, lwd=3)


# Try pos/neg shift instead of signed shift and interact with round x strategy
model_pocPosNegShiftEarnExp_strategyRoundShift_pred2= glm(formula = choice ~ 0 + pastOC1sc*strategyRecode + posShiftsc*strategyRecode*roundRecode + negShiftsc*strategyRecode*roundRecode + earnNormalizedOverall*strategyRecode + linExpectation*strategyRecode, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocPosNegShiftEarnExp_strategyRoundShift_pred2)
# AIC = 30228 - slightly better when splitting up signed shift into pos/neg when looking at interactions with roundxstrategyxshift
# In this model, main effects of past outcome, strategy, earnings and expectations still here. 
# this model now shows a main effect of negative shift but not positive shift
# interaction between strategy and positive shift
# 3-way interaction with negative shift and round
# poc x strategy is trending at p =.1
# breaking up shift shows separate effects for positive vs. negative shifts

# plot the positive shift interaction with strategy and the 3-way interaction with negative shift x strat x round
roundVals = rep(c(-1,1), each = 4)
stratVals = rep(c(-1,-1,1,1), times = 2)
posShiftVals = rep(c(0,.33), times =2)
negShiftVals = rep(c(-.33,0), times =4)

contextStratModel1Summary_posNegShift = summary(model_pocPosNegShiftEarnExp_strategyRoundShift_pred2); 


stratBeta = contextStratModel1Summary_posNegShift$coefficients[2]
roundBeta = contextStratModel1Summary_posNegShift$coefficients[3]
posShiftBeta = contextStratModel1Summary_posNegShift$coefficients[4]
negShiftBeta = contextStratModel1Summary_posNegShift$coefficients[5]
posShiftStratBeta = contextStratModel1Summary_posNegShift$coefficients[11] 
negShiftStratBeta = contextStratModel1Summary_posNegShift$coefficients[13]
negShiftRoundBeta = contextStratModel1Summary_posNegShift$coefficients[14]
stratRoundBeta = contextStratModel1Summary_posNegShift$coefficients[10]
negShiftStratRoundBeta = contextStratModel1Summary_posNegShift$coefficients[19]


# POSITIVE SHIFT X STRATEGY
pgamPosShiftxStrat= 1/(1+exp(-1*(posShiftBeta*posShiftVals + stratBeta*stratVals[1:4] + posShiftStratBeta*stratVals[1:4]*posShiftVals)))
plot(pgamPosShiftxStrat[1:2], type="l", col="goldenrod", lwd=3, ylim=c(.3,.6), ylab="p(gamble)", xlab="positive shift amount", main="Positive shift x Strategy (n=124)\n, p = .008", axes=F)
lines(pgamPosShiftxStrat[3:4], lwd=3, col="tomato1")

axis(1, at = c(1,2), labels=c("$0", "+$20"), lwd=3)
axis(2, at = c(.3,.4,.5,.6), lwd=3)
abline(h=.5, lwd=3, col="gray", lty="dotted")
legend("bottomright", legend=c("Act Natural", "Strategy"), lty=c(1,1), bty="n", col=c("goldenrod1","tomato1"), cex=1, lwd=3)


# NEGATIVE SHIFT X STRATEGY X ROUND
pgamNegShiftxStrategyxRound= 1/(1+exp(-1*(negShiftBeta*negShiftVals + stratBeta*stratVals + stratRoundBeta*stratVals*roundVals + negShiftStratBeta*negShiftVals*stratVals + negShiftRoundBeta*negShiftVals*roundVals + negShiftStratRoundBeta*negShiftVals*stratVals*roundVals)));

# 1:2 - negative to 0 shift; natural, round 1
# 3:4 - negative to 0 shift; strategy, round 1
# 5:6 - negative to 0 shift;natural, round 2
# 7:8 - negative to 0 shift; strategy, round 2

plot(pgamNegShiftxStrategyxRound[1:2], type="l", col="goldenrod", lwd=3, ylim=c(.3,.6), ylab="p(gamble)", xlab="negative shift amount", main="Negative shift x Strategy x Round (n=124)\np = .006", axes=F)
lines(pgamNegShiftxStrategyxRound[3:4], lwd=3, col="tomato1")
lines(pgamNegShiftxStrategyxRound[5:6], lwd=3, col="goldenrod", lty=2)
lines(pgamNegShiftxStrategyxRound[7:8], lwd=3, col="tomato1", lty=2)
axis(1, at = c(1,2), labels=c("-$20", "$0"), lwd=3)
axis(2, at = c(.3,.4,.5,.6), lwd=3)
abline(h=.5, lwd=3, col="gray", lty="dotted")
legend("bottomright", legend=c("Nat-Rnd1", "Strat-Rnd1", "Nat-Rnd2", "Strat-Rnd2"), lty=c(1,1,2,2), bty="n", col=c("goldenrod1","tomato1","goldenrod1","tomato1"), cex=1, lwd=3)

# the thing about negative shift is that these occur so infrequently and the pattern we see here that just isn't really making sense might just be coming up against noise.
# moving forward, we will proceed with signed shift as noted above.

# Let's look at strategy x round x base model 2: model_pocSignedShiftEarnExp_pocIntxn_pred2 
# interact everything with strategy
model_pocSignedShiftEarnExp_pocIntxn_strategyAll_pred2  = glm(formula = choice ~ 0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + earnNormalizedOverall*pastOC1sc*strategyRecode + linExpectation*pastOC1sc*strategyRecode, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocSignedShiftEarnExp_pocIntxn_strategyAll_pred2);
# AIC: 30213 - worse then model without strategy
# original effects hold up and only trending interaction with signed shift and strategy

model_pocSignedShiftEarnExp_pocIntxn_strategyPocShift_pred2  = glm(formula = choice ~ 0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + earnNormalizedOverall*pastOC1sc + linExpectation*pastOC1sc, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocSignedShiftEarnExp_pocIntxn_strategyPocShift_pred2);
# AIC: 30212 - still slightly worse then model without strategy
# original effects hold up 
# trending interaction between past outcome and strategy and signed shift and strategy

# add round interaction to each term
model_pocSignedShiftEarnExp_pocIntxn_strategyPocShift_roundAll_pred2  = glm(formula = choice ~ 0 + signedShiftsc*strategyRecode*roundRecode + earnNormalizedOverall*pastOC1sc*roundRecode*strategyRecode + linExpectation*pastOC1sc*roundRecode*strategyRecode, family = "binomial", data = rdmDFclean, offset = predModel2)
summary(model_pocSignedShiftEarnExp_pocIntxn_strategyPocShift_roundAll_pred2);
#AIC: 30220 - AIC worse when adding round
# Main effects hold up along with interactions between poc and earnings/expectatinos
# consistent with above, trending interaction between signed shift and strategy, and past outcome and strategy
# this model shows:
    # interactions between round and earnings, round and linear expectations where round weakens thee effects of both
    # interactions between round x earnings x outcome and round x expectation x outcome
    # big 4-way interactions between round x strategy x earnings x poc and round x strategy x expectation x poc

# Best model with base model 2 is one that interacts strategy with past outcome and signed shift.These results are also consistent with results using base model 1 where there are trending interactions between strategy and poc and strategy and shift

# The round interactions with past outcome, expectations and earnings suggests something could potentially be happening with how people are tracking things over the rounds. In the next section, look at round 1 data (the cleanest) and people who switch vs repeat conditions


```

```{r repeat-vs-switch-conditions}
# Could people who repeat conditions be more likely to track earnings over the rounds whereas people who switch strategies might reset between rounds?

# subset data for those who were in condition code 1 and 4
repeatconditions = c(condcode1, condcode4)
rdmDFrepeatCond = rdmDFclean[as.numeric(rdmDFclean$subID) %in% repeatconditions,]

# subset data for those who were in condition code 2 and 3
switchconditions = c(condcode2, condcode3)
rdmDFswitchCond = rdmDFclean[as.numeric(rdmDFclean$subID) %in% switchconditions,]

model1_repeatcond_trialLevRoundStrat= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + (1|subID), data=rdmDFrepeatCond , family = "binomial")
summary(model1_repeatcond_trialLevRoundStrat);# similar results as above when including everyone
# (-1*-.004) + (-1*.27) + (-1*-1*.055) = -0.211 # nat, round 1
# (1*-.004) + (-1*.27) + (1*-1*.055) = -0.329 # nat, round 2
# (-1*-.004) + (1*.27) + (-1*1*.055) = 0.219 # strat, round 1
# (1*-.004) + (1*.27) + (1*1*.055) = 0.321 # strat, round 2
# more risk-taking for strategy and less for natural and this effect is stronger in round 2 for people who repeat conditions

model1_switchcond_trialLevRoundStrat= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + (1|subID), data=rdmDFswitchCond , family = "binomial")
summary(model1_switchcond_trialLevRoundStrat);# different results  at trial level with only an effect of strategy, no effect of round
# more risk-taking in the strategy condition and this doesn't change across rounds

# interim summary -> strategy increases risk-taking for everyone, but this effect is stronger over time for people who repeat condition. More time with specific strategy = stronger efffect of that strategy.


# get predicted values
rdmDFrepeatCond$pred= predict(model1_repeatcond_trialLevRoundStrat,type="link"); 
rdmDFswitchCond$pred= predict(model1_switchcond_trialLevRoundStrat,type="link"); 

# TEMPORAL CONTEXT EFFECTS
# 1) past outcome, signed shift, earnings and expectations - consistent with our base model 1 above
# repeat:
model_repeatcond_pocShiftEarnExp = glm(choice ~ 0 + pastOC1sc + signedShiftsc + linExpectation + earnNormalizedOverall, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp);
# main effects as above except no effect of signed shift (p = .13) in people who repeat condition
# AIC: 15039

# switch:
model_switchcond_pocShiftEarnExp = glm(choice ~ 0 + pastOC1sc + signedShiftsc + linExpectation + earnNormalizedOverall, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp);
# main effects same as above - including effect of signed shift for people who switch conditions
# AIC: 15168

# 2) past outcome, signed shift, interaction bt earn x poc and earn x exp - consistent with base model 2 above
# repeat:
model_repeatcond_pocShiftEarnExp_pocIntxn = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall + pastOC1sc*linExpectation + signedShiftsc, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_pocIntxn);
# main effects as above except no effect of signed shift (p = .13) in people who repeat condition
# AIC: 15035 -> better model adding interaction with past outcome and earnings and expectation
# consistent with model above where we have all people there is main effect of past outcome and interaction between poc x earn and poc x ex
# still not a signed shift effect.

# switch:
model_switchcond_pocShiftEarnExp_pocIntxn = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall + pastOC1sc*linExpectation + signedShiftsc, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp_pocIntxn);
# AIC: 15160 -> improvement from model above - adding intxn with pocxearn and pocxexp helps
# results are consistent above with model where we include all data
# main effects of poc, shift and intxn wtih poc x earnings and poc x expectation

# Interim summary -> For all people, accounting for an interaction between poc x earnings and poc x expectation improves model fit. The big difference between groups is that people who repeat don't show an effect of signed shift whereas people who switch do show an effect of signed effect.


# TEMPORAL CONTEXT EFFECTS + STRATEGY + ROUND

# Base model 1: poc, shift, earnings, expectations
# repeat:
# just add strategy
model_repeatcond_pocShiftEarnExp_strategy =glm(choice ~ 0 + pastOC1sc*strategyRecode  + signedShiftsc*strategyRecode + earnNormalizedOverall*strategyRecode + linExpectation*strategyRecode, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_strategy);
# AIC: 15036 -> adding strategy improves model from above where AIC = 15039 - base model 1 for repeat people
# main effects of past outcome, earnings and expectations hold up
# interaction between strategy and shift - making shift effect stronger in strategy condition
# trending interaction with strategy and earnings -> strategy weakens earning effect
# trending interaction with strategy and expectations -> strategy weakens expectation effect
# no intxn bt poc and strat, p.13 but the direction is consistent with strategy weakening poc effect
# in this case - this means that strategy make shift effect stronger but potentially weakens effects of immediate and global timescales

# add round
model_repeatcond_pocShiftEarnExp_strategyRound =glm(choice ~ 0 + pastOC1sc*strategyRecode*roundRecode  + signedShiftsc*strategyRecode*roundRecode + earnNormalizedOverall*strategyRecode*roundRecode + linExpectation*strategyRecode*roundRecode, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_strategyRound);
# no effect of round and no interactions
# adding round makes model AIC much worse for people who repeat conditions

# switch:
# just add strategy
model_switchcond_pocShiftEarnExp_strategy =glm(choice ~ 0 + pastOC1sc*strategyRecode  + signedShiftsc*strategyRecode + earnNormalizedOverall*strategyRecode + linExpectation*strategyRecode, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp_strategy);
# AIC = 15168 - same AIC as base model 1 in switch people
# main effect of strategy but no interaction with strategy and context effects

# add round
model_switchcond_pocShiftEarnExp_strategyRound =glm(choice ~ 0 + pastOC1sc*strategyRecode*roundRecode  + signedShiftsc*strategyRecode*roundRecode + earnNormalizedOverall*strategyRecode*roundRecode + linExpectation*strategyRecode*roundRecode, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp_strategyRound);
# no effect/intxn with round and adding round makes AIC much worse for people who swtich conditions

# Interim summary -> Base model 1: Strategy only has an effect on temporal context for people who repeat conditions. Round has no effect for either group.


# Base model 2: poc, shift, poc x earnings, poc x expectations
# repeat:
# add strategy:
model_repeatcond_pocShiftEarnExp_pocIntxn_strategy = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode + pastOC1sc*linExpectation*strategyRecode + signedShiftsc*strategyRecode, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_pocIntxn_strategy);
# AIC = 15036 -> adding strategy increases AIC by 1
# Interaction between strategy and signed shift
# trending interaction between earnings x strategy and expectations and strategy


# add round:
model_repeatcond_pocShiftEarnExp_pocIntxn_strategyRound = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode*roundRecode + pastOC1sc*linExpectation*strategyRecode*roundRecode + signedShiftsc*strategyRecode*roundRecode, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_pocIntxn_strategyRound);
# AIC = 15038 -> adding round makes AIC worse but shows some interactions like in model above with all people.

# switch:
# add strategy:
model_switchcond_pocShiftEarnExp_pocIntxn_strategy = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode + pastOC1sc*linExpectation*strategyRecode + signedShiftsc*strategyRecode, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp_pocIntxn_strategy);
# AIC = 15164
# temporal context effects still there
# no effect of strategy - makes AIC worse 

# add round:
model_switchcond_pocShiftEarnExp_pocIntxn_strategyRound = glm(choice ~ 0 + pastOC1sc*earnNormalizedOverall*strategyRecode*roundRecode + pastOC1sc*linExpectation*strategyRecode*roundRecode + signedShiftsc*strategyRecode*roundRecode, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp_pocIntxn_strategyRound);
# AIC = 15180
# temporal context effects still there
# no effect of round

# interim summary: strategy and round are only impacting choices for people who repeat conditions. This suggests that the weird round interactions we see above in models with all people are driven by those who repeat conditions (because strategy effects get stronger in round 2?). For people who switch conditions, there are only contextual effects and these do not change by strategy or round. Because AIC is much worse with round, it doesn't seem like we should spend a lot of time following up on this right now. It could be noisy findings because we are just throwing so much into the model, but it could also be something about people who repeat treat past outcome, earning and expectations as continuous or that this may only be the case for people who repeat natural but not strategy.

# Both groups are showing similar contextual effects, although it seems like neighborhood effect in people who switch depends on strategy (stronger effect of shift in people who repeat strategy vs. repeat natural). Only people who repeat conditions show effects of instructions and potentially round on contextual models. For people who switch conditions, there is no effect of instructions or round on contextual models.



# Could people who switch vs. repeat be treating expectations and earnings differently  (i.e. tracking earnings across rounds?)

# take the base model 1 first and sub expectations and earnings over the rounds
model_repeatcond_pocShiftEarnExp_acrossRounds = glm(choice ~ 0 + pastOC1sc + signedShiftsc + linExpAcrossRounds + earningsAcrossRounds, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_acrossRounds);
#AIC = 15038 - this is an improvement from model with expectations and earnings within round (AIC: 15039) - AIC is much worse when changing just one of the global terms to span rounds


model_switchcond_pocShiftEarnExp_acrossRounds = glm(choice ~ 0 + pastOC1sc + signedShiftsc + linExpAcrossRounds + earningsAcrossRounds, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp_acrossRounds);
# AIC: 15176 much worse than model with linExpectation and earnings within round (AIC: 15160)

# interim -> people who repeat conditions seem to track expectations and earnings across rounds (direction of effects are consistent across groups though)

# interact model exp and earn across rounds with strategy for repeat data
model_repeatcond_pocShiftEarnExp_acrossRounds_strategy = glm(choice ~ 0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + linExpAcrossRounds*strategyRecode + earningsAcrossRounds*strategyRecode, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_acrossRounds_strategy);
# AIC = 15036 - best model so far  (with base model 1)
# interaction between strategy and shift - shift effect stronger with strategy condition
# trending interactions between strategy and earnings (effect of earnings is weaker in people who repeat strategy condition)
# trending interaction between strategy and expectations (effect of expectation is weaker in people who repeat strategy condition)

# add round
model_repeatcond_pocShiftEarnExp_acrossRounds_strategyRound = glm(choice ~ 0 + pastOC1sc*strategyRecode*roundRecode + signedShiftsc*strategyRecode*roundRecode + linExpAcrossRounds*strategyRecode*roundRecode + earningsAcrossRounds*strategyRecode*roundRecode, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_acrossRounds_strategyRound);
# adding round increases AIC, trending interaction between round and strategy but no other effects of round.

# People who repeat conditions appear to track earnings and expectations across rounds and strategy weakens these effects (trending intxn though)

# Look at base model 2 and include earnings and expectations over
model_repeatcond_pocShiftEarnExp_acrossRounds_pocIntxn= glm(choice ~ 0 + pastOC1sc*earningsAcrossRounds + pastOC1sc*linExpAcrossRounds + signedShiftsc, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_acrossRounds_pocIntxn);
# AIC: 15036 - AIC here is sightly higher than base model 2 with earnings and expectations split up by round.
# interaction between poc and earnings across rounds
# interaction between poc and expectation across rounds
# negative effect of poc

model_switchcond_pocShiftEarnExp_acrossRounds_pocIntxn= glm(choice ~ 0 + pastOC1sc*earningsAcrossRounds + pastOC1sc*linExpAcrossRounds + signedShiftsc, data=rdmDFswitchCond, family="binomial", offset=pred);
summary(model_switchcond_pocShiftEarnExp_acrossRounds_pocIntxn);
#AIC: 15174 - similar to base model1, for people who switch, best model is one with earnings and expectations within round

# add strategy to base model 2  with exp/earn across rounds for repeat data
model_repeatcond_pocShiftEarnExp_acrossRounds_pocIntxn_strategy= glm(choice ~ 0 + pastOC1sc*earningsAcrossRounds*strategyRecode + pastOC1sc*linExpAcrossRounds*strategyRecode + signedShiftsc*strategyRecode, data=rdmDFrepeatCond, family="binomial", offset=pred);
summary(model_repeatcond_pocShiftEarnExp_acrossRounds_pocIntxn_strategy);
# AIC: 15036 - same as model above without strategy.
# strategy weakens earning and expectation effects
# strategy makes shift effect stronger
# still negative past outcome effect, interaction bewteen poc and earnings and trending effect of poc and expectations

# For people who repeat conditions, global timescale effect appear to span both rounds but that this effect is weaker for people doing the strategy condition both rounds. This is consistent with round independence ratings (people who repeat natural are more likely to say rounds did not feel independent where as people who repeat strategy are more likely to say rounds felt independent).




# Let's look at round 1 data next - this would be the "cleanest" analysis.

```

```{r, subset-round1-data}

rdmRound1df = rdmDFclean[rdmDFclean$roundRDM==1,]; # subset data for just round 1 folks


model_round1_triLevel = glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + (1|subID), data=rdmRound1df , family = "binomial")
summary(model_round1_triLevel);
# AIC = 15861.7 


model_round1_triLevelStrat = glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + strategyRecode + (1|subID), data=rdmRound1df , family = "binomial")
summary(model_round1_triLevelStrat)
# gain, safe and ev as expected
# no effect of strategy
# AIC = 15863.3 -> adding strategy does not improve model!


# move forward with better fitting model: model_round1_triLevel (no strategy)
rdmRound1df$predRnd1TriLev= predict(model_round1_triLevel,type="link"); 

# TEMPORAL CONTEXT EFFECTS
# base model 1: poc, shift, earn, exp
model_round1_pocSignedShiftEarnExp = glm(choice ~ 0 + pastOC1sc + signedShiftsc + linExpectation + earnNormalizedOverall, data=rdmRound1df, family="binomial", offset=predRnd1TriLev)
summary(model_round1_pocSignedShiftEarnExp);
# AIC = 15194
# main effects of past outcome, expectations and earnings
# trending effect of signed shift
# AIC = 15195 - with pos/neg shift

# base model 2: poc, shift, poc x earn, poc x exp
model_round1_pocSignedShiftEarnExp_pocIntxn = glm(choice ~ 0 + pastOC1sc + signedShiftsc + linExpectation*pastOC1sc + earnNormalizedOverall*pastOC1sc, data=rdmRound1df, family="binomial", offset=predRnd1TriLev)
summary(model_round1_pocSignedShiftEarnExp_pocIntxn);
# AIC: 15189 -> adding interaction improves model but none of the immediate and global interactions are significant
# still main effect of past outcome and trending signed shift


# interim summary -> past outcome effect is strong across models, signed shift is less consistent but trending, and interacting poc with exp and earn improves the model but the interactions are not significant nor are main effects in base model 2.


# ADD STRATEGY
# base model 1: poc, shift, exp, earn
model_round1_pocSignedShiftEarnExp_strat = glm(choice ~ 0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + linExpectation*strategyRecode + earnNormalizedOverall*strategyRecode, data=rdmRound1df, family="binomial", offset=predRnd1TriLev)
summary(model_round1_pocSignedShiftEarnExp_strat);
# AIC: 15201 -> worse AIC adding strategy
# no effect of strategy

# base model 2: poc, shift, poc x earn, poc x exp
model_round1_pocSignedShiftEarnExp_pocIntxn_strat = glm(choice ~ 0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + linExpectation*pastOC1sc*strategyRecode + earnNormalizedOverall*pastOC1sc*strategyRecode, data=rdmRound1df, family="binomial", offset=predRnd1TriLev)
summary(model_round1_pocSignedShiftEarnExp_pocIntxn_strat);
# nooooothing. only thing that is significant is main effect of poc and trending positive shift effect. some interactions with poc, strategy and earn are p~.1

# interim summary -> no effect of strategy in round 1 of data.
# splitting up into round data is cleanest but doesn't allow for strategy effect to show for people who repeat conditions across rounds.
# this may be why we don't see strategy effects in people who switch condition.

```

```{r, rdm-ERQ-span-motivation}

# look at trial level model to see if ERQ, motivation and span interact with strategy (before accounting for temporal context effects)

# model with round and strategy (and interaction)
model2_trialLevRoundStrat_indivMeasures= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + ERQsuppSC*strategyRecode + ERQreappSC*strategyRecode + compositeSpanScore*strategyRecode + motivationNumeric*strategyRecode +(1|subID), data=rdmDFclean , family = "binomial")
summary(model2_trialLevRoundStrat_indivMeasures)
# gain, safe, EV as above
# no main effect of round 
# main effect of strategy (more risk-taking in strategy condition)
# positive interaction between round and strategy 
  # this interaction means that the effect of each condition is stronger in round 2 (i.e. more risk-taking for strategy, esp in round 2 and less risk-taking in natural, esp round 2)
# negative interaction between reappraisal and strategy
# trending negative interaction between motivation and strategy
# no other interactions

model2_trialLevRoundStrat_indivMeasures_noSpan= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + ERQsuppSC*strategyRecode + ERQreappSC*strategyRecode + motivationNumeric*strategyRecode +(1|subID), data=rdmDFclean , family = "binomial")
summary(model2_trialLevRoundStrat_indivMeasures_noSpan)
# remove composite span because it reduces our data and it didn't have an effect
# no effect of motivation on strategy
# AIC = 30644.6


model2_trialLevRoundStrat_indivMeasures_ERQonly= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + ERQsuppSC*strategyRecode + ERQreappSC*strategyRecode +(1|subID), data=rdmDFclean , family = "binomial")
summary(model2_trialLevRoundStrat_indivMeasures_ERQonly)
# AIC = 30641.3 
# strongest effect is of reappraisal

model2_trialLevRoundStrat_indivMeasures_ERQreap= glmer(choice ~ 1 + gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + ERQreappSC*strategyRecode +(1|subID), data=rdmDFclean , family = "binomial")
summary(model2_trialLevRoundStrat_indivMeasures_ERQreap);
# AIC = 30641.7

ERQvals = rep(seq(from = .33, to = 1, length.out = 5), times =2)
stratVals = rep(c(-1,1), each = 5)

stratBeta = 0.39530
erqBeta=1.42996
stratERQbeta = -0.43512 

pgamStratERQ= 1/(1+exp(-1*( (stratBeta*stratVals) + (erqBeta*ERQvals) + (stratERQbeta*stratVals*ERQvals) )));


plot(pgamStratERQ[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="reappraisal scores", cex=2, ylim=c(0, 1), axes=F, main="strat x ERQ reap"); # low reappraisal natural - no effect of past outcome
lines(pgamStratERQ[6:10], lwd=4, col="tomato1", lty=1); # high reappraisal, natural, negative effect of past outcome
axis(1, at=c(1,5), label=c("14", "42"), lwd=3, cex=1.5)
axis(2, lwd =3, cex=1.5)
abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
legend("bottomleft", legend=c("Act Natural","Ignore Context"),lty=1, bty="n", col=c("goldenrod1", "tomato1"), cex=1, lwd=3)
# for people who score high on reappraising, there is no effect of strategy
# for people who score low on reappraising, there is more risk-taking in the strategy condition

# save the predicted values - not sure we will use these:
rdmDFclean$predModel2_ERQreap = predict(model2_trialLevRoundStrat_indivMeasures_ERQreap, type="link")


```



```{r rdm-strategy-span}
# Does motivation, ERQ and composite span interact with strategy effects on temporal context?
# Because we do not have composite span for each person (missing 23 people; n= 101 for these analyses)
# for the people we are missing composite span: 5 did nat-nat, 3 did nat-strat, 7 did strat-nat and 8 did strat-strat, so this isn't great.

# Because we are missing data for these people, any analyses that include composite span will show a lower AIC even though part of that decrease in AIC is due to missing data and not necessarily better model fit.
# Comparing models with different data is difficult! 
# Potential solutions include:
# 1) run our models above inc. trial-level, pull predicted values, and then base models 1 and 2 with n=101 to see if our baseline results change. Then include
# 2) looking at trial-level likelihoods and comparing across all data vs. composite span data

# Some predictions to keep on track:
# 1) Motivation and composite span should enhance strategy's effects on decision-making overall 
# 2) Motivation and composite span should enhance strategy's effects on temporal context in risk
# 3) We expect these effects to be stronger at immediate and global timescales because we expect strategy to do the most work here (although we are finding some effects of strategy at neighborhood timescale)
# 4) ERQ reappraisal and suppression - less clear hypotheses here - could see effects of either or both
  # ERQ reappraisal may be associated with stronger strategy influence overall and/or on temporal context effects
  # ERQ suppression could go either way - strategy is asking people to take a different perspective but its also asking them to ignore (i.e. contextual influences) so people who have higher suppression scores could be better at the strategy.
  # it may be that the strategy is getting at both reappraisal and suppression and so people with higher reappraisal and suppression scores may BOTH be more successful at implementing the strategy.


# Trial-level model with n=101

rdmWithSpanDF = rdmDFclean[is.finite(rdmDFclean$compositeSpanScore),];

# trial-level model:
triLev_n101 = glmer(choice~gainScaled + safeScaled + evLevScaled + roundRecode*strategyRecode + (1|subID), data=rdmWithSpanDF , family = "binomial")
summary(triLev_n101);
# AIC = 24965.2

# using estimates from triLev_n101:
triLevn101summ = summary(triLev_n101)

conditionBeta = triLevn101summ$coefficients[6]
roundBeta = triLevn101summ$coefficients[5]
condRoundIntxnBeta =triLevn101summ$coefficients[7]

rounds = c(-1,-1,1,1); # round 1, round 1, round 2, round 2
conditions = c(-1,1,-1,1) # natural, strategy, natural, strategy

pgamRoundxCondition = 1/(1+exp(-1*( (conditionBeta*conditions) + (roundBeta*rounds) + (condRoundIntxnBeta*conditions*rounds) )));

# natural, round 1 pgam = 0.4853046 (model results with all data= 0.4909277)
# natural, round 2  pgam = 0.4512572 (model results with all data = 0.4593623)
# strategy, round 1 pgam = 0.5153633 (model results with all data = 0.5125908)
# strategy, round 2 pgam = 0.5480805 (model results with all data = 0.5371388)
# very similar pattern of risk-taking overall as a fx of round x strat as analysis with all participants
# plot these effects:
plot(c(pgamRoundxCondition[1], pgamRoundxCondition[3]),  ylim = c(.4,.6), pch=16, axes = F, lwd = 5, col="goldenrod1", ylab="P(gamble)", xlab="Round", cex = 2)
points(c(pgamRoundxCondition[2], pgamRoundxCondition[4]), pch=16, cex=2, col="tomato1")
axis(1, at=c(1,2), label=c("1", "2"), lwd=6, cex=1.5)
axis(2, lwd =6, cex=1.5)
abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
legend("bottomright", legend=c("Act Natural", "Strategy"),pch =16, bty="n", col=c("goldenrod1","tomato1"), cex=1)


# save predicted values
rdmWithSpanDF$triLevn101pred= predict(triLev_n101,type="link"); 


# base model 1:
pocShiftEarnExp_n101 = glm(choice~0+pastOC1sc + signedShiftsc + earnNormalizedOverall + linExpectation, data=rdmWithSpanDF, family="binomial", offset=triLevn101pred);
summary(pocShiftEarnExp_n101);
# Trending negative effect of poc
# Significant effects of earnings and expectations as expected
# no significant effect of signed shift (p=.13)
# AIC = 24244

# base model 2:
pocShiftEarnExp_pocIntxn_n101 = glm(choice~0+pastOC1sc*earnNormalizedOverall + signedShiftsc + pastOC1sc*linExpectation, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
summary(pocShiftEarnExp_pocIntxn_n101);
# AIC: 24232
# like with the models including all data, the interaction bewteen poc and earn and poc and exp improves model fit
# similar to models with all data, there is a negative effect of past outcome, and positive interaction between poc x earnings and negative interaction between poc x expectations. 
# not seeing a signed shift effect but p = .11


# interact base models with strategy
# base model 1
pocShiftEarnExp_n101_strategy = glm(choice~0+pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + earnNormalizedOverall*strategyRecode + linExpectation*strategyRecode, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
summary(pocShiftEarnExp_n101_strategy);
# AIC: 24247 - adding strategy to all variables increases AIC 
# trending positive interaction with strategy and shift (the direction is consistent with interaction we see in model with all data where strategy makes signed shift effect stronger)

# base model 2:
pocShiftEarnExp_pocIntxn_n101_strategy = glm(choice~0+pastOC1sc*earnNormalizedOverall*strategyRecode + signedShiftsc*strategyRecode + pastOC1sc*linExpectation*strategyRecode, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
summary(pocShiftEarnExp_pocIntxn_n101_strategy);
# AIC = 24239 - adding strategy to each variable/interaction increases AIC
# still seeing negative effect of past outcome, trending positive effect of shift, interaction between poc and earnings and poc and expecttaions
# trending interaction between signed shift and strategy


# These model results are qualitatively consistent when including all data but there is weakening of some effects/interaction with the reduction in data including the main effects of immediate and global timescales and that strategy seems to have the strongest possible effect on neighborhood timescales.

# Let's look at composite span, motivation and ERQ

# start by putting in an interaction between strategy and ERQ, motivation, and span
# add span, erq and motivation to just strategy
# base model1
pocShiftEarnExp_n101_strategyAllIndivMeasures = glm(choice~0 + pastOC1sc*strategyRecode + signedShiftsc*strategyRecode + earnNormalizedOverall*strategyRecode + linExpectation*strategyRecode+ strategyRecode*compositeSpanScore + strategyRecode*motivationNumeric + strategyRecode*ERQsuppSC + strategyRecode*ERQreappSC, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
summary(pocShiftEarnExp_n101_strategyAllIndivMeasures);
# only trending interaction is strategy x reappraisal
# AIC: 23797 - AIC improves but ERQ removes some data for two participants


# base model 2:
pocShiftEarnExp_pocIntxn_n101_strategyAllIndivMeasures = glm(choice~0+pastOC1sc*earnNormalizedOverall*strategyRecode + signedShiftsc*strategyRecode + pastOC1sc*linExpectation*strategyRecode + strategyRecode*compositeSpanScore + strategyRecode*motivationNumeric + strategyRecode*ERQsuppSC + strategyRecode*ERQreappSC, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
summary(pocShiftEarnExp_pocIntxn_n101_strategyAllIndivMeasures);
# AIC: 23790
# like above, reappraisal has trending interaction with strategy

```

```{r ERQ-strategy-temporalcontext}
# explore reappraisal because that seems to be the most impactful on strategy - does it interact with strategy x temporal context effects?
pocShiftEarnExp_n101_strategyERQreap = glm(choice~0 + pastOC1sc*strategyRecode*ERQreappSC + signedShiftsc*strategyRecode*ERQreappSC + earnNormalizedOverall*strategyRecode*ERQreappSC + linExpectation*strategyRecode*ERQreappSC, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
summary(pocShiftEarnExp_n101_strategyERQreap);
# AIC = 23788 - adding interaction with ERQ reap to strategy improves model overall
# interaction between poc x strat x ERQ reappraisal

# plot this:
stratERQreap_basemodel1n101 = summary(pocShiftEarnExp_n101_strategyERQreap)

pocBeta = stratERQreap_basemodel1n101$coefficients[1]
stratBeta = stratERQreap_basemodel1n101$coefficients[2]
ERQreapBeta = stratERQreap_basemodel1n101$coefficients[3]
pocStratBeta = stratERQreap_basemodel1n101$coefficients[7]
pocERQreapBeta = stratERQreap_basemodel1n101$coefficients[8]
stratERQreapBeta = stratERQreap_basemodel1n101$coefficients[9]
pocERQstratBeta = stratERQreap_basemodel1n101$coefficients[16]


# poc x strat x ERQ reappraisal
pocVals = rep(seq(from=0, to = 1, length.out=5), times = 4)
stratVals = rep(c(-1,1), each=10)
reapVals = rep(rep(c(.33, 1), each=5), times=2)

pgamStratPOCreap_n101 = 1/(1+exp(-1*( (pocBeta*pocVals) + (stratBeta*stratVals) + (ERQreapBeta*reapVals) + (pocStratBeta*pocVals*stratVals) + (pocERQreapBeta*pocVals*reapVals) + (stratERQreapBeta*stratVals*reapVals) + (pocERQstratBeta*pocVals*stratVals*reapVals) )));

# 1:5: low reappraisal, natural
# 6:10: high reappraisal, natural - dashed line
# 11:15: low reappraisal, strategy 
# 16:20: high reappraisal, strategy - dashed line

plot(pgamStratPOCreap_n101[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="Outcome(t-1) amount", cex=2, ylim=c(.3, .61), axes=F, main="poc x strat x ERQ reap, n=101"); # low reappraisal natural - no effect of past outcome
lines(pgamStratPOCreap_n101[6:10], lwd=4, col="goldenrod1", lty=2); # high reappraisal, natural, negative effect of past outcome
lines(pgamStratPOCreap_n101[11:15], lwd=4, col="tomato1"); # low reappraisal, strategy, negative effect of past outcome
lines(pgamStratPOCreap_n101[16:20], lwd=4, col="tomato1", lty=2); # high reappraisal, strategy, positive effect of past outcome
axis(1, at=c(1,3,5), label=c("$0", "$30.50", "$60.98"), lwd=3, cex=1.5)
axis(2, lwd =3, cex=1.5)
abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
legend("bottomleft", legend=c("Nat, low reap","Nat, high reap", "Strat, low reap", "Strat, high reap"),lty=c(1,2,1,2), bty="n", col=c("goldenrod1","goldenrod1", "tomato1", "tomato1"), cex=1, lwd=3)
# for people with low reappraisal, the strategy leads to stronger immediate timescale effect
# for people with high reappraisal, the strategy has strong effect on risk-taking but the effect is positive



# look at the same effect of ERQ in all data
# base model 1
pocShiftEarnExp_strategyERQreap = glm(choice~0 + pastOC1sc*strategyRecode*ERQreappSC + signedShiftsc*strategyRecode*ERQreappSC + earnNormalizedOverall*strategyRecode*ERQreappSC + linExpectation*strategyRecode*ERQreappSC, data=rdmDFclean, family="binomial",offset=predModel2);
summary(pocShiftEarnExp_strategyERQreap);
# AIC =  29756

# plot this:
stratERQreap_basemodel1 = summary(pocShiftEarnExp_strategyERQreap)

pocBeta = stratERQreap_basemodel1$coefficients[1]
stratBeta = stratERQreap_basemodel1$coefficients[2]
ERQreapBeta = stratERQreap_basemodel1$coefficients[3]
pocStratBeta = stratERQreap_basemodel1$coefficients[7]
pocERQreapBeta = stratERQreap_basemodel1$coefficients[8]
stratERQreapBeta = stratERQreap_basemodel1$coefficients[9]
pocERQstratBeta = stratERQreap_basemodel1$coefficients[16]


# poc x strat x ERQ reappraisal
pocVals = rep(seq(from=0, to = 1, length.out=5), times = 4)
stratVals = rep(c(-1,1), each=10)
reapVals = rep(rep(c(.33, 1), each=5), times=2)

pgamStratPOCreap_basemodel1_all = 1/(1+exp(-1*( (pocBeta*pocVals) + (stratBeta*stratVals) + (ERQreapBeta*reapVals) + (pocStratBeta*pocVals*stratVals) + (pocERQreapBeta*pocVals*reapVals) + (stratERQreapBeta*stratVals*reapVals) + (pocERQstratBeta*pocVals*stratVals*reapVals) )));

# 1:5: low reappraisal, natural
# 6:10: high reappraisal, natural - dashed line
# 11:15: low reappraisal, strategy 
# 16:20: high reappraisal, strategy - dashed line

plot(pgamStratPOCreap_basemodel1_all[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="Outcome(t-1) amount", cex=2, ylim=c(.3, .61), axes=F, main="poc x strat x ERQ reap, n=124"); # low reappraisal natural - no effect of past outcome
lines(pgamStratPOCreap_basemodel1_all[6:10], lwd=4, col="goldenrod1", lty=2); # high reappraisal, natural, negative effect of past outcome
lines(pgamStratPOCreap_basemodel1_all[11:15], lwd=4, col="tomato1"); # low reappraisal, strategy, negative effect of past outcome
lines(pgamStratPOCreap_basemodel1_all[16:20], lwd=4, col="tomato1", lty=2); # high reappraisal, strategy, positive effect of past outcome
axis(1, at=c(1,3,5), label=c("$0", "$30.50", "$60.98"), lwd=3, cex=1.5)
axis(2, lwd =3, cex=1.5)
abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
legend("bottomleft", legend=c("Nat, low reap","Nat, high reap", "Strat, low reap", "Strat, high reap"),lty=c(1,2,1,2), bty="n", col=c("goldenrod1","goldenrod1", "tomato1", "tomato1"), cex=1, lwd=3)
# similar results as model with just composite data
# overall the effect of past outcome on risk-taking is negative, except for people in the strategy condition who have a tendency to reappraise. 
# the effect is that there is still an effect of immediate timescale, but it is flipped (leading to more risk-taking with increasing outcomes)- could this also contribute to more risk-taking in strategy condition?
# for people who are not great at reappraising, could the strategy be putting more load on them and so they are relying on their more habitual, natural responses to a negative effect of  past outcome?

# base model 2 with all data and ERQ x strat
pocShiftEarnExp_pocIntxn_strategyERQreap = glm(choice~0 + pastOC1sc*strategyRecode*ERQreappSC + signedShiftsc*strategyRecode*ERQreappSC + earnNormalizedOverall*pastOC1sc + linExpectation*pastOC1sc, data=rdmDFclean, family="binomial",offset=predModel2);
summary(pocShiftEarnExp_pocIntxn_strategyERQreap);
# AIC =  29746

# plot this (just erq x strat x poc)
stratERQreap_basemodel2 = summary(pocShiftEarnExp_pocIntxn_strategyERQreap)

pocBeta = stratERQreap_basemodel2$coefficients[1]
stratBeta = stratERQreap_basemodel2$coefficients[2]
ERQreapBeta = stratERQreap_basemodel2$coefficients[3]
pocStratBeta = stratERQreap_basemodel2$coefficients[7]
pocERQreapBeta = stratERQreap_basemodel2$coefficients[8]
stratERQreapBeta = stratERQreap_basemodel2$coefficients[9]
pocERQstratBeta = stratERQreap_basemodel2$coefficients[14]


# poc x strat x ERQ reappraisal
pocVals = rep(seq(from=0, to = 1, length.out=5), times = 4)
stratVals = rep(c(-1,1), each=10)
reapVals = rep(rep(c(.33, 1), each=5), times=2)

pgamStratPOCreap_basemodel2_all = 1/(1+exp(-1*( (pocBeta*pocVals) + (stratBeta*stratVals) + (ERQreapBeta*reapVals) + (pocStratBeta*pocVals*stratVals) + (pocERQreapBeta*pocVals*reapVals) + (stratERQreapBeta*stratVals*reapVals) + (pocERQstratBeta*pocVals*stratVals*reapVals) )));

# 1:5: low reappraisal, natural
# 6:10: high reappraisal, natural - dashed line
# 11:15: low reappraisal, strategy 
# 16:20: high reappraisal, strategy - dashed line

plot(pgamStratPOCreap_basemodel2_all[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="Outcome(t-1) amount", cex=2, ylim=c(.3, .61), axes=F, main="poc x strat x ERQ reap\n base model 2 n=124"); # low reappraisal natural - no effect of past outcome
lines(pgamStratPOCreap_basemodel2_all[6:10], lwd=4, col="goldenrod1", lty=2); # high reappraisal, natural, negative effect of past outcome
lines(pgamStratPOCreap_basemodel2_all[11:15], lwd=4, col="tomato1"); # low reappraisal, strategy, negative effect of past outcome
lines(pgamStratPOCreap_basemodel2_all[16:20], lwd=4, col="tomato1", lty=2); # high reappraisal, strategy, positive effect of past outcome
axis(1, at=c(1,3,5), label=c("$0", "$30.50", "$60.98"), lwd=3, cex=1.5)
axis(2, lwd =3, cex=1.5)
abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
legend("bottomleft", legend=c("Nat, low reap","Nat, high reap", "Strat, low reap", "Strat, high reap"),lty=c(1,2,1,2), bty="n", col=c("goldenrod1","goldenrod1", "tomato1", "tomato1"), cex=1, lwd=3)

# interaction between poc x strat and erq iin both base models are very similar - at least the directions


# quick notes to add to summary - ERQ seems to be the strongest influence on strategy so spent time exploring that

```




# the two sections below feels out of control and little like fishing and noise...going to hold off on this
```{r}


# add composite span only
# base model 1:
# pocShiftEarnExp_n101_strategySpan = glm(choice~0 + pastOC1sc*strategyRecode*compositeSpanScore + signedShiftsc*strategyRecode*compositeSpanScore + earnNormalizedOverall*strategyRecode*compositeSpanScore + linExpectation*strategyRecode*compositeSpanScore, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
# summary(pocShiftEarnExp_n101_strategySpan);
# # AIC: 24246 - this is still higher than base model 1 alone but better than just strategy with base model
# # composite span interacts with strategy at each timescale (weakest with poc x strat - trending p = .08)
# # when accounting for composite span, we now see overall interactions with strategy and each timescale
# # and composite span has trending intxn with poc, p =  .08
# # plot some stuff 
# stratSpan_n101summary = summary(pocShiftEarnExp_n101_strategySpan)
# 
# # poc x strategy
# stratVals = rep(c(-1,1), each = 5);
# 
# pocBeta = stratSpan_n101summary$coefficients[1]
# stratBeta = stratSpan_n101summary$coefficients[2]
# spanBeta = stratSpan_n101summary$coefficients[3]
# pocStratBeta = stratSpan_n101summary$coefficients[7]
# pocSpanBeta = stratSpan_n101summary$coefficients[8]
# stratSpanBeta = stratSpan_n101summary$coefficients[9]
# pocStratSpanBeta = stratSpan_n101summary$coefficients[16]
# shiftBeta = stratSpan_n101summary$coefficients[4]
# shiftStratBeta = stratSpan_n101summary$coefficients[10]
# shiftSpanBeta = stratSpan_n101summary$coefficients[11]
# shiftStratSpanBeta = stratSpan_n101summary$coefficients[17]
# 
# earnBeta = stratSpan_n101summary$coefficients[5]
# expBeta = stratSpan_n101summary$coefficients[6]
# stratEarnBeta =stratSpan_n101summary$coefficients[12]
# stratExpBeta = stratSpan_n101summary$coefficients[14]
# earnSpanBeta = stratSpan_n101summary$coefficients[13]
# expSpanBeta = stratSpan_n101summary$coefficients[15]
# stratEarnSpanBeta = stratSpan_n101summary$coefficients[18]
# stratExpSpanBeta = stratSpan_n101summary$coefficients[19]
# 
# pgamStratPOC_n101 = 1/(1+exp(-1*( (pocBeta*pocVals) + (stratBeta*stratVals) + (pocStratBeta*pocVals*stratVals) )));
# 
# plot(pgamStratPOC_n101[1:5],  ylim = c(.4,.6), type="l", axes = F, lwd = 3, col="goldenrod1", ylab="P(gamble)", xlab="Outcome (t-1) amount", cex = 2, main="Effect of past outcome on risk-taking\nweakens with strategy, p=.03")
# lines(pgamStratPOC_n101[6:10], cex=2, col="tomato1", lwd=3)
# axis(1, at=c(1,3,5), label=c("$0", "$30.50", "$60.98"), lwd=3, cex=1.5)
# axis(2, lwd =3, cex=1.5)
# abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
# legend("topright", legend=c("Act Natural", "Strategy"),lty=1, bty="n", col=c("goldenrod1","tomato1"), cex=1, lwd=3)
# # PAST OUTCOME HAS NEGATIVE EFFECT ON RISK-TAKING, WEAKER IN STRATEGY CONDITION
# 
# # poc x strat x composite span (this is trending so let's not get too into this but we can look at direction of trending effect)
# pocVals = rep(seq(from=0, to = 1, length.out=5), times = 4)
# stratVals = rep(c(-1,1), each=10)
# spanVals = rep(rep(c(.06, 1), each=5), times=2)
# 
# pgamStratPOCspan_n101 = 1/(1+exp(-1*( (pocBeta*pocVals) + (stratBeta*stratVals) + (spanBeta*spanVals) + (pocStratBeta*pocVals*stratVals) + (pocSpanBeta*pocVals*spanVals) + (stratSpanBeta*stratVals*spanVals) + pocStratSpanBeta*pocVals*stratVals*spanVals)));
# 
# # 1:5: low span, natural
# # 6:10: high span, natural - dashed line
# # 11:15: low span, strategy 
# # 16:20: high span, strategy - dashed line
# 
# plot(pgamStratPOCspan_n101[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="Outcome(t-1) amount", cex=2, ylim=c(.3, .61))
# lines(pgamStratPOCspan_n101[6:10], lwd=4, col="goldenrod1", lty=2); # more risk-taking for high span people in natural condition, negative effect of poc there for both but possibly slightly weaker in high span
# lines(pgamStratPOCspan_n101[11:15], lwd=4, col="tomato1"); # effect of past outcome is positive in strategy condition for low span
# lines(pgamStratPOCspan_n101[16:20], lwd=4, col="tomato1", lty=2); # effect of past outcome is negaitve in strategy condition for high span people
# # so for all people in natural and strategy with high span. the effect of poast outcome is to reduce risk-taking with higher previos outcomes
# # the exception is that people who do the strategy with low span scores show a positive effect of strategy.
# # these patterns are unexpected and not like we'd predict. its also not significant so we aren't going to give a lot of space to this.
# 
# # plot shift x strat effect
# shiftVals = rep(seq(from= -0.3278689, to = 0.3278689, length.out=5), times =2)
# stratVals = rep(c(-1,1), each = 5)
# 
# pgamStratShift_n101 = 1/(1+exp(-1*( (shiftBeta*shiftVals) + (stratBeta*stratVals) + (shiftStratBeta*shiftVals*stratVals) )));
# 
# plot(pgamStratShift_n101[1:5],  ylim = c(.3,.7), type="l", axes = F, lwd = 3, col="goldenrod1", ylab="P(gamble)", xlab="Signed shift amount", cex = 2, main="Effect of signed shift on risk-taking\nflips and strengthens with strategy, p=.007")
# lines(pgamStratShift_n101[6:10], cex=2, col="tomato1", lwd=3)
# axis(1, at=c(1,3,5), label=c("-$20", "$0", "$20"), lwd=3, cex=1.5)
# axis(2, lwd =3, cex=1.5)
# abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
# legend("bottomright", legend=c("Act Natural", "Strategy"),lty=1, bty="n", col=c("goldenrod1","tomato1"), cex=1, lwd=3)
# # EFFECT OF SIGNED SHIFT IS MORE POSITIVE AND STRONGER IN STRATEGY CONDITION
# 
# # shift x strat x span
# shiftVals = rep(seq(from=-0.3278689, to = 0.3278689, length.out=5), times = 4)
# stratVals = rep(c(-1,1), each=10)
# spanVals = rep(rep(c(.06, 1), each=5), times=2)
# 
# pgamStratShiftspan_n101 = 1/(1+exp(-1*( (shiftBeta*shiftVals) + (stratBeta*stratVals) + (spanBeta*spanVals) + (shiftStratBeta*shiftVals*stratVals) + (shiftSpanBeta*shiftVals*spanVals) + (stratSpanBeta*stratVals*spanVals) + (shiftStratSpanBeta*shiftVals*stratVals*spanVals) )));
# 
# plot(pgamStratShiftspan_n101[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="Signed shift amount", cex=2, ylim=c(.3, .7)); # low span, natural - positive effect of shift
# lines(pgamStratShiftspan_n101[6:10], lwd=4, col="goldenrod1", lty=2); # high span natural - positive effect of shift
# lines(pgamStratShiftspan_n101[11:15], lwd=4, col="tomato1"); # low span, strategy - positive effect of shift
# lines(pgamStratShiftspan_n101[16:20], lwd=4, col="tomato1", lty=2); # high span, strategy negative effect of shift
# 
# # for people with high span, natural condition is associated with positive effect of shift and strategy makes that effect negative.
# # for people with low span, strategy has the strongest effect on them (its positive effect) whereas the effect of shift is negative for those approaching choices naturally 
# # perhaps this is more reflective of people's ability to maintain the strategy instructions in their minds?
# 
# # strategy and expectations and earnings
# earnVals = seq(from=0, to =1, length.out=5)
# expVals = seq(from =.008, to = 1, length.out = 5)
# stratVals = rep(c(-1,1), each=5)
# 
# pgamStratEarn_n101 = 1/(1+exp(-1*( (earnBeta*earnVals) + (stratBeta*stratVals) + (stratEarnBeta*earnVals*stratVals) )));
# 
# plot(pgamStratEarn_n101[1:5],  ylim = c(0, 1), type="l", axes = F, lwd = 3, col="goldenrod1", ylab="P(gamble)", xlab="Earnings amount (normalized)", cex = 2, main="Effect of earnings on risk-taking\nflips and strengthens with strategy")
# lines(pgamStratEarn_n101[6:10], cex=2, col="tomato1", lwd=3)
# axis(1, at=c(1,5), label=c(0,1), lwd=3, cex=1.5)
# axis(2, lwd =3, cex=1.5)
# abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
# legend("topleft", legend=c("Act Natural", "Strategy"),lty=1, bty="n", col=c("goldenrod1","tomato1"), cex=1, lwd=3)
# # EFFECT OF EARNINGS IS MORE POSITIVE AND STRONGER IN STRATEGY CONDITION
# 
# 
# pgamStratExp_n101 = 1/(1+exp(-1*( (expBeta*expVals) + (stratBeta*stratVals) + (stratExpBeta*expVals*stratVals) )));
# 
# plot(pgamStratExp_n101[1:5],  ylim = c(0, 1), type="l", axes = F, lwd = 3, col="goldenrod1", ylab="P(gamble)", xlab="Expectations amount (normalized)", cex = 2, main="Effect of expectations on risk-taking\nflips with strategy")
# lines(pgamStratExp_n101[6:10], cex=2, col="tomato1", lwd=3)
# axis(1, at=c(1,5), label=c(0,1), lwd=3, cex=1.5)
# axis(2, lwd =3, cex=1.5)
# abline(a=.5, b=0, col="darkgrey", lty="dashed", lwd=1)
# legend("topleft", legend=c("Act Natural", "Strategy"),lty=1, bty="n", col=c("goldenrod1","tomato1"), cex=1, lwd=3)
# # LIFE EARNINGS, EFFECT OF EXPECTATIONS FLIPS IN STRATEGY CONDITION
# 
# 
# # put these together - pick a point - hold expectations constant at .5: and pick 3 levels of earnings = 0, .5, and 1
# stratVals = c(-1,1)
# pgamStratEarnExp_n101_earnBigger = 1/(1+exp(-1*( (expBeta*.5) + (earnBeta*.9)+ (stratBeta*stratVals) + (stratExpBeta*.5*stratVals) + (stratEarnBeta*.9*stratVals) )));
# 
# pgamStratEarnExp_n101_earnEqual= 1/(1+exp(-1*( (expBeta*.5) + (expBeta*.5)+ (stratBeta*stratVals) + (stratExpBeta*.5*stratVals) + (stratEarnBeta*.5*stratVals) )));
# 
# pgamStratEarnExp_n101_earnSmaller= 1/(1+exp(-1*( (expBeta*.5) + (earnBeta*.1)+ (stratBeta*stratVals) + (stratExpBeta*.5*stratVals) + (stratEarnBeta*.1*stratVals) )));
# 
# plot(pgamStratEarnExp_n101_earnBigger[1],col="goldenrod1", pch=16, cex=2, ylim=c(0,1))
# points(pgamStratEarnExp_n101_earnBigger[2], col="tomato1", pch = 16, cex=2)
# #points(pgamStratEarnExp_n101_earnEqual[1], col="goldenrod1", pch = 10, cex=2)
# #points(pgamStratEarnExp_n101_earnEqual[2], col="tomato1", pch = 10, cex=2)
# points(pgamStratEarnExp_n101_earnSmaller[1], col="goldenrod1", pch = 2, cex=2)
# points(pgamStratEarnExp_n101_earnSmaller[2], col="tomato1", pch = 2, cex=2)
# 
# 
# 
# plot(c(pgamStratEarnExp_n101_earnBigger[1], pgamStratEarnExp_n101_earnEqual[1], pgamStratEarnExp_n101_earnSmaller[1] ),col="goldenrod1", pch=16, cex=2, ylim=c(0,1), ylab="P(gamble)", xlab = "earnings relative to expectations", axes=F)
# points(c(pgamStratEarnExp_n101_earnBigger[2], pgamStratEarnExp_n101_earnEqual[2], pgamStratEarnExp_n101_earnSmaller[2] ),col="tomato1", pch=16, cex=2)
# abline(h = .5)
# axis(1, at = c(1,2,3), labels=c("earn>exp", "earn=exp", "earn<exp"), lwd=3)
# axis(2, lwd=3)
# 
# # for strategy - more risk-taking when earnings are greater than expected and less risk-taking when earnings = exp or are less than exp
# # for natural - no effect on risk-taking when earnings are less or greater than expected but less when earnings = expectations? Ugh what the fuck is going on. is this just noise?
# 
# 
# # earn x strat x span
# 
# # shift x strat x span
# earnVals = rep(seq(from=0, to =1, length.out=5), times = 4)
# stratVals = rep(c(-1,1), each=10)
# spanVals = rep(rep(c(.06, 1), each=5), times=2)
# 
# pgamStratEarnspan_n101 = 1/(1+exp(-1*( (earnBeta*earnVals) + (stratBeta*stratVals) + (spanBeta*spanVals) + (stratEarnBeta*earnVals*stratVals) + (earnSpanBeta*earnVals*spanVals) + (earnSpanBeta*earnVals*spanVals) + (stratEarnSpanBeta*earnVals*stratVals*spanVals) )));
# 
# plot(pgamStratEarnspan_n101[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="earnings (normalized)", cex=2, ylim=c(0, 1), main ="strat x earn x span"); # low span, natural, negative effect of earnings on risk-taking
# lines(pgamStratEarnspan_n101[6:10], lwd=4, col="goldenrod1", lty=2); # high span natural - positive effect of earnings
# lines(pgamStratEarnspan_n101[11:15], lwd=4, col="tomato1"); # low span, strategy - positive effect of earnings
# lines(pgamStratEarnspan_n101[16:20], lwd=4, col="tomato1", lty=2); # high span, strategy negative effect of earnings
# 
# # Natural (yellow) - low span - earnings have weak effect on risk but for high-span people, the effect is stronger and positive
# # Strategy (red) - low span - earnings have positive effect on risk but for high span people, the effect is weaker and negative
# 
# # for people with high working memory capacity, global timescale effect is strong when people behave naturally but when they are told to ignore context, they seem to do that to some extent or they go in the opposite direction
# # for people with low working memory capacity, asking them to act natural leads to similar behavior as people good at strategy where there is a negiatve effect and weaker effect of earnings on risk(?) but in the strategy this leads to strong, positive effect of earnings on risk
# 
# # again, is this more related to people's ability to remember task instructions in general (maintain those instructions in their minds while they make risky choices because for people with high span, their behavior reflects what we'd expect were thye to follow instructions)
# 
# # exp x strat x span
# expVals = rep(seq(from=0.008, to =1, length.out=5), times = 4)
# stratVals = rep(c(-1,1), each=10)
# spanVals = rep(rep(c(.06, 1), each=5), times=2)
# 
# pgamStratExpspan_n101 = 1/(1+exp(-1*( (expBeta*expVals) + (stratBeta*stratVals) + (spanBeta*spanVals) + (stratExpBeta*expVals*stratVals) + (expSpanBeta*expVals*spanVals) + (expSpanBeta*expVals*spanVals) + (stratExpSpanBeta*expVals*stratVals*spanVals) )));
# 
# plot(pgamStratExpspan_n101[1:5], type="l", lwd=4, col="goldenrod1", ylab="P(gamble)", xlab="earnings (normalized)", cex=2, ylim=c(0, 1), main ="strat x exp x span"); # low span, natural (yellow solid), positive effect of expectation on risk-taking
# lines(pgamStratExpspan_n101[6:10], lwd=4, col="goldenrod1", lty=2); # high span natural (yellow dashed) - negative effect of expectations
# lines(pgamStratExpspan_n101[11:15], lwd=4, col="tomato1"); # low span, strategy (red solid) - negative effect of expectations
# lines(pgamStratExpspan_n101[16:20], lwd=4, col="tomato1", lty=2); # high span, strategy (red dashed) positive effect of earnings
# 
# # Natural (yellow) - low span - earnings have the weakest effect on risk (its positive) but for high-span people, the effect is stronger and negative
# # Strategy (red) - low span - earnings have negative effect on risk but for high span people, the effect is positive
# 
# 
# # for people with high working memory capacity, global timescale effect for expectation is negative (as we typically see) when people behave naturally but when they are told to ignore context, they go in the opposite direction
# # for people with low working memory capacity, asking them to act natural leads to similar behavior as high span people who following strategy where there is a positive effect of expectations on risk(?) but in the strategy this leads to strong, negative effect of earnings on risk
# 
# # the 3-way interactions between earnings and expectations are very very similar in how strategy and span influence global timescale effects on risk-taking.
# # and the similarities between high span nat/low span strat and low span nat/high span strat are consistent with the interaction bewteen strategy and shift and span
# 
# # is this something with how high span people follow instructions better?

```

``` {r}
# add motivation only
# pocShiftEarnExp_n101_strategyMotiv = glm(choice~pastOC1sc*strategyRecode*motivationNumeric + signedShiftsc*strategyRecode*motivationNumeric + earnNormalizedOverall*strategyRecode*motivationNumeric + linExpectation*strategyRecode*motivationNumeric, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
# summary(pocShiftEarnExp_n101_strategyMotiv);
# # possibly interaction between strat x motivation and earnings
# # interaction between poc and motivation, beta = -1.162, p = 0.004
# # AIC: 24254 - much worse than models above at this point suggesting that motivation is not as strong of a predictor on strategy strength as composite span is.
# 
# # model with composite span is much better AIC wise and composite span seems to have the biggest impact on strategy
# # both motivation and composite span have a negative interaction with past outcome effect - in both cases it weakens the past outcome effect - not sure what this means and we didn't really expect direct interactions between temporal context effects and these individual-level measures
# 
# # add ERQ supp only
# pocShiftEarnExp_n101_strategyERQsupp = glm(choice~pastOC1sc*strategyRecode*ERQsuppSC + signedShiftsc*strategyRecode*ERQsuppSC + earnNormalizedOverall*strategyRecode*ERQsuppSC  + linExpectation*strategyRecode*ERQsuppSC, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
# summary(pocShiftEarnExp_n101_strategyERQsupp);
# # AIC = 23792 - we have slightly less observations for ERQ because for 2 people, we don't ERQ so the AIC will be smaller
# # negative interaction between suppression and strategy where higher suppression weakens strategy effect over all but not on strategy xtemporal context
# 
# # add ERQ reappraisal only
# pocShiftEarnExp_n101_strategyERQreap = glm(choice~pastOC1sc*strategyRecode*ERQreappSC + signedShiftsc*strategyRecode*ERQreappSC + earnNormalizedOverall*strategyRecode*ERQreappSC  + linExpectation*strategyRecode*ERQreappSC, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
# summary(pocShiftEarnExp_n101_strategyERQreap);
# # AIC: 23783 - better AIC than model with suppression
# # main effect of reappraisal score on risk-taking -> more risk-taking for people with higher reappraisal scores - this is consistent with one previous study (I think)
# # reappraisal strengthens strategy effect on past outcome but not with other temporal context effects - we predicted something like this would happen.
# 
# # So these model results suggest that ERQ may have stronger effects on risk-taking and strategy
# 
# # add both to model:
# pocShiftEarnExp_n101_strategyERQ_stratSuppOnly = glm(choice~pastOC1sc*strategyRecode*ERQreappSC + signedShiftsc*strategyRecode*ERQreappSC + earnNormalizedOverall*strategyRecode*ERQreappSC  + linExpectation*strategyRecode*ERQreappSC + strategyRecode*ERQsuppSC, data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
# summary(pocShiftEarnExp_n101_strategyERQ_stratSuppOnly);
# # AIC: 23787 - worse model fit adding both reap and sup and the only things that hold up are poc, erq reap and poc x strat reap
# 
# 
# pocShiftEarnExp_n101_strategyERQboth = glm(choice~pastOC1sc*strategyRecode*ERQreappSC + signedShiftsc*strategyRecode*ERQreappSC + earnNormalizedOverall*strategyRecode*ERQreappSC  + linExpectation*strategyRecode*ERQreappSC + pastOC1sc*strategyRecode*ERQsuppSC + signedShiftsc*strategyRecode*ERQsuppSC + earnNormalizedOverall*strategyRecode*ERQsuppSC  + linExpectation*strategyRecode*ERQsuppSC , data=rdmWithSpanDF, family="binomial",offset=triLevn101pred);
# summary(pocShiftEarnExp_n101_strategyERQboth);
# # AIC: 23787 - same as model above. Reappraisal outdoes suppression in all of these models and by AIC. 
# # overall effect of reappraisal and ERQ - more risk-taking with higher ERQ
# # interaction between poc x strat x reappraisal
# # interaction bewteen poc and strategy (negative beta which means effect of poc is stronger in strategy? - need to plot this)
# # interaction between suppression and strategy (strategy weakened by higher suppression scores)
# # interaction between poc, strategy and reappraisal
# 
# 



```



```{r individual-differences}

#individual level modeling is tricky here because of the singularity with strategy and round. can't put them both in a model (either trial-level or in the contextual models)

# For each participant, fit trial-level model then past outcome
subsTriLevMods = list();
#subsPocMods = list();
subsContextMods = list();
trialLevelResults = as.data.frame(matrix(data = NA, nrow = nSub, ncol=7, dimnames=list(c(NULL), c("subID","stratBeta","stratPval", "roundBeta", "roundPval", "stratRoundBeta", "stratRoundPval"))))

#contextResultColNames = c("subID", "pocBeta", "pocPval","stratBeta", "stratPval", "pocStratBeta", "pocStratPval", "roundBeta", "roundPval")
#contextResultColNames = c("subID", "pocBeta", "pocPval","stratBeta", "stratPval", "pocStratBeta", "pocStratPval")
#contextResults = as.data.frame(matrix(data=NA,nrow=nSub, ncol=length(contextResultColNames), dimnames=list(c(NULL), contextResultColNames)));



for (s in 1:nSub) {
  sub = rdmDFclean[rdmDFclean$subID==subIDchar[s],]; # pull out a single subject
  
  subsTriLevMods[[s]] = glm(choice~gainScaled + safeScaled + evLevScaled, data=sub, family="binomial"); # run the trial level model 
  # model fits are not consistently working across people who repeat/switch conditions so including strategy in models for people who repeat strategy, there are no results because of singularities
    
  # tmpTriLevResults = summary(subsTriLevMods[[s]]);
  # trialLevelResults$subID[s] = subIDchar[s]; # fill in sub ID
  # trialLevelResults$stratBeta[s] = tmpTriLevResults$coefficients[[5]]; # store strat beta
  # trialLevelResults$stratPval[s] = tmpTriLevResults$coefficients[[12]]; # store strat pvalue
  # trialLevelResults$roundBeta[s] = tmpTriLevResults$coefficients[[6]]; # store strategy beta
  # trialLevelResults$roundPval[s] = tmpTriLevResults$coefficients[[13]]; # store strat pvalue
  # trialLevelResults$stratRoundBeta[s] = tmpTriLevResults$coefficients[[7]]; # store intxn beta
  # trialLevelResults$stratRoundPval[s] = tmpTriLevResults$coefficients[[14]]; # store intxn pvalue
  
  
  
    sub$pred = predict(subsTriLevMods[[s]],type='link'); # get predicted values
    
    subsContextMods[[s]] = glm(choice~pastOC1sc*strategyRecode, data=sub, family="binomial", offset=pred);
    #subsContextMods[[s]] = glm(choice~pastOC1sc*strategyRecode*roundRDM, data=sub, family="binomial", offset=pred); # doesn't work well

    tmp =summary(subsContextMods[[s]]); #store coefficients from poc model
    contextResults$subID[s] = subIDchar[s]; # fill in sub ID
    contextResults$pocBeta[s] = tmp$coefficients[[2]]; # store poc beta
    contextResults$pocPval[s] = tmp$coefficients[[14]]; # store poc pvalue
    contextResults$stratBeta[s] = tmp$coefficients[[3]]; # store strategy beta
    contextResults$stratPval[s] = tmp$coefficients[[15]]; # store strat pvalue
    contextResults$pocStratBeta[s] = tmp$coefficients[[4]]; # store intxn beta
    contextResults$pocStratPval[s] = tmp$coefficients[[16]]; # store intxn pvalue
 }
  
}; 

print(contextResults)
contextResults = contextResults[is.finite(contextResults$pocBeta),]; # remove NA rows

# POC
  # about half(30) have a negative effect of past outcome; 5 are significant
  # the other half (32) have a positive effect of past outcome; 2 are significant

# Strategy 
  # 39 people have positive effects of strategy and 11 are significant
  # 23 people have negative effects of strategy and 9 are significant

# POC x Strategy
  # 28 people have negative interaction between poc and strategy and 3 are significant
  # 34 people have positive interaction between poc and strategy and 7 are significant

```
